# -*- coding: utf-8 -*-
"""
ç”Ÿæ„å‚è°‹å•†å“è¯„åˆ†ï¼ˆä»£è´­åº—é“ºå‹å¥½ç‰ˆï¼‰
- ç¨³å¥å½’ä¸€åŒ–ï¼ˆ1%~99%è£å‰ª + MinMaxï¼‰
- é»˜è®¤å¼±åŒ–è½¬åŒ–ç‡ã€å¼ºè°ƒGMV/ä»¶æ•°ä¸â€œå…´è¶£â€æŒ‡æ ‡ï¼ˆåŠ è´­/æ”¶è—ï¼‰
- è´Ÿå‘æŒ‡æ ‡é‡ç‚¹æ‰£åˆ†ï¼šé€€æ¬¾/é€€è´§
- æ”¯æŒæŒ‰â€œTop/Bottomç™¾åˆ†æ¯”â€æˆ–â€œTopN/BottomNâ€è¾“å‡º
"""

import os
import pandas as pd
import numpy as np
from datetime import datetime

# =============== ğŸ‘‡ å¯è°ƒå‚æ•°åŒºï¼ˆæŒ‰éœ€ä¿®æ”¹ï¼‰================

# è¾“å…¥ Excel è·¯å¾„
INPUT_PATH = r"D:\TB\sycm\ç”Ÿæ„å‚è°‹å•†å“ä¿¡æ¯\ã€ç”Ÿæ„å‚è°‹å¹³å°ã€‘å•†å“_å…¨éƒ¨_2025-08-03_2025-08-09.xls"

# è¾“å‡ºæ ¹ç›®å½•ï¼ˆè‡ªåŠ¨åˆ›å»ºæ—¶é—´æˆ³å­ç›®å½•ï¼‰
OUTPUT_BASE_DIR = r"D:\TB\sycm\ç”Ÿæ„å‚è°‹å•†å“åˆ†æç»“æœ"

# è¾“å‡ºç­–ç•¥ï¼šäºŒé€‰ä¸€
SELECT_BY_PERCENT = True   # True=æŒ‰ç™¾åˆ†æ¯”, False=æŒ‰TopN/BottomN
GOOD_PCT = 0.15            # å‰15%ä½œä¸ºä¼˜å“
BAD_PCT = 0.15             # å15%ä½œä¸ºå¾…æ”¹è¿›
TOP_N = 50                 # è‹¥ SELECT_BY_PERCENT=Falseï¼Œåˆ™å–Top_N/Bottom_N
BOTTOM_N = 50

# åˆ—åä¼˜å…ˆåŒ¹é…ï¼ˆå¯è‡ªå®šä¹‰è¦†ç›–ï¼›ç•™ç©ºåˆ™ç”¨â€œæ¨¡ç³Šä¸­æ–‡å€™é€‰â€è‡ªåŠ¨è¯†åˆ«ï¼‰
# ä¾‹å¦‚ï¼šCOL_OVERRIDES = {"gmv":"æ”¯ä»˜é‡‘é¢(å…ƒ)","units":"æ”¯ä»˜ä»¶æ•°","conv":"æ”¯ä»˜è½¬åŒ–ç‡"}
COL_OVERRIDES = {
    # "gmv": "",
    # "units": "",
    # "conv": "",
    # "ctr": "",
    # "cart": "",
    # "fav": "",
    # "buyers": "",
    # "uv": "",
    # "refund": "",
    # "return": "",
    # "bounce": "",
}

# ä»£è´­åº—é“ºé»˜è®¤æƒé‡ï¼ˆå¯æŒ‰éœ€è°ƒæ•´ï¼‰
POS_WEIGHTS = {
    "gmv":   0.50,  # æ”¯ä»˜é‡‘é¢ï¼ˆGMVï¼‰
    "units": 0.25,  # æ”¯ä»˜ä»¶æ•°
    "cart":  0.15,  # åŠ è´­ç‡/åŠ è´­äººæ•°/åŠ è´­ä»¶æ•°
    "fav":   0.05,  # æ”¶è—ç‡/æ”¶è—äººæ•°
    "ctr":   0.05,  # ç‚¹å‡»ç‡ï¼ˆè¾…åŠ©ï¼‰
    "conv":  0.00,  # è½¬åŒ–ç‡ï¼ˆå¼±åŒ–ï¼šé»˜è®¤ä¸è®¡åˆ†ï¼‰
    "buyers":0.00,  # ä¹°å®¶æ•°ï¼ˆå¦‚è¦è€ƒè™‘å¯ç»™æƒé‡ï¼‰
    "uv":    0.00,  # è®¿å®¢æ•°ï¼ˆä¸€èˆ¬æ— éœ€è®¡åˆ†ï¼‰
}
NEG_WEIGHTS = {
    "refund": 0.30,  # é€€æ¬¾ç‡/é€€æ¬¾å æ¯”
    "return": 0.20,  # é€€è´§ç‡
    "bounce": 0.10,  # è·³å¤±ç‡ï¼ˆå¦‚æœ‰ï¼‰
}

# è¯„åˆ†æ—¶å±•ç¤ºåç§°åˆ—ï¼ˆè‹¥ç•™ç©ºåˆ™è‡ªåŠ¨å°è¯•è¯†åˆ«ï¼‰
NAME_COL_CANDIDATES = ["å•†å“åç§°", "å®è´åç§°", "å•†å“", "æ ‡é¢˜", "Item", "Product"]

# ç»“æœæ–‡ä»¶å
ALL_FILE_NAME   = "å…¨éƒ¨å•†å“_å«è¯„åˆ†.xlsx"
GOOD_FILE_NAME  = "ä¼˜å“TOP.xlsx"
BAD_FILE_NAME   = "å¾…æ”¹è¿›BOTTOM.xlsx"

# ======================================================


def robust_minmax(s: pd.Series) -> pd.Series:
    """ç¨³å¥å½’ä¸€åŒ–ï¼šæŒ‰1%~99%åˆ†ä½è£å‰ªååšMin-Maxã€‚"""
    s = pd.to_numeric(s, errors="coerce")
    if s.notna().sum() == 0:
        return pd.Series([0.0] * len(s), index=s.index)
    q1 = s.quantile(0.01)
    q99 = s.quantile(0.99)
    s_clip = s.clip(lower=q1, upper=q99)
    mn, mx = s_clip.min(), s_clip.max()
    if pd.isna(mn) or pd.isna(mx) or mx == mn:
        return pd.Series([0.0] * len(s), index=s.index)
    return (s_clip - mn) / (mx - mn)


def find_col_auto(df: pd.DataFrame, candidates):
    """åœ¨dfä¸­æŒ‰å€™é€‰ä¸­æ–‡ç‰‡æ®µæ¨¡ç³ŠåŒ¹é…åˆ—åï¼ŒåŒ¹é…åˆ°å³è¿”å›åˆ—åï¼Œå¦åˆ™Noneã€‚"""
    for col in df.columns:
        name = str(col)
        for cand in candidates:
            if cand in name:
                return col
    return None


def build_column_map(df: pd.DataFrame) -> dict:
    """æ ¹æ® overrides + å€™é€‰è¯ï¼Œæ„å»ºå„æŒ‡æ ‡å¯¹åº”çš„å®é™…åˆ—åæ˜ å°„ã€‚"""

    # ä¸­æ–‡å€™é€‰ï¼ˆæŒ‰å¸¸è§â€œç”Ÿæ„å‚è°‹/ä¸šåŠ¡ä¸­å°â€è¡¨å¤´ï¼‰
    POS_MAP = {
        "gmv":   ["æ”¯ä»˜é‡‘é¢", "æˆäº¤é‡‘é¢", "æ”¯ä»˜æ€»é‡‘é¢", "é”€å”®é¢"],
        "units": ["æ”¯ä»˜ä»¶æ•°", "æˆäº¤ä»¶æ•°", "é”€é‡"],
        "buyers":["æ”¯ä»˜ä¹°å®¶æ•°", "æˆäº¤äººæ•°", "æˆäº¤ä¹°å®¶æ•°"],
        "conv":  ["è½¬åŒ–ç‡", "æ”¯ä»˜è½¬åŒ–ç‡"],
        "ctr":   ["ç‚¹å‡»ç‡"],
        "cart":  ["åŠ è´­ç‡", "åŠ è´­äººæ•°", "åŠ è´­ä»¶æ•°"],
        "fav":   ["æ”¶è—äººæ•°", "æ”¶è—ç‡"],
        "uv":    ["è®¿å®¢æ•°", "æµè§ˆäººæ•°", "UV"]
    }
    NEG_MAP = {
        "refund": ["é€€æ¬¾ç‡", "é€€æ¬¾ç¬”æ•°å æ¯”"],
        "return": ["é€€è´§ç‡"],
        "bounce": ["è·³å¤±ç‡"],
    }

    resolved = {}

    # å…ˆåº”ç”¨ç”¨æˆ·è¦†ç›–
    for k, v in COL_OVERRIDES.items():
        if v:
            if v in df.columns:
                resolved[k] = v
            else:
                print(f"âš ï¸ è¦†ç›–åˆ— {k}='{v}' ä¸åœ¨æ•°æ®ä¸­ï¼Œå¿½ç•¥è¯¥è¦†ç›–ã€‚")

    # è‡ªé€‚åº”åŒ¹é…æœªè¦†ç›–çš„
    for k, cands in POS_MAP.items():
        if k not in resolved:
            col = find_col_auto(df, cands)
            if col is not None:
                resolved[k] = col
    for k, cands in NEG_MAP.items():
        if k not in resolved:
            col = find_col_auto(df, cands)
            if col is not None:
                resolved[k] = col

    return resolved


def pick_name_column(df: pd.DataFrame) -> str | None:
    for cand in NAME_COL_CANDIDATES:
        if cand in df.columns:
            return cand
    # é€€è€Œæ±‚å…¶æ¬¡ï¼šæ‰¾å«â€œå“â€æˆ–â€œåâ€çš„åˆ—
    for col in df.columns:
        if ("å" in str(col)) or ("å“" in str(col)):
            return col
    return None


def score_dataframe(df: pd.DataFrame, col_map: dict) -> pd.DataFrame:
    """æ ¹æ®æƒé‡ä¸åˆ—æ˜ å°„ç”Ÿæˆç»¼åˆè¯„åˆ†ä¸æ’åã€‚"""
    score = pd.Series(0.0, index=df.index)

    # æ­£å‘åŠ åˆ†
    for key, w in POS_WEIGHTS.items():
        if w == 0:
            continue
        col = col_map.get(key)
        if col is not None:
            score += w * robust_minmax(df[col])

    # è´Ÿå‘æ‰£åˆ†
    for key, w in NEG_WEIGHTS.items():
        if w == 0:
            continue
        col = col_map.get(key)
        if col is not None:
            score -= w * robust_minmax(df[col])

    out = df.copy()
    out["ç»¼åˆè¯„åˆ†"] = score.round(6)
    out["æ’å"] = out["ç»¼åˆè¯„åˆ†"].rank(ascending=False, method="dense").astype(int)
    return out


def select_good_bad(df_scored: pd.DataFrame):
    """æ ¹æ®é€‰æ‹©ç­–ç•¥ç­›é€‰ä¼˜å“/å¾…æ”¹è¿›é›†åˆã€‚"""
    if SELECT_BY_PERCENT:
        p_high = df_scored["ç»¼åˆè¯„åˆ†"].quantile(1 - GOOD_PCT)  # å‰GOOD_PCT
        p_low = df_scored["ç»¼åˆè¯„åˆ†"].quantile(BAD_PCT)       # åBAD_PCT
        good_df = df_scored[df_scored["ç»¼åˆè¯„åˆ†"] >= p_high].sort_values("ç»¼åˆè¯„åˆ†", ascending=False)
        bad_df = df_scored[df_scored["ç»¼åˆè¯„åˆ†"] <= p_low].sort_values("ç»¼åˆè¯„åˆ†", ascending=True)
    else:
        good_df = df_scored.sort_values("ç»¼åˆè¯„åˆ†", ascending=False).head(TOP_N)
        bad_df = df_scored.sort_values("ç»¼åˆè¯„åˆ†", ascending=True).head(BOTTOM_N)
    return good_df, bad_df


def main():
    if not os.path.exists(INPUT_PATH):
        raise FileNotFoundError(f"æœªæ‰¾åˆ°è¾“å…¥æ–‡ä»¶ï¼š{INPUT_PATH}")

    df = pd.read_excel(INPUT_PATH)
    # æ¸…ç†å…¨ç©ºè¡Œ/åˆ—
    df = df.dropna(how="all", axis=0).dropna(how="all", axis=1)

    # åˆ—æ˜ å°„
    col_map = build_column_map(df)

    # è®¡ç®—è¯„åˆ†
    df_scored = score_dataframe(df, col_map)

    # é€‰æ‹©ä¼˜/å·®
    good_df, bad_df = select_good_bad(df_scored)

    # ç”Ÿæˆè¾“å‡ºè·¯å¾„
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    out_dir = os.path.join(OUTPUT_BASE_DIR, f"ç”Ÿæ„å‚è°‹_ç»¼åˆè¯„åˆ†_{ts}")
    os.makedirs(out_dir, exist_ok=True)
    all_path  = os.path.join(out_dir, ALL_FILE_NAME)
    good_path = os.path.join(out_dir, GOOD_FILE_NAME)
    bad_path  = os.path.join(out_dir, BAD_FILE_NAME)

    # å†™å…¥Excelï¼Œé™„å¸¦â€œè¯„åˆ†é…ç½®â€é¡µ
    with pd.ExcelWriter(all_path, engine="openpyxl") as w:
        df_scored.sort_values("ç»¼åˆè¯„åˆ†", ascending=False).to_excel(w, index=False, sheet_name="å…¨éƒ¨(é™åº)")

        # è®°å½•æ˜ å°„ä¸æƒé‡
        meta_rows = []
        meta_rows.append(["æ­£å‘æŒ‡æ ‡", "åŒ¹é…åˆ°çš„åˆ—å", "æƒé‡"])
        for k, wgt in POS_WEIGHTS.items():
            meta_rows.append([k, col_map.get(k), wgt])
        meta_rows.append(["è´Ÿå‘æŒ‡æ ‡", "åŒ¹é…åˆ°çš„åˆ—å", "æƒé‡"])
        for k, wgt in NEG_WEIGHTS.items():
            meta_rows.append([k, col_map.get(k), wgt])

        pd.DataFrame(meta_rows, columns=["æŒ‡æ ‡/ç±»å‹", "åˆ—å", "æƒé‡"]).to_excel(w, index=False, sheet_name="è¯„åˆ†é…ç½®")

    good_df.to_excel(good_path, index=False)
    bad_df.to_excel(bad_path, index=False)

    name_col = pick_name_column(df_scored)
    preview_cols = [c for c in [name_col, "ç»¼åˆè¯„åˆ†", "æ’å"] if c]
    print("âœ… è¾“å‡ºå®Œæˆ")
    print(f"å…¨éƒ¨ï¼š{all_path}")
    print(f"ä¼˜å“ï¼š{good_path}  ï¼ˆ{len(good_df)} è¡Œï¼‰")
    print(f"å¾…æ”¹è¿›ï¼š{bad_path}  ï¼ˆ{len(bad_df)} è¡Œï¼‰")
    if preview_cols:
        print("\nã€ä¼˜å“é¢„è§ˆã€‘")
        print(good_df.sort_values("ç»¼åˆè¯„åˆ†", ascending=False)[preview_cols].head(10).to_string(index=False))
        print("\nã€å¾…æ”¹è¿›é¢„è§ˆã€‘")
        print(bad_df.sort_values("ç»¼åˆè¯„åˆ†", ascending=True)[preview_cols].head(10).to_string(index=False))


if __name__ == "__main__":
    main()
