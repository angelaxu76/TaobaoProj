# jingya/cainiao_generate_excel_binding_goods_jingya.py
# -*- coding: utf-8 -*-
import re
import time
import psycopg2
import pandas as pd
from pathlib import Path
from typing import Dict, Tuple, Optional
from config import BRAND_CONFIG, PGSQL_CONFIG

# ä»…ä¿ç•™æ¨¡æ¿çš„ 6 åˆ—ï¼ˆæŒ‰ä½ è¦æ±‚çš„é¡ºåºï¼Œâ€œ*èœé¸Ÿè´§å“IDâ€æ”¾æœ€åï¼‰
TEMPLATE_COLUMNS = [
    "*é”€å”®æ¸ é“", "*æ¸ é“åº—é“ºID", "*å‘è´§æ¨¡å¼",
    "*å¤–éƒ¨æ¸ é“å•†å“ID", "*å•†å“åç§°", "*èœé¸Ÿè´§å“ID",
]

# â€”â€” å•†å“åç”Ÿæˆï¼ˆä¸ cainiao_generate_update_goods_excel ä¸€è‡´ï¼‰â€”â€”
BRAND_MAP  = {
    "clarks_jingya": "clarkså…¶ä¹",
    "camper": "camperçœ‹æ­¥",
    "clarks": "clarkså…¶ä¹",
    "ecco": "çˆ±æ­¥",
    "geox": "å¥ä¹å£«",
    "barbour": "å·´ä¼¯å°”",
}
STYLE_MAP = {
    "boots": "é´",
    "sandal": "å‡‰é‹",
    "loafers": "ä¹ç¦é‹",
    "slip-on": "ä¾¿é‹",
    "casual": "ä¼‘é—²é‹",
}
def build_product_name(brand: str, gender: str, style_en: str, product_code: str, size: str) -> str:
    brand_label = BRAND_MAP.get((brand or "").lower(), brand)
    gender_label = "ç”·é‹" if "ç”·" in (gender or "") else "å¥³é‹"
    style_zh = STYLE_MAP.get((style_en or "").lower(), "ä¼‘é—²é‹")
    # ä¸€å®šæŠŠç¼–ç ä¸å°ºç æ‹¼è¿›å»
    return f"{brand_label}{gender_label}{style_zh}{product_code}å°ºç {size}".replace("None", "")

def _clean_join(code: str, size: str) -> str:
    """ç¼–ç +å°ºç ï¼Œå»æ‰éå­—æ¯æ•°å­—å­—ç¬¦ã€‚"""
    return re.sub(r"[^A-Za-z0-9]", "", f"{str(code or '')}{str(size or '')}")

def _parse_code_size_from_any(text: str) -> Tuple[str, str]:
    """
    ä» channel_item_id æˆ–ä»»æ„å­—ç¬¦ä¸²å…œåº•è§£æ (product_code, size)ã€‚
    å…¼å®¹å¦‚ K100300-00142 / 26178475-395 / 2617847539540 ç­‰å†™æ³•ã€‚
    """
    s = str(text or "")
    # å…ˆå°è¯•ï¼šç¼–ç (å­—æ¯å¯é€‰+5ä½ä»¥ä¸Šæ•°å­—+å¯é€‰è¿æ¥ç¬¦+æœ€å¤š3ä½) + å¯é€‰å°ºç (2-3ä½)
    m = re.search(r"([A-Za-z]*\d{5,}[-_\.]?\d{0,3})(\d{2,3})?$", s)
    if m:
        code = m.group(1) or ""
        size = m.group(2) or ""
        return code, size
    # å†å°è¯•å¸¸è§ â€œç¼–ç -å°ºç  / ç¼–ç _å°ºç  / ç¼–ç .å°ºç â€
    m2 = re.search(r"([A-Za-z]*\d{5,})[-_\.]?(\d{2,3})", s)
    if m2:
        return m2.group(1) or "", m2.group(2) or ""
    return "", ""

def _fetch_maps(table: str, pgcfg: Dict):
    """
    ä¸€æ¬¡æ€§æ‹‰å–æ˜ å°„ï¼Œé¿å…é€è¡ŒæŸ¥åº“ï¼š
      - id_to_channel_item: è´§å“ID(channel_product_id) -> channel_item_idï¼›ä»¥åŠ channel_item_id -> channel_item_idï¼ˆåŒè·¯å¾„ï¼Œæœ€å¤§åŒ–å‘½ä¸­ï¼‰
      - item_to_code_size:  channel_item_id -> (product_code, size)
      - code_size_to_gender_style: (product_code, size) -> (gender, style_category)
    """
    id_to_channel_item: Dict[str, str] = {}
    item_to_code_size: Dict[str, Tuple[str, str]] = {}
    code_size_to_gender_style: Dict[Tuple[str, str], Tuple[str, str]] = {}

    conn = psycopg2.connect(**pgcfg)
    try:
        with conn.cursor() as cur:
            cur.execute(f"""
                SELECT channel_item_id, channel_product_id, product_code, size, gender, style_category
                FROM {table}
            """)
            for channel_item_id, channel_product_id, product_code, size, gender, style in cur.fetchall():
                ch_item = str(channel_item_id or "")
                ch_prod = str(channel_product_id or "")
                code = str(product_code or "")
                sz = str(size or "")
                # åŒè·¯å¾„ï¼šè´§å“IDâ†’item ä»¥åŠ itemâ†’item
                if ch_prod:
                    id_to_channel_item[ch_prod] = ch_item
                if ch_item:
                    id_to_channel_item[ch_item] = ch_item
                    item_to_code_size[ch_item] = (code, sz)
                # å‘½åæ˜ å°„
                key = (code, sz)
                if key not in code_size_to_gender_style:
                    code_size_to_gender_style[key] = (str(gender or ""), str(style or ""))
    finally:
        conn.close()

    return id_to_channel_item, item_to_code_size, code_size_to_gender_style

def generate_channel_binding_excel(brand: str, goods_dir: Path, debug: bool = True) -> Path:
    t0 = time.time()
    def log(msg):
        if debug:
            print(msg)

    brand = (brand or "").lower()
    cfg = BRAND_CONFIG[brand]
    table_name = cfg["TABLE_NAME"]
    pgcfg = cfg.get("PGSQL_CONFIG", PGSQL_CONFIG)

    log(f"â–¶ å¼€å§‹ç”Ÿæˆç»‘å®šExcel | brand={brand} | table={table_name}")
    goods_dir = Path(goods_dir)
    product_files = list(goods_dir.glob("è´§å“å¯¼å‡º*.xlsx"))
    if not product_files:
        raise FileNotFoundError("âŒ æœªæ‰¾åˆ°ä»¥ã€è´§å“å¯¼å‡ºã€å¼€å¤´çš„ Excel æ–‡ä»¶")
    product_file = product_files[0]
    relation_file = goods_dir / "å•†è´§å“å…³ç³»å¯¼å‡º.xlsx"
    log(f"âœ“ è¾“å…¥æ–‡ä»¶ï¼š{product_file}")
    log(f"âœ“ å…³ç³»æ–‡ä»¶ï¼š{relation_file}ï¼ˆå­˜åœ¨={relation_file.exists()}ï¼‰")

    # è¯»å–åŸå§‹æ•°æ®
    t = time.time()
    df_product = pd.read_excel(product_file, dtype=str)
    log(f"âœ“ è¯»å–è´§å“å¯¼å‡ºï¼š{len(df_product)} è¡Œï¼Œç”¨æ—¶ {time.time()-t:.2f}s")

    if relation_file.exists():
        t = time.time()
        df_relation = pd.read_excel(relation_file, dtype=str)
        log(f"âœ“ è¯»å–å•†è´§å“å…³ç³»ï¼š{len(df_relation)} è¡Œï¼Œç”¨æ—¶ {time.time()-t:.2f}s")
    else:
        df_relation = pd.DataFrame(columns=["èœé¸Ÿè´§å“ID"])
        log("âš  æœªæ‰¾åˆ°å•†è´§å“å…³ç³»æ–‡ä»¶ï¼Œé»˜è®¤è§†ä¸ºå…¨éƒ¨æœªç»‘å®š")

    # å·²ç»‘å®šå»é‡ï¼ˆå»æ‰åç¼€ *1ï¼‰
    if "èœé¸Ÿè´§å“ID" in df_relation.columns:
        before = df_relation["èœé¸Ÿè´§å“ID"].nunique(dropna=True)
        df_relation["èœé¸Ÿè´§å“ID"] = df_relation["èœé¸Ÿè´§å“ID"].str.replace(r"\*1$", "", regex=True)
        bound_ids = df_relation["èœé¸Ÿè´§å“ID"].dropna().unique().tolist()
        log(f"âœ“ å·²ç»‘å®šIDæ•°ï¼š{len(bound_ids)}ï¼ˆå»é‡å‰ {before}ï¼‰")
    else:
        bound_ids = []
        log("âš  å…³ç³»è¡¨æ— ã€èœé¸Ÿè´§å“IDã€åˆ—ï¼Œé»˜è®¤è§†ä¸ºå…¨éƒ¨æœªç»‘å®š")

    unbound_df = df_product[~df_product["è´§å“ID"].isin(bound_ids)].copy()
    log(f"âœ“ æœªç»‘å®šå¾…å¤„ç†ï¼š{len(unbound_df)} è¡Œ")

    # é¢„å– DB æ˜ å°„ï¼ˆä¸€æ¬¡æŸ¥è¯¢ï¼‰
    t = time.time()
    id_to_channel_item, item_to_code_size, code_size_to_gender_style = _fetch_maps(table_name, pgcfg)
    log(
        f"âœ“ DB æ˜ å°„ï¼šidâ†’item {len(id_to_channel_item)}ï¼›itemâ†’(code,size) {len(item_to_code_size)}ï¼›"
        f"(code,size)â†’(gender,style) {len(code_size_to_gender_style)}ï¼Œç”¨æ—¶ {time.time()-t:.2f}s"
    )

    # å›ºå®šåˆ—
    unbound_df["*é”€å”®æ¸ é“"] = "æ·˜åˆ†é”€"
    unbound_df["*æ¸ é“åº—é“ºID"] = "2219163936872"
    unbound_df["*å‘è´§æ¨¡å¼"] = "ç›´å‘"
    unbound_df["*èœé¸Ÿè´§å“ID"] = unbound_df["è´§å“ID"]
    log("âœ“ å·²å¡«å……å›ºå®šåˆ—ï¼š*é”€å”®æ¸ é“ / *æ¸ é“åº—é“ºID / *å‘è´§æ¨¡å¼ / *èœé¸Ÿè´§å“ID")

    # å…ˆå¾—åˆ°æ¯è¡Œçš„ channel_item_idï¼ˆå‘½ä¸­ä¸åˆ°å°±ç”¨ è´§å“ID å…œåº•ï¼‰
    unbound_df["_ch_item"] = unbound_df["è´§å“ID"].map(id_to_channel_item).fillna(unbound_df["è´§å“ID"])

    # æ˜ å°„å‡º (code,size)
    codes_sizes = unbound_df["_ch_item"].map(item_to_code_size)

    def _safe_get_code(cs):
        return cs[0] if isinstance(cs, (tuple, list)) and len(cs) == 2 and cs[0] is not None else ""

    def _safe_get_size(cs):
        return cs[1] if isinstance(cs, (tuple, list)) and len(cs) == 2 and cs[1] is not None else ""

    unbound_df["_code"] = codes_sizes.apply(_safe_get_code)
    unbound_df["_size"] = codes_sizes.apply(_safe_get_size)

    # å…œåº•ï¼šå¯¹ç¼ºå¤±çš„ï¼Œä» ch_item æ–‡æœ¬è§£æ
    mask_missing = (unbound_df["_code"] == "") | (unbound_df["_size"] == "")
    if mask_missing.any():
        parsed = unbound_df.loc[mask_missing, "_ch_item"].apply(_parse_code_size_from_any)
        unbound_df.loc[mask_missing, "_code"] = [p[0] for p in parsed]
        unbound_df.loc[mask_missing, "_size"] = [p[1] for p in parsed]

    # è§„èŒƒåŒ–ï¼šåªä¿ç•™å­—æ¯æ•°å­—
    unbound_df["_code"] = unbound_df["_code"].astype(str).str.replace(r"[^A-Za-z0-9]", "", regex=True)
    unbound_df["_size"] = unbound_df["_size"].astype(str).str.replace(r"[^A-Za-z0-9]", "", regex=True)

    # *å¤–éƒ¨æ¸ é“å•†å“IDï¼ˆvectorizedï¼‰
    unbound_df["*å¤–éƒ¨æ¸ é“å•†å“ID"] = (unbound_df["_code"] + unbound_df["_size"]).fillna("")
    null_rate = (unbound_df["*å¤–éƒ¨æ¸ é“å•†å“ID"] == "").mean()
    log(f"âœ“ ç”Ÿæˆ *å¤–éƒ¨æ¸ é“å•†å“ID å®Œæˆï¼ˆç©ºå€¼å æ¯” {null_rate:.1%}ï¼‰")

    # *å•†å“åç§°ï¼ˆvectorized + DBæ€§åˆ«/æ¬¾å¼æ˜ å°„ï¼‰
    def _name_row(row):
        code, size = row["_code"], row["_size"]
        gender, style = code_size_to_gender_style.get((code, size), ("", ""))
        return build_product_name(brand, gender, style, code, size)

    t = time.time()
    unbound_df["*å•†å“åç§°"] = unbound_df.apply(_name_row, axis=1)
    log(f"âœ“ ç”Ÿæˆ *å•†å“åç§° å®Œæˆï¼Œç”¨æ—¶ {time.time()-t:.2f}s")

    # æŒ‰ 6 åˆ—è¾“å‡º
    final_df = unbound_df.reindex(columns=TEMPLATE_COLUMNS)
    log(f"âœ“ æœ€ç»ˆåˆ—é¡ºåºï¼š{TEMPLATE_COLUMNS}")

    # ç¬¬ä¸€è¡Œæç¤º
    tip_row = {
        "*é”€å”®æ¸ é“": "å¡«å†™é”€å”®æ¸ é“åç§°ï¼Œè¯·å‚è§ä¸‹æ–¹'é”€å”®æ¸ é“å‚è€ƒ'sheetè¡¨",
        "*æ¸ é“åº—é“ºID": "å¡«å†™åº—é“ºIDï¼Œè¯·å‚ç…§ä»¥ä¸‹åœ°å€https://g.cainiao.com/infra/tao-fuwu/information",
        "*å‘è´§æ¨¡å¼": "è¯·é€‰æ‹©ç›´å‘æˆ–ä»£å‘",
        "*å¤–éƒ¨æ¸ é“å•†å“ID": "",
        "*å•†å“åç§°": "",
        "*èœé¸Ÿè´§å“ID": "",
    }
    final_df_with_tip = pd.concat(
        [pd.DataFrame([tip_row], columns=TEMPLATE_COLUMNS), final_df],
        ignore_index=True
    )

    # å†™æ–‡ä»¶
    output_file = goods_dir / "æœªç»‘å®šå•†å“ç»‘å®šä¿¡æ¯.xlsx"
    t = time.time()
    with pd.ExcelWriter(output_file, engine="openpyxl") as writer:
        final_df_with_tip.to_excel(writer, index=False, sheet_name="å•ä¸ªå•†å“ç»‘å®š")
    log(f"âœ“ å†™å…¥Excelï¼š{output_file} ç”¨æ—¶ {time.time()-t:.2f}s")
    log(f"ğŸ‰ å…¨æµç¨‹å®Œæˆï¼Œæ€»è€—æ—¶ {time.time()-t0:.2f}sï¼›æ€»è¡Œæ•°ï¼ˆå«æç¤ºè¡Œï¼‰={len(final_df_with_tip)}")
    return output_file

if __name__ == "__main__":
    # æœ¬åœ°å¿«é€Ÿæµ‹è¯•
    generate_channel_binding_excel("camper", Path("D:/TB/taofenxiao/goods"))
