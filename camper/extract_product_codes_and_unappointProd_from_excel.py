import pandas as pd
import psycopg2
from datetime import datetime

# === é…ç½® ===
input_file = r"D:\TB\taojingxiao\jingya\GEI.xlsx"
sku_column_name = "skuåç§°"
distribution_status_column = "é“ºè´§çŠ¶æ€"
channel_product_id_column = "æ¸ é“äº§å“id"
price_status_column = "ä»·æ ¼çŠ¶æ€"

output_dir = r"D:\TB\taojingxiao\jingya"
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

PGSQL_CONFIG = {
    "host": "192.168.4.55",
    "port": 5432,
    "user": "postgres",
    "password": "madding2010",
    "dbname": "camper_inventory_db"
}
TABLE_NAME = "camper_inventory"

# === æå–å•†å“ç¼–ç  ===
def extract_product_code(sku_name):
    if pd.isna(sku_name):
        return None
    return str(sku_name).split("ï¼Œ")[0].strip()

# === è·å–å•†å“æ€§åˆ« ===
def fetch_gender_map(codes):
    conn = psycopg2.connect(**PGSQL_CONFIG)
    cursor = conn.cursor()
    cursor.execute(f"""
        SELECT DISTINCT product_code, gender
        FROM {TABLE_NAME}
        WHERE product_code = ANY(%s)
    """, (codes,))
    rows = cursor.fetchall()
    conn.close()
    return {r[0]: r[1] for r in rows}

# === è·å–å°ºç åº“å­˜ ===
def fetch_inventory(codes, sizes):
    conn = psycopg2.connect(**PGSQL_CONFIG)
    cursor = conn.cursor()
    cursor.execute(f"""
        SELECT product_code, size, stock_quantity
        FROM {TABLE_NAME}
        WHERE product_code = ANY(%s) AND size = ANY(%s)
    """, (codes, sizes))
    rows = cursor.fetchall()
    conn.close()

    inventory = {}
    for product_code, size, qty in rows:
        inventory.setdefault(product_code, {})[size] = qty
    return inventory

# === è·å–å•†å“ä»·æ ¼ ===
def fetch_price_map(codes):
    conn = psycopg2.connect(**PGSQL_CONFIG)
    cursor = conn.cursor()
    cursor.execute(f"""
        SELECT DISTINCT product_code, price_gbp
        FROM {TABLE_NAME}
        WHERE product_code = ANY(%s)
    """, (codes,))
    rows = cursor.fetchall()
    conn.close()
    return {r[0]: r[1] for r in rows}

# === ä¸»ç¨‹åº ===
def main():
    df = pd.read_excel(input_file, dtype={channel_product_id_column: str})
    df["å•†å“ç¼–ç "] = df[sku_column_name].apply(extract_product_code)
    unique_codes = df["å•†å“ç¼–ç "].dropna().drop_duplicates().tolist()

    gender_map = fetch_gender_map(unique_codes)

    # åˆ†ç±»å•†å“ç¼–ç 
    groups = {"women": [], "men": []}
    for code in unique_codes:
        gender = gender_map.get(code, "unknown")
        if gender == "women":
            groups["women"].append(code)
        elif gender == "men":
            groups["men"].append(code)

    # æ¯ç±»å°ºç å®šä¹‰
    size_map = {
        "women": [str(s) for s in range(35, 43)],
        "men": [str(s) for s in range(39, 47)]
    }

    # æ¯ç±»å¯¼å‡ºåº“å­˜+ä»·æ ¼
    for gender, codes in groups.items():
        if not codes:
            continue
        sizes = size_map[gender]
        inventory = fetch_inventory(codes, sizes)
        price_map = fetch_price_map(codes)

        records = []
        for code in codes:
            row = {"product_code": code, "ä»·æ ¼": price_map.get(code, "")}
            for size in sizes:
                row[size] = inventory.get(code, {}).get(size, 0)
            records.append(row)

        df_out = pd.DataFrame(records)
        output_file = rf"{output_dir}\unique_productCodes_{gender}.xlsx"
        df_out.to_excel(output_file, index=False)
        print(f"âœ… å·²å¯¼å‡ºåº“å­˜è¡¨ï¼š{output_file}")

    # å¯¼å‡ºæœªé“ºè´§å•†å“
    unpublished_df = df[df[distribution_status_column] == "æœªé“ºè´§"]
    unpublished_output = rf"{output_dir}\unpublished_products_{timestamp}.xlsx"
    unpublished_df[[channel_product_id_column, distribution_status_column]].to_excel(unpublished_output, index=False)
    print(f"âœ… å·²å¯¼å‡ºæœªé“ºè´§å•†å“ï¼š{unpublished_output}")

    # å¯¼å‡ºä»·æ ¼æœªè®¾ç½®å•†å“
    if price_status_column in df.columns:
        missing_price_df = df[df[price_status_column] == "æœªè®¾ç½®"].copy()
        if not missing_price_df.empty:
            price_map_full = fetch_price_map(missing_price_df["å•†å“ç¼–ç "].dropna().unique().tolist())
            missing_price_df["ä»·æ ¼"] = missing_price_df["å•†å“ç¼–ç "].apply(lambda c: price_map_full.get(c, ""))
            out_df = missing_price_df[[channel_product_id_column, "å•†å“ç¼–ç ", "ä»·æ ¼"]].drop_duplicates(subset=["å•†å“ç¼–ç "])
            out_df[channel_product_id_column] = out_df[channel_product_id_column].astype(str)
            missing_output = rf"{output_dir}\products_missing_price_{timestamp}.xlsx"
            out_df.to_excel(missing_output, index=False)
            print(f"âš ï¸ å·²å¯¼å‡ºä»·æ ¼æœªè®¾ç½®å•†å“ï¼š{missing_output}")
        else:
            print("âœ… æ‰€æœ‰å•†å“éƒ½å·²è®¾ç½®ä»·æ ¼ï¼Œæ— éœ€å¯¼å‡ºç¼ºä»·è¡¨ã€‚")

    # âœ… æ›´æ–°æ•°æ®åº“ is_published çŠ¶æ€
    try:
        all_codes = df["å•†å“ç¼–ç "].dropna().unique().tolist()
        if all_codes:
            conn = psycopg2.connect(**PGSQL_CONFIG)
            cursor = conn.cursor()
            cursor.execute(f"""
                UPDATE {TABLE_NAME}
                SET is_published = TRUE
                WHERE product_code = ANY(%s)
            """, (all_codes,))
            conn.commit()
            conn.close()
            print(f"ğŸ“Œ å·²æ›´æ–°æ•°æ®åº“ä¸­ {len(all_codes)} ä¸ªå•†å“ç¼–ç çš„å‘å¸ƒçŠ¶æ€ã€‚")
        else:
            print("âš ï¸ æ— æœ‰æ•ˆå•†å“ç¼–ç ï¼Œæ— éœ€æ›´æ–°æ•°æ®åº“å‘å¸ƒçŠ¶æ€ã€‚")
    except Exception as e:
        print(f"âŒ æ•°æ®åº“ is_published æ›´æ–°å¤±è´¥: {e}")

if __name__ == "__main__":
    main()
