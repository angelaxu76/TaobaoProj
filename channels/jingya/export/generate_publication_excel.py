import os
import re
import shutil
import pandas as pd
from sqlalchemy import create_engine
from config import BRAND_CONFIG, SETTINGS
from common_taobao.core.price_utils import calculate_jingya_prices
from common_taobao.text.generate_taobao_title_v1 import generate_taobao_title

# ==== å›ºå®šå‚æ•° ====
ä¸Šå¸‚å­£èŠ‚ = "2025æ˜¥å­£"
å­£èŠ‚ = "æ˜¥ç§‹"
æ¬¾å¼ = "ä¼‘é—²"
é—­åˆæ–¹å¼ = ""
è·Ÿåº•æ¬¾å¼ = "å¹³åº•"
å¼€å£æ·±åº¦ = "æµ…å£"
é‹å¤´æ¬¾å¼ = "åœ†å¤´"
åœ°åŒºå›½å®¶ = "è‹±å›½"
å‘è´§æ—¶é—´ = "7"
è¿è´¹æ¨¡ç‰ˆ = "parcelforce"
ç¬¬ä¸€è®¡é‡å•ä½ = "1"
ç¬¬äºŒè®¡é‡å•ä½ = "1"
é”€å”®å•ä½ = "åŒ"
å“å = "é‹"
æµ·å…³æ¬¾å¼ = "ä¼‘é—²é‹"
å¤–åº•ææ–™ = "EVA"
å†…åº•é•¿åº¦ = "27"

# æ¡ä»¶å‚æ•°ï¼ˆå¯è°ƒï¼‰
MIN_SIZES = 4         # æœ€å°‘å°ºç æ•°é‡
MIN_TOTAL_STOCK = 20  # æœ€å°‘æ€»åº“å­˜



def extract_field(name, content):
    pattern = re.compile(rf"{name}\s*[:ï¼š]\s*(.+)", re.IGNORECASE)
    match = pattern.search(content)
    return match.group(1).strip() if match else ""

def get_category_v2(title: str, content: str, heel_height: str) -> str:
    t = title.lower()
    c = content.lower()
    if any(k in t for k in ["boot", "ankle", "chelsea"]):
        return "é´å­"
    if any(k in t for k in ["sandal", "slide", "slipper", "mule", "flip-flop"]):
        return "å‡‰é‹æ‹–é‹"
    if heel_height in ["é«˜è·Ÿ(5-8cm)", "ä¸­è·Ÿ(3-5cm)"]:
        return "å…¶ä»–ä¼‘é—²é‹"
    return "å…¶ä»–ä¼‘é—²é‹"

def generate_publication_excels(brand: str):
    brand = brand.lower()
    if brand not in BRAND_CONFIG:
        raise ValueError(f"âŒ ä¸æ”¯æŒçš„å“ç‰Œ: {brand}")

    if brand == "clarks_jingya":
        MIN_TOTAL_STOCK = 11
    elif brand == "camper":
        MIN_TOTAL_STOCK = 35
    elif brand == "geox":
        MIN_TOTAL_STOCK = 11
    else:
        MIN_TOTAL_STOCK = 11  # å…œåº•é»˜è®¤å€¼

    config = BRAND_CONFIG[brand]
    txt_folder = config["TXT_DIR"]
    output_base = config["OUTPUT_DIR"] / "publication_excels"
    image_src_dir = config["IMAGE_DIR"]
    image_dst_dir = output_base / "images"
    pg_cfg = config["PGSQL_CONFIG"]
    å“ç‰Œ = brand

    # ==== è¿æ¥æ•°æ®åº“ ====
    print(f"\nğŸ”Œ æ­£åœ¨è¿æ¥æ•°æ®åº“ï¼Œå“ç‰Œï¼š{brand.upper()}...")
    engine = create_engine(
        f"postgresql+psycopg2://{pg_cfg['user']}:{pg_cfg['password']}@{pg_cfg['host']}:{pg_cfg['port']}/{pg_cfg['dbname']}"
    )

    print("\nğŸ“Š æ­£åœ¨æŸ¥è¯¢ç¬¦åˆæ¡ä»¶çš„å•†å“...")
    query = f"""
    WITH size_counts AS (
        SELECT product_code,
               COUNT(*) AS available_sizes,
               SUM(stock_count) AS total_stock
        FROM {config['TABLE_NAME']}
        WHERE stock_count > 1
        GROUP BY product_code
    ),
    publish_status AS (
        SELECT product_code,
               BOOL_OR(is_published) AS any_published
        FROM {config['TABLE_NAME']}
        GROUP BY product_code
    )
    SELECT DISTINCT ci.product_code,
           ci.original_price_gbp,
           ci.discount_price_gbp
    FROM {config['TABLE_NAME']} ci
    JOIN size_counts sc ON ci.product_code = sc.product_code
    JOIN publish_status ps ON ci.product_code = ps.product_code
    WHERE ps.any_published = FALSE
      AND sc.available_sizes >= {MIN_SIZES}
      AND sc.total_stock > {MIN_TOTAL_STOCK}
    """
    df_codes = pd.read_sql(query, engine)
    product_codes = df_codes["product_code"].tolist()
    print(f"âœ… è·å–åˆ°å•†å“æ•°: {len(product_codes)}")

    if not product_codes:
        print("âš ï¸ æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„å•†å“ï¼Œä»»åŠ¡ç»“æŸ")
        return

    # === æ–°å¢ï¼šæ£€æµ‹é‡å¤ product_code å¹¶æ‰“å°å‡ºæ¥ ===
    dup_codes = df_codes[df_codes.duplicated(subset="product_code", keep=False)]

    if not dup_codes.empty:
        print("\nâ—â— æ£€æµ‹åˆ°é‡å¤çš„å•†å“ç¼–ç ï¼ˆå¯¼è‡´ set_index å¤±è´¥ï¼‰:")
        for c in sorted(dup_codes["product_code"].unique()):
            print(f"   âš  é‡å¤ç¼–ç : {c}")
            print(dup_codes[dup_codes["product_code"] == c])
        print("â— è¯·æ£€æŸ¥ä»¥ä¸Šç¼–ç çš„ TXT æˆ–æ•°æ®åº“è®°å½•ã€‚")

    # === ä¿®å¤ï¼šè‡ªåŠ¨å»é‡ï¼Œä¿ç•™æ¯ä¸ªç¼–ç ä¸€è¡Œ ===
    df_codes_unique = (
        df_codes
        .sort_values(["product_code", "discount_price_gbp", "original_price_gbp"])
        .drop_duplicates(subset="product_code", keep="last")
    )

    # === åŸæ¥çš„ä»£ç  ===
    price_map = df_codes_unique.set_index("product_code")[["original_price_gbp", "discount_price_gbp"]].to_dict("index")




    gender_map = {
        k.strip().upper(): v for k, v in
        pd.read_sql(f"SELECT DISTINCT product_code, gender FROM {config['TABLE_NAME']}", engine)
        .dropna()
        .values
    }

    rows = []
    print("\nğŸ“¦ æ­£åœ¨è¯»å– TXT å¹¶ç”Ÿæˆå•†å“è¡Œæ•°æ®...")
    for idx, code in enumerate(product_codes, 1):
        code_clean = code.strip().upper()
        txt_path = txt_folder / f"{code_clean}.txt"
        if not txt_path.exists():
            print(f"âŒ ç¼ºå°‘ TXT æ–‡ä»¶: {txt_path}")
            continue

        with open(txt_path, 'r', encoding='utf-8') as f:
            content = f.read()

        title_en = extract_field("Product Name", content)
        title_cn = generate_taobao_title(code, content, brand)["taobao_title"]

        print(f"[{code_clean}] EN: {title_en} â†’ CN: {title_cn}")

        price_info = price_map.get(code, {"original_price_gbp": 0, "discount_price_gbp": 0})
        original = price_info.get("original_price_gbp", 0) or 0
        discount = price_info.get("discount_price_gbp", 0) or 0

        # è¿‡æ»¤æ‰ä¸º0çš„ä»·æ ¼
        valid_prices = [p for p in [original, discount] if p > 0]

        # å¦‚æœæœ‰æœ‰æ•ˆä»·æ ¼ï¼Œå–æœ€å°çš„é‚£ä¸ªï¼Œå¦åˆ™ä¸º0
        final_price = min(valid_prices) if valid_prices else 0

        try:
            _, rmb_price = calculate_jingya_prices(final_price, delivery_cost=7,exchange_rate=SETTINGS["EXCHANGE_RATE"])
        except:
            rmb_price = ""

        lining_info = content.lower()
        upper_info = content.lower()

        lining_material = "å¤´å±‚ç‰›çš®" if "leather" in lining_info else ("ç»‡ç‰©" if "recycled polyester" in lining_info else "")
        upper_material = "ç‰›çš®é©" if "leather" in upper_info else ("ç»‡ç‰©" if "recycled polyester" in upper_info else "")

        hscode = "6403990090" if 'upper' in content.lower() and 'leather' in upper_info else "6405200090"

        match = re.search(r'Height[:ï¼š]?\s*(\d+\.?\d*)', content)
        if match:
            height = float(match.group(1))
            heel_height = "é«˜è·Ÿ(5-8cm)" if height > 5 else "ä¸­è·Ÿ(3-5cm)" if height >= 3 else "ä½è·Ÿ(1-3cm)"
        else:
            heel_height = ""

        row = {
            "è‹±æ–‡æ ‡é¢˜": title_en,
            "æ ‡é¢˜": title_cn,
            "å•†å“ç¼–ç ": code,
            "ä»·æ ¼": rmb_price,
            "å†…é‡Œæè´¨": lining_material,
            "å¸®é¢æè´¨": upper_material,
            "ä¸Šå¸‚å­£èŠ‚": ä¸Šå¸‚å­£èŠ‚,
            "å­£èŠ‚": å­£èŠ‚,
            "æ¬¾å¼": æ¬¾å¼,
            "é—­åˆæ–¹å¼": é—­åˆæ–¹å¼,
            "è·Ÿåº•æ¬¾å¼": è·Ÿåº•æ¬¾å¼,
            "å¼€å£æ·±åº¦": å¼€å£æ·±åº¦,
            "åè·Ÿé«˜": heel_height,
            "é‹å¤´æ¬¾å¼": é‹å¤´æ¬¾å¼,
            "åœ°åŒºå›½å®¶": åœ°åŒºå›½å®¶,
            "å‘è´§æ—¶é—´": å‘è´§æ—¶é—´,
            "è¿è´¹æ¨¡ç‰ˆ": è¿è´¹æ¨¡ç‰ˆ,
            "HSCODE": hscode,
            "ç¬¬ä¸€è®¡é‡å•ä½": ç¬¬ä¸€è®¡é‡å•ä½,
            "ç¬¬äºŒè®¡é‡å•ä½": ç¬¬äºŒè®¡é‡å•ä½,
            "é”€å”®å•ä½": é”€å”®å•ä½,
            "å“å": å“å,
            "æµ·å…³æ¬¾å¼": æµ·å…³æ¬¾å¼,
            "å¤–åº•ææ–™": å¤–åº•ææ–™,
            "å†…åº•é•¿åº¦": å†…åº•é•¿åº¦,
            "å“ç‰Œ": å“ç‰Œ,
            "æ€§åˆ«": gender_map.get(code_clean, "ç”·æ¬¾"),
            "ç±»ç›®": get_category_v2(title_en, content, heel_height)
        }
        rows.append(row)

    df_all = pd.DataFrame(rows)
    if df_all.empty:
        print("âš ï¸ æ²¡æœ‰å¯ç”Ÿæˆçš„æ•°æ®")
        return

    print("\nğŸ“Š åˆ†ç±»ç»Ÿè®¡ï¼š")
    print(df_all.groupby(["æ€§åˆ«", "ç±»ç›®"]).size())

    os.makedirs(output_base, exist_ok=True)
    print("\nğŸ“¤ æ­£åœ¨å¯¼å‡º Excel æ–‡ä»¶...")
    for (gender, category), sub_df in df_all.groupby(["æ€§åˆ«", "ç±»ç›®"]):
        out_file = output_base / f"{brand}_{gender}_{category}.xlsx"
        if out_file.exists():
            out_file.unlink()
        sub_df.drop(columns=["æ€§åˆ«", "ç±»ç›®"]).to_excel(out_file, index=False)
        print(f"âœ… å¯¼å‡ºï¼š{out_file}")

    # æ‹·è´å›¾ç‰‡
    # æ‹·è´å›¾ç‰‡
    image_dst_dir.mkdir(parents=True, exist_ok=True)
    print("\nğŸ–¼ï¸ æ­£åœ¨å¤åˆ¶å•†å“å›¾ç‰‡...")
    missing_codes = []  # <== æ–°å¢ï¼šæ”¶é›†ç¼ºå›¾ç¼–ç 
    for code in product_codes:
        code_clean = code.strip().upper()
        matched_images = list(image_src_dir.glob(f"{code_clean}*.jpg"))
        if not matched_images:
            print(f"âš ï¸ æœªæ‰¾åˆ°å›¾ç‰‡: {code_clean}")
            missing_codes.append(code_clean)   # <== è®°å½•ç¼ºå›¾ç¼–ç 
            continue
        for img_path in matched_images:
            shutil.copy(img_path, image_dst_dir / img_path.name)

    # === æ–°å¢ï¼šå†™å‡º publication_codes.txt ä¸ missing_codes.txt ===
        # === æ–°å¢ï¼šå†™å‡º publication_codes.txt ä¸ missing_codes.txt ===
    pub_codes_file = config["OUTPUT_DIR"] / "publication_codes.txt"
    miss_codes_file = config["OUTPUT_DIR"] / "missing_codes.txt"

    # æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„å•†å“ç¼–ç 
    with open(pub_codes_file, "w", encoding="utf-8") as f:
        for code in sorted(set(product_codes)):
            f.write(f"{code}\n")
    print(f"ğŸ“ å·²å†™å‡ºå•†å“ç¼–ç åˆ—è¡¨: {pub_codes_file} ({len(product_codes)} ä¸ª)")

    # ç¼ºå›¾çš„ç¼–ç 
    with open(miss_codes_file, "w", encoding="utf-8") as f:
        for code in sorted(set(missing_codes)):
            f.write(f"{code}\n")
    print(f"ğŸ“ å·²å†™å‡ºç¼ºå›¾ç¼–ç åˆ—è¡¨: {miss_codes_file} ({len(missing_codes)} ä¸ª)")



    print("\nâœ… æ‰€æœ‰æ“ä½œå®Œæˆã€‚")

