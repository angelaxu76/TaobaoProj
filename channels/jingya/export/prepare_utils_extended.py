# -*- coding: utf-8 -*-
"""
prepare_utils_extended.py  â€”â€” å‘å¸ƒç”¨ Excel ç”Ÿæˆå™¨ï¼ˆå·²å¯¹æ¥â€œæœ€æ–°æ ‡é¢˜&ä»·æ ¼è„šæœ¬â€ï¼‰
- æ ‡é¢˜ï¼šä½¿ç”¨ generate_taobao_title.generate_taobao_title()
- ä»·æ ¼ï¼šä½¿ç”¨æœ¬åœ° price_utils.calculate_discount_price()
- å…¶ä½™ï¼šå»¶ç»­åŸæœ‰æ•°æ®æµã€åˆ†ç»„å¯¼å‡ºä¸å›¾ç‰‡æ‹·è´é€»è¾‘
"""

import pandas as pd
import shutil
import psycopg2

# ===== ä½ åŸæœ‰çš„å…¬å…±å‡½æ•°ï¼ˆä¿ç•™ï¼‰ =====
from common.core.translate import safe_translate
from common.core.txt_parser import extract_product_info
from common.core.image_utils import copy_images_by_code

# ===== æ›¿æ¢ä¸ºä½ çš„â€œæœ€æ–°â€è„šæœ¬ =====
from common.core.price_utils import calculate_discount_price            # æœ€æ–°ä»·æ ¼è®¡ç®—ï¼ˆæœ¬åœ°æ–‡ä»¶ï¼‰
from common.text.generate_taobao_title import generate_taobao_title     # æœ€æ–°æ·˜å®æ ‡é¢˜ï¼ˆæœ¬åœ°æ–‡ä»¶ï¼‰


def get_publishable_product_codes(config: dict, store_name: str) -> list:
    """
    ä»æ•°æ®åº“ç­›é€‰å‡ºè¯¥åº—é“ºæœªå‘å¸ƒè¿‡ã€ä¸” TXT ä¸­ â€œ:æœ‰è´§â€ å°ºç æ•°é‡ >=3 çš„å•†å“ç¼–ç 
    """
    conn = psycopg2.connect(**config["PGSQL_CONFIG"])
    table_name = config["TABLE_NAME"]
    txt_dir = config["TXT_DIR"]

    query = f"""
        SELECT product_code
        FROM {table_name}
        WHERE stock_name = %s AND is_published = FALSE
        GROUP BY product_code
        HAVING COUNT(*) = COUNT(*)
            AND product_code NOT IN (
                SELECT DISTINCT product_code FROM {table_name}
                WHERE stock_name = %s AND is_published = TRUE
            )
    """
    df = pd.read_sql(query, conn, params=(store_name, store_name))
    candidate_codes = df["product_code"].unique().tolist()

    def has_3_or_more_instock(code):
        try:
            txt_path = txt_dir / f"{code}.txt"
            if not txt_path.exists():
                return False
            lines = txt_path.read_text(encoding="utf-8").splitlines()
            size_line = next((line for line in lines if line.startswith("Product Size:")), "")
            return size_line.count(":æœ‰è´§") >= 3
        except Exception:
            return False

    result = [code for code in candidate_codes if has_3_or_more_instock(code)]
    print(f"ğŸŸ¢ åº—é“ºã€{store_name}ã€‘å¾…å‘å¸ƒå•†å“æ•°: {len(result)}")
    return result


def generate_product_excels(config: dict, store_name: str):
    """
    ä¸ºæŒ‡å®šåº—é“ºè¾“å‡ºå¤šä¸ª Excelï¼ˆæŒ‰ gender + category åˆ†æ–‡ä»¶ï¼‰ï¼Œ
    å¹¶å°†å¯¹åº”ç¼–ç å›¾ç‰‡æ‹·è´åˆ°åº—é“ºå‘å¸ƒç›®å½•çš„ images/ ä¸‹ã€‚
    """
    from openpyxl import Workbook

    txt_dir = config["TXT_DIR"]
    output_dir = config["OUTPUT_DIR"] / store_name
    output_dir.mkdir(parents=True, exist_ok=True)
    image_dir = config["IMAGE_DIR"]
    image_output_dir = output_dir / "images"
    image_output_dir.mkdir(parents=True, exist_ok=True)

    codes = get_publishable_product_codes(config, store_name)
    if not codes:
        print("âš ï¸ æ²¡æœ‰å¯å‘å¸ƒå•†å“")
        return

    # ä»æ•°æ®åº“è·å– gender + è‹±é•‘ä»·æ ¼ï¼ˆåŸä»·/æŠ˜æ‰£ä»·ï¼‰ï¼Œå†™å…¥ info ä¾›ä»·æ ¼å‡½æ•°è®¡ç®—
    conn = psycopg2.connect(**config["PGSQL_CONFIG"])
    table = config["TABLE_NAME"]
    query = f"""
        SELECT product_code, gender, original_price_gbp, discount_price_gbp
        FROM {table}
        WHERE stock_name = %s
    """
    df_price = pd.read_sql(query, conn, params=(store_name,))
    price_map = {
        row["product_code"]: {
            "gender": row["gender"],
            "Price": row["original_price_gbp"],
            "AdjustedPrice": row["discount_price_gbp"]
        }
        for _, row in df_price.iterrows()
    }

    brand_key = (config.get("BRAND") or config.get("brand") or table).lower()

    records = []
    for code in codes:
        # 1) æ±‡é›† TXT ä¿¡æ¯ + DB ä»·æ ¼å­—æ®µ
        info = extract_product_info(txt_dir / f"{code}.txt")
        info.update(price_map.get(code, {}))

        gender = (info.get("gender") or "unknown").lower()
        eng_title = info.get("Product Name", "No Data")
        desc = info.get("Product Description", "")
        upper = (
            info.get("Upper Material")
            or info.get("Product Material")
            or info.get("upper material")
            or info.get("Material")
            or "No Data"
        )

        color = info.get("Product Color", info.get("color", ""))

        # 2) è®¡ç®—ä»·æ ¼ï¼ˆèµ°ä½ æœ€æ–°è§„åˆ™ï¼‰
        price = calculate_discount_price(info)  # ä¼˜å…ˆ AdjustedPriceï¼ŒæŒ‰ä½ ç°è¡Œå…¬å¼/æ¡£ä½+è¿›ä½

        # 3) ç”Ÿæˆæ·˜å®æ ‡é¢˜ï¼ˆèµ°ä½ æœ€æ–°è§„åˆ™ï¼‰
        #    æŒ‰ä½ çš„ title è§£ææ–¹å¼ï¼Œæ‹¼æ¥ content è®©å…¶å†…éƒ¨æŠ½å–å­—æ®µ
        content_lines = []
        for k in ["Product Name", "Product Description", "Product Material", "Product Color", "Product Gender"]:
            v = (info.get(k) or "").strip()
            if v:
                content_lines.append(f"{k}: {v}")
        content = "\n".join(content_lines) if content_lines else ""

        title_dict = generate_taobao_title(product_code=code, content=content, brand_key=brand_key)
        cn_title = title_dict.get("taobao_title") or title_dict.get("title_cn")

        # å›é€€ï¼šè‹¥å¼‚å¸¸æˆ–ç©ºå€¼ï¼Œç”¨æœºç¿»è‹±æ–‡åå…œåº•
        if not cn_title:
            cn_title = safe_translate(eng_title)

        # 4) åˆ†ç±»ï¼ˆè½»ä¿®ï¼šé¿å…æ­¤å‰ "boots""chelsea" æ‹¼æ¥ bugï¼‰
        category = classify_shoe(f"{eng_title} {desc}")

        # 5) ç´¯ç§¯è®°å½• + å›¾ç‰‡æ‹·è´
        records.append({
            "gender": gender,
            "category": category,
            "å•†å“åç§°": cn_title,
            "å•†å“ç¼–ç ": code,
            "ä»·æ ¼": price,
            "upper material": upper,
            "è‹±æ–‡åç§°": eng_title
        })
        copy_images_by_code(code, image_dir, image_output_dir)

    # 6) å¯¼å‡ºå¤šä¸ª Excelï¼ˆæŒ‰ gender+category åˆ†æ–‡ä»¶ï¼‰
    df = pd.DataFrame(records)
    df = df[["å•†å“åç§°", "å•†å“ç¼–ç ", "ä»·æ ¼", "upper material", "è‹±æ–‡åç§°", "gender", "category"]]

    from collections import defaultdict
    group_map = defaultdict(list)
    for rec in records:
        group_map[(rec["gender"], rec["category"])].append(rec["å•†å“ç¼–ç "])

    for (gen, cat), code_list in group_map.items():
        part = df[df["å•†å“ç¼–ç "].isin(code_list)].drop(columns=["gender", "category"])
        if not part.empty:
            wb = Workbook()
            ws = wb.active
            ws.title = "å•†å“å‘å¸ƒ"
            ws.append(part.columns.tolist())
            for row in part.itertuples(index=False):
                ws.append(row)
            save_path = output_dir / f"{gen}-{cat}.xlsx"
            wb.save(save_path)
            print(f"âœ… å·²å¯¼å‡º: {save_path.name}")


def classify_shoe(text: str):
    """
    ç®€å•é‹ç±»åˆ†ç±»ï¼šé´å­ / å‡‰é‹ / å…¶ä»–
    """
    text = (text or "").lower()
    if any(k in text for k in ["boot", "boots", "chelsea", "ankle", "chukka"]):
        return "é´å­"
    elif any(k in text for k in ["sandal", "sandals", "slide", "å‡‰é‹", "open toe", "slipper", "mule"]):
        return "å‡‰é‹"
    else:
        return "å…¶ä»–"


def copy_images_for_store(config: dict, store_name: str, code_list: list):
    """
    å°†æŒ‡å®šç¼–ç çš„æ‰€æœ‰å›¾ç‰‡ä»å…±äº«ç›®å½•å¤åˆ¶åˆ°åº—é“ºå‘å¸ƒç›®å½•ä¸‹çš„ images æ–‡ä»¶å¤¹ä¸­ã€‚
    å¦‚æœæŸä¸ªç¼–ç æ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•å›¾ç‰‡ï¼Œåˆ™è®°å½•åˆ° missing_images.txtã€‚
    """
    src_dir = config["IMAGE_DIR"]
    dst_dir = config["OUTPUT_DIR"] / store_name / "images"
    dst_dir.mkdir(parents=True, exist_ok=True)

    missing_file = config["OUTPUT_DIR"] / store_name / "missing_images.txt"
    missing_file.parent.mkdir(parents=True, exist_ok=True)
    missing_codes = []

    copied_count = 0
    for code in code_list:
        matched = False
        for img in src_dir.glob(f"*{code}*.jpg"):
            shutil.copy(img, dst_dir / img.name)
            copied_count += 1
            matched = True
        if not matched:
            missing_codes.append(code)

    if missing_codes:
        with open(missing_file, "w", encoding="utf-8") as f:
            for code in missing_codes:
                f.write(code + "\n")
        print(f"âš ï¸ ç¼ºå›¾å•†å“ç¼–ç å·²è®°å½•: {missing_file}ï¼ˆå…± {len(missing_codes)} æ¡ï¼‰")

    print(f"âœ… å›¾ç‰‡æ‹·è´å®Œæˆï¼Œå…±å¤åˆ¶ {copied_count} å¼ å›¾ â†’ {dst_dir}")


def get_publishable_codes_for_supplier(config: dict) -> list:
    conn = psycopg2.connect(**config["PGSQL_CONFIG"])
    table = config["TABLE_NAME"]
    txt_dir = Path(config["TXT_DIR"])

    # 1. æ•°æ®åº“å±‚é¢ç­›é€‰ï¼šæœªå‘å¸ƒã€ç”·å¥³æ¬¾ã€æœ‰è´§å°ºç  â‰¥4ã€æ€»åº“å­˜ >30
    query = f"""
        SELECT product_code
        FROM {table}
        WHERE gender IN ('ç”·æ¬¾', 'å¥³æ¬¾')
          AND is_published = FALSE
          AND stock_count > 0
        GROUP BY product_code
        HAVING COUNT(DISTINCT size) >= 4
           AND SUM(stock_count) > 30
    """
    df = pd.read_sql(query, conn)
    conn.close()
    candidate_codes = df["product_code"].unique().tolist()

    # 2. TXT æ–‡ä»¶æ ¡éªŒï¼šè‡³å°‘æœ‰ 4 ä¸ª ":æœ‰è´§"
    def txt_has_4_sizes(code: str) -> bool:
        txt_path = txt_dir / f"{code}.txt"
        if not txt_path.exists():
            return False
        try:
            lines = txt_path.read_text(encoding="utf-8").splitlines()
            size_line = next((line for line in lines if line.startswith("Product Size:")), "")
            return size_line.count(":æœ‰è´§") >= 4
        except:
            return False

    valid_codes = [code for code in candidate_codes if txt_has_4_sizes(code)]

    print(f"ğŸŸ¢ Camper ä¾›è´§å•†æ¨¡å¼ä¸‹å¯å‘å¸ƒå•†å“æ•°é‡ï¼š{len(valid_codes)}")
    return valid_codes
