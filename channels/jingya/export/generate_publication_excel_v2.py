# -*- coding: utf-8 -*-
import os
import re
import shutil
import pandas as pd
from sqlalchemy import create_engine

# âœ… ä»ç„¶å…¼å®¹è€ä»£ç çš„ import æ–¹å¼ï¼Œä½†å®é™…æ¥æºæ˜¯æ‹†åˆ†åçš„ config/*
from config import (
    BRAND_CONFIG,
    SETTINGS,
    EXCEL_CONSTANTS_BASE,
    EXCEL_CONSTANTS_BY_BRAND,
    PUBLISH_RULES_BASE,
    PUBLISH_RULES_BY_BRAND,
)

from common.pricing.price_utils import calculate_jingya_prices
from common.text.generate_taobao_title import generate_taobao_title


def extract_field(name, content):
    pattern = re.compile(rf"{name}\s*[:ï¼š]\s*(.+)", re.IGNORECASE)
    match = pattern.search(content)
    return match.group(1).strip() if match else ""


def get_category_v2(title: str, content: str, heel_height: str) -> str:
    t = title.lower()
    if any(k in t for k in ["boot", "ankle", "chelsea"]):
        return "é´å­"
    if any(k in t for k in ["sandal", "slide", "slipper", "mule", "flip-flop"]):
        return "å‡‰é‹æ‹–é‹"
    if heel_height in ["é«˜è·Ÿ(5-8cm)", "ä¸­è·Ÿ(3-5cm)"]:
        return "å…¶ä»–ä¼‘é—²é‹"
    return "å…¶ä»–ä¼‘é—²é‹"


def generate_publication_excels(brand: str):
    brand = brand.lower()
    if brand not in BRAND_CONFIG:
        raise ValueError(f"âŒ ä¸æ”¯æŒçš„å“ç‰Œ: {brand}")

    # ===== V2: å‘å¸ƒè§„åˆ™ï¼ˆé˜ˆå€¼ï¼‰æ¥è‡ª publish_config =====
    publish_rules = {
        **PUBLISH_RULES_BASE,
        **PUBLISH_RULES_BY_BRAND.get(brand, {}),
    }
    MIN_SIZES = int(publish_rules["MIN_SIZES"])
    MIN_TOTAL_STOCK = int(publish_rules["MIN_TOTAL_STOCK"])

    # ===== V2: Excel å›ºå®šå­—æ®µæ¥è‡ª publish_configï¼ˆå¯æŒ‰å“ç‰Œè¦†ç›–ï¼‰=====
    excel_constants = {
        **EXCEL_CONSTANTS_BASE,
        **EXCEL_CONSTANTS_BY_BRAND.get(brand, {}),
    }

    config = BRAND_CONFIG[brand]
    txt_folder = config["TXT_DIR"]
    output_base = config["OUTPUT_DIR"] / "publication_excels"
    image_src_dir = config["IMAGE_DIR"]
    image_dst_dir = output_base / "images"
    pg_cfg = config["PGSQL_CONFIG"]
    å“ç‰Œ = brand

    # ==== è¿æ¥æ•°æ®åº“ ====
    print(f"\nğŸ”Œ æ­£åœ¨è¿æ¥æ•°æ®åº“ï¼Œå“ç‰Œï¼š{brand.upper()}...")
    engine = create_engine(
        f"postgresql+psycopg2://{pg_cfg['user']}:{pg_cfg['password']}@{pg_cfg['host']}:{pg_cfg['port']}/{pg_cfg['dbname']}"
    )

    print("\nğŸ“Š æ­£åœ¨æŸ¥è¯¢ç¬¦åˆæ¡ä»¶çš„å•†å“...")
    query = f"""
    WITH size_counts AS (
        SELECT product_code,
               COUNT(*) AS available_sizes,
               SUM(stock_count) AS total_stock
        FROM {config['TABLE_NAME']}
        WHERE stock_count > 1
        GROUP BY product_code
    ),
    publish_status AS (
        SELECT product_code,
               BOOL_OR(is_published) AS any_published
        FROM {config['TABLE_NAME']}
        GROUP BY product_code
    )
    SELECT DISTINCT ci.product_code,
           ci.original_price_gbp,
           ci.discount_price_gbp
    FROM {config['TABLE_NAME']} ci
    JOIN size_counts sc ON ci.product_code = sc.product_code
    JOIN publish_status ps ON ci.product_code = ps.product_code
    WHERE ps.any_published = FALSE
      AND sc.available_sizes >= {MIN_SIZES}
      AND sc.total_stock > {MIN_TOTAL_STOCK}
    """
    df_codes = pd.read_sql(query, engine)

    # ç»Ÿä¸€æ¸…æ´—ç¼–ç ï¼Œé¿å…åé¢æ˜ å°„ miss
    df_codes["product_code"] = df_codes["product_code"].astype(str).str.strip().str.upper()

    product_codes = df_codes["product_code"].tolist()
    print(f"âœ… è·å–åˆ°å•†å“æ•°: {len(product_codes)}")

    if not product_codes:
        print("âš ï¸ æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„å•†å“ï¼Œä»»åŠ¡ç»“æŸ")
        return

    # === æ£€æµ‹é‡å¤ product_codeï¼ˆä¾¿äºæ’é”™ï¼‰===
    dup_codes = df_codes[df_codes.duplicated(subset="product_code", keep=False)]
    if not dup_codes.empty:
        print("\nâ—â— æ£€æµ‹åˆ°é‡å¤çš„å•†å“ç¼–ç ï¼ˆå¯èƒ½å¯¼è‡´æ˜ å°„å¼‚å¸¸ï¼‰:")
        for c in sorted(dup_codes["product_code"].unique()):
            print(f"   âš  é‡å¤ç¼–ç : {c}")
            print(dup_codes[dup_codes["product_code"] == c])
        print("â— å»ºè®®æ£€æŸ¥æ•°æ®åº“è®°å½•æˆ– TXT æ–‡ä»¶æ˜¯å¦é‡å¤ã€‚")

    # å»é‡ï¼šä¿ç•™æ¯ä¸ªç¼–ç ä¸€è¡Œï¼ˆé€‰æ‹©ä»·æ ¼æ›´â€œåˆç†â€çš„è¡Œï¼‰
    df_codes_unique = (
        df_codes
        .sort_values(["product_code", "discount_price_gbp", "original_price_gbp"])
        .drop_duplicates(subset="product_code", keep="last")
    )

    # price_map: key ä¸€å¾‹ç”¨å¤§å†™æ¸…æ´—åçš„ product_code
    price_map = df_codes_unique.set_index("product_code")[["original_price_gbp", "discount_price_gbp"]].to_dict("index")

    # gender_map
    gender_df = pd.read_sql(
        f"SELECT DISTINCT product_code, gender FROM {config['TABLE_NAME']}",
        engine
    ).dropna()
    gender_df["product_code"] = gender_df["product_code"].astype(str).str.strip().str.upper()
    gender_map = {k: v for k, v in gender_df.values}

    rows = []
    print("\nğŸ“¦ æ­£åœ¨è¯»å– TXT å¹¶ç”Ÿæˆå•†å“è¡Œæ•°æ®...")

    for idx, code_clean in enumerate(product_codes, 1):
        txt_path = txt_folder / f"{code_clean}.txt"
        if not txt_path.exists():
            print(f"âŒ ç¼ºå°‘ TXT æ–‡ä»¶: {txt_path}")
            continue

        with open(txt_path, 'r', encoding='utf-8') as f:
            content = f.read()

        title_en = extract_field("Product Name", content)
        title_cn = generate_taobao_title(code_clean, content, brand)["taobao_title"]
        print(f"[{code_clean}] EN: {title_en} â†’ CN: {title_cn}")

        price_info = price_map.get(code_clean, {"original_price_gbp": 0, "discount_price_gbp": 0})
        original = price_info.get("original_price_gbp", 0) or 0
        discount = price_info.get("discount_price_gbp", 0) or 0

        # è¿‡æ»¤æ‰ä¸º0çš„ä»·æ ¼
        valid_prices = [p for p in [original, discount] if p > 0]
        final_price = min(valid_prices) if valid_prices else 0

        try:
            _, rmb_price = calculate_jingya_prices(
                final_price,
                delivery_cost=7,
                exchange_rate=SETTINGS["EXCHANGE_RATE"]
            )
        except Exception:
            rmb_price = ""

        # æè´¨ï¼ˆç¤ºä¾‹é€»è¾‘ï¼šä½ ä»¥åå¯ä»¥åšå¾—æ›´ç»†ï¼‰
        content_lower = content.lower()
        lining_material = "å¤´å±‚ç‰›çš®" if "leather" in content_lower else ("ç»‡ç‰©" if "recycled polyester" in content_lower else "")
        upper_material = "ç‰›çš®é©" if "leather" in content_lower else ("ç»‡ç‰©" if "recycled polyester" in content_lower else "")

        # HS codeï¼ˆä¿ç•™ä½ å½“å‰é€»è¾‘ï¼‰
        hscode = "6403990090" if ("upper" in content_lower and "leather" in content_lower) else "6405200090"

        # åè·Ÿé«˜
        match = re.search(r'Height[:ï¼š]?\s*(\d+\.?\d*)', content)
        if match:
            height = float(match.group(1))
            heel_height = "é«˜è·Ÿ(5-8cm)" if height > 5 else "ä¸­è·Ÿ(3-5cm)" if height >= 3 else "ä½è·Ÿ(1-3cm)"
        else:
            heel_height = ""

        row = {
            "è‹±æ–‡æ ‡é¢˜": title_en,
            "æ ‡é¢˜": title_cn,
            "å•†å“ç¼–ç ": code_clean,
            "ä»·æ ¼": rmb_price,
            "å†…é‡Œæè´¨": lining_material,
            "å¸®é¢æè´¨": upper_material,
            "åè·Ÿé«˜": heel_height,
            "HSCODE": hscode,

            # âœ… V2ï¼šå›ºå®šå­—æ®µä¸€é”®æ³¨å…¥
            **excel_constants,

            "å“ç‰Œ": å“ç‰Œ,
            "æ€§åˆ«": gender_map.get(code_clean, "ç”·æ¬¾"),
            "ç±»ç›®": get_category_v2(title_en, content, heel_height),
        }
        rows.append(row)

    df_all = pd.DataFrame(rows)
    if df_all.empty:
        print("âš ï¸ æ²¡æœ‰å¯ç”Ÿæˆçš„æ•°æ®")
        return

    print("\nğŸ“Š åˆ†ç±»ç»Ÿè®¡ï¼š")
    print(df_all.groupby(["æ€§åˆ«", "ç±»ç›®"]).size())

    os.makedirs(output_base, exist_ok=True)
    print("\nğŸ“¤ æ­£åœ¨å¯¼å‡º Excel æ–‡ä»¶...")
    for (gender, category), sub_df in df_all.groupby(["æ€§åˆ«", "ç±»ç›®"]):
        out_file = output_base / f"{brand}_{gender}_{category}.xlsx"
        if out_file.exists():
            out_file.unlink()
        sub_df.drop(columns=["æ€§åˆ«", "ç±»ç›®"]).to_excel(out_file, index=False)
        print(f"âœ… å¯¼å‡ºï¼š{out_file}")

    # æ‹·è´å›¾ç‰‡
    image_dst_dir.mkdir(parents=True, exist_ok=True)
    print("\nğŸ–¼ï¸ æ­£åœ¨å¤åˆ¶å•†å“å›¾ç‰‡...")
    missing_codes = []
    for code_clean in product_codes:
        matched_images = list(image_src_dir.glob(f"{code_clean}*.jpg"))
        if not matched_images:
            print(f"âš ï¸ æœªæ‰¾åˆ°å›¾ç‰‡: {code_clean}")
            missing_codes.append(code_clean)
            continue
        for img_path in matched_images:
            shutil.copy(img_path, image_dst_dir / img_path.name)

    # å†™å‡º publication_codes.txt ä¸ missing_codes.txt
    pub_codes_file = config["OUTPUT_DIR"] / "publication_codes.txt"
    miss_codes_file = config["OUTPUT_DIR"] / "missing_codes.txt"

    with open(pub_codes_file, "w", encoding="utf-8") as f:
        for code in sorted(set(product_codes)):
            f.write(f"{code}\n")
    print(f"ğŸ“ å·²å†™å‡ºå•†å“ç¼–ç åˆ—è¡¨: {pub_codes_file} ({len(set(product_codes))} ä¸ª)")

    with open(miss_codes_file, "w", encoding="utf-8") as f:
        for code in sorted(set(missing_codes)):
            f.write(f"{code}\n")
    print(f"ğŸ“ å·²å†™å‡ºç¼ºå›¾ç¼–ç åˆ—è¡¨: {miss_codes_file} ({len(set(missing_codes))} ä¸ª)")

    print("\nâœ… æ‰€æœ‰æ“ä½œå®Œæˆã€‚")


if __name__ == "__main__":
    # ç¤ºä¾‹ï¼špython generate_publication_excel.py
    # ä½ ä¹Ÿå¯ä»¥åœ¨è¿™é‡Œæ”¹æˆ argparseï¼ˆåç»­å†åšï¼‰
    pass
