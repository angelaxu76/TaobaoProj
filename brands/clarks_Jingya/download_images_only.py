import re
import json
import requests
from bs4 import BeautifulSoup
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from config import CLARKS, ensure_all_dirs
import psycopg2
from psycopg2.extras import RealDictCursor

# === é…ç½® ===
PRODUCT_LINKS_FILE = CLARKS["BASE"] / "publication" / "product_links.txt"
IMAGE_DIR = CLARKS["IMAGE_DOWNLOAD"]
HEADERS = {"User-Agent": "Mozilla/5.0"}
MAX_WORKERS = 5
SKIP_EXISTING_IMAGE = True

ensure_all_dirs(IMAGE_DIR)




def extract_product_code(url):
    match = re.search(r'/([0-9]+)-p', url)
    return match.group(1) if match else "unknown"


def extract_image_urls(soup):
    image_urls = []
    script_tag = soup.find("script", id="__NEXT_DATA__")
    if script_tag:
        try:
            json_data = json.loads(script_tag.string)
            image_urls = json_data.get("props", {}).get("pageProps", {}).get("product", {}).get("imageUrls", [])
        except Exception as e:
            print(f"âš ï¸ å›¾ç‰‡ JSON æå–å¤±è´¥: {e}")
    return image_urls


def download_image(url, save_path):
    try:
        if SKIP_EXISTING_IMAGE and save_path.exists():
            print(f"âœ… å·²å­˜åœ¨ï¼Œè·³è¿‡: {save_path.name}")
            return
        r = requests.get(url, headers=HEADERS, timeout=10)
        if r.status_code == 200:
            with open(save_path, "wb") as f:
                f.write(r.content)
            print(f"ğŸ–¼ï¸ ä¸‹è½½æˆåŠŸ: {save_path.name}")
        else:
            print(f"âš ï¸ å›¾ç‰‡è¯·æ±‚å¤±è´¥ï¼ˆ{r.status_code}ï¼‰: {url}")
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {url} â†’ {e}")


def process_image_only(url):
    print(f"ğŸ“· å¤„ç†å›¾ç‰‡: {url}")
    try:
        r = requests.get(url, headers=HEADERS, timeout=15)
        r.raise_for_status()
        soup = BeautifulSoup(r.text, "html.parser")

        code = extract_product_code(url)
        image_urls = extract_image_urls(soup)

        for idx, img_url in enumerate(image_urls):
            img_path = IMAGE_DIR / f"{code}_{idx + 1}.jpg"
            download_image(img_url, img_path)
    except Exception as e:
        print(f"âŒ å›¾ç‰‡å¤„ç†å¤±è´¥: {url} â†’ {e}")


def fetch_urls_from_db_by_codes(code_file_path, pgsql_config, table_name):
    code_list = [line.strip() for line in Path(code_file_path).read_text(encoding="utf-8").splitlines() if line.strip()]
    print(f"ğŸ” å…±è¯»å–åˆ° {len(code_list)} ä¸ªå•†å“ç¼–ç ")

    urls = set()
    try:
        conn = psycopg2.connect(**pgsql_config)
        cursor = conn.cursor(cursor_factory=RealDictCursor)

        placeholders = ",".join(["%s"] * len(code_list))
        query = f"""
            SELECT DISTINCT product_code, product_url
            FROM {table_name}
            WHERE product_code IN ({placeholders})
        """
        cursor.execute(query, code_list)
        rows = cursor.fetchall()

        code_to_url = {row["product_code"]: row["product_url"] for row in rows}
        for code in code_list:
            url = code_to_url.get(code)
            if url:
                urls.add(url)
            else:
                print(f"âš ï¸ ç¼–ç æœªæ‰¾åˆ°: {code}")

        cursor.close()
        conn.close()
    except Exception as e:
        print(f"âŒ æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {e}")

    return list(urls)


def download_images_by_code_file(code_txt_path):
    pgsql_config = CLARKS["PGSQL_CONFIG"]
    table_name = CLARKS["TABLE_NAME"]

    urls = fetch_urls_from_db_by_codes(code_txt_path, pgsql_config, table_name)
    print(f"ğŸ“¦ å…±éœ€ä¸‹è½½ {len(urls)} ä¸ªå•†å“çš„å›¾ç‰‡\n")

    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = [executor.submit(process_image_only, url) for url in urls]
        for future in as_completed(futures):
            future.result()

    print("\nâœ… æ‰€æœ‰æŒ‡å®šå•†å“å›¾ç‰‡ä¸‹è½½å®Œæˆ")


def main():
    if not PRODUCT_LINKS_FILE.exists():
        print(f"âŒ é“¾æ¥æ–‡ä»¶ä¸å­˜åœ¨: {PRODUCT_LINKS_FILE}")
        return
    urls = [u.strip() for u in PRODUCT_LINKS_FILE.read_text(encoding="utf-8").splitlines() if u.strip()]
    print(f"ğŸ“¦ å…± {len(urls)} ä¸ªå•†å“å›¾ç‰‡å¾…å¤„ç†")

    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = [executor.submit(process_image_only, url) for url in urls]
        for future in as_completed(futures):
            future.result()

    print("\nâœ… æ‰€æœ‰å›¾ç‰‡ä¸‹è½½å®Œæˆ")


if __name__ == "__main__":
    # main()  # å¤„ç† product_links.txt ä¸­æ‰€æœ‰é“¾æ¥

    # ğŸ‘‡ æˆ–è€…åªå¤„ç†æŒ‡å®šç¼–ç çš„å•†å“è¡¥å›¾
    code_txt_path = CLARKS["BASE"] / "publication" / "è¡¥å›¾ç¼–ç .txt"
    download_images_by_code_file(code_txt_path)
