import os
import re
import time
import threading
from pathlib import Path
from typing import Dict, Optional, Tuple, List
from urllib.parse import urlparse
from concurrent.futures import ThreadPoolExecutor, as_completed

from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import SessionNotCreatedException

from config import SIZE_RANGE_CONFIG, GEOX
from common_taobao.ingest.txt_writer import format_txt
from common_taobao.core.category_utils import infer_style_category

# ===================== åŸºæœ¬é…ç½® =====================
PRODUCT_LINK_FILE = GEOX["BASE"] / "publication" / "product_links.txt"
TXT_OUTPUT_DIR = GEOX["TXT_DIR"]
BRAND = "geox"

# å»ºè®®ï¼š4~8 ä¹‹é—´æŒ‰ç”µè„‘æ€§èƒ½è°ƒ
MAX_THREADS = 6

# æ‰‹åŠ¨ç™»å½•ç­‰å¾…æ—¶é—´ï¼ˆç™»å½•çª—å£åªå‡ºç°ä¸€æ¬¡ï¼‰
LOGIN_WAIT_SECONDS = 20

TXT_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# ===================== Chrome Profileï¼ˆç™»å½•ç”¨ï¼‰ =====================
# âš  ç™»å½•ç”¨ driverï¼šä½¿ç”¨ä½ åŸæ¥é…ç½®çš„ Profileï¼ˆæœ‰æŠ˜æ‰£/ç™»å½•æ€ï¼‰
PROFILE_ROOT = r"D:\ChromeProfiles\AutoProfile_GEOX"   # éé»˜è®¤ç›®å½•æ ¹
PROFILE_NAME = "Profile 2"                             # å­ç›®å½•åï¼šProfile 1/2/3/4/Default ç­‰
FIXED_UA = (
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
    "AppleWebKit/537.36 (KHTML, like Gecko) "
    "Chrome/120.0.0.0 Safari/537.36"
)


# ===================== ç™»å½• driverï¼ˆå¯è§çª—å£ï¼‰ =====================
def _build_options(headless: bool = False,
                   user_data_dir: str = PROFILE_ROOT,
                   profile_name: str = PROFILE_NAME) -> Options:
    chrome_options = Options()

    if headless:
        chrome_options.add_argument("--headless=new")

    # å¦‚æœ‰éœ€è¦ï¼Œæ”¹æˆä½ çœŸå® Chrome è·¯å¾„
    chrome_options.binary_location = r"C:\Program Files\Google\Chrome\Application\chrome.exe"

    # âœ… å¤ç”¨å·²å­˜åœ¨çš„ Profileï¼ˆå…³é”®ï¼‰
    chrome_options.add_argument(f"--user-data-dir={user_data_dir}")
    chrome_options.add_argument(f"--profile-directory={profile_name}")

    # ç¨³å®šå‚æ•°
    chrome_options.add_argument("--start-maximized")
    chrome_options.add_argument("--no-first-run")
    chrome_options.add_argument("--no-default-browser-check")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--window-size=1920,1080")
    chrome_options.add_argument("--disable-blink-features=AutomationControlled")
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option("useAutomationExtension", False)
    chrome_options.add_argument(f"user-agent={FIXED_UA}")

    return chrome_options


def _kill_chrome():
    os.system('taskkill /F /IM chrome.exe /T')
    os.system('taskkill /F /IM chromedriver.exe /T')


def create_login_driver() -> webdriver.Chrome:
    """ç”¨äºæ‰‹åŠ¨/è‡ªåŠ¨ç™»å½•çš„ä¸€æ¬¡æ€§å¯è§çª—å£ driverã€‚"""
    print("Using user-data-dir =", PROFILE_ROOT)
    print("Using profile-directory =", PROFILE_NAME)
    try:
        opts = _build_options(headless=False)
        driver = webdriver.Chrome(options=opts)
        driver.execute_script(
            "Object.defineProperty(navigator, 'webdriver', {get: () => undefined});"
        )
        print(
            "Chrome =", driver.capabilities.get("browserVersion"),
            "| Chromedriver =",
            driver.capabilities.get("chrome", {}).get("chromedriverVersion")
        )
        return driver
    except SessionNotCreatedException:
        _kill_chrome()
        time.sleep(0.5)
        opts = _build_options(headless=False)
        driver = webdriver.Chrome(options=opts)
        driver.execute_script(
            "Object.defineProperty(navigator, 'webdriver', {get: () => undefined});"
        )
        print(
            "Chrome =", driver.capabilities.get("browserVersion"),
            "| Chromedriver =",
            driver.capabilities.get("chrome", {}).get("chromedriverVersion")
        )
        return driver


# ===================== Worker driverï¼ˆå¤šçº¿ç¨‹ headlessï¼‰ =====================
def create_worker_driver() -> webdriver.Chrome:
    """
    å¤šçº¿ç¨‹ worker ä½¿ç”¨çš„è½»é‡ driverï¼š
    - headless
    - ç¦å›¾
    - pageLoadStrategy=eager
    """
    o = Options()
    o.add_argument("--headless=new")
    o.add_argument("--disable-gpu")
    o.add_argument("--no-sandbox")
    o.add_argument("--disable-dev-shm-usage")
    o.add_argument("--window-size=1920,1080")
    o.add_argument("--disable-blink-features=AutomationControlled")
    o.add_experimental_option("excludeSwitches", ["enable-automation"])
    o.add_experimental_option("useAutomationExtension", False)
    o.add_argument(
        "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    )
    # ç¦å›¾ï¼Œè¿›ä¸€æ­¥æé€Ÿ
    o.add_argument("--blink-settings=imagesEnabled=false")
    # DOMContentLoaded å³è¿”å›
    o.set_capability("pageLoadStrategy", "eager")

    d = webdriver.Chrome(options=o)
    d.execute_script("Object.defineProperty(navigator,'webdriver',{get:()=>undefined});")
    return d


# ===================== ä¼šè¯å¯¼å‡º / å¯¼å…¥ =====================
def export_session(driver: webdriver.Chrome) -> Dict:
    """å¯¼å‡º cookies + localStorageï¼Œä¾›å¹¶å‘çº¿ç¨‹å¤ç”¨ç™»å½•æ€ã€‚"""
    cookies = driver.get_cookies()
    ls_items = driver.execute_script(
        """
        const out = {};
        for (let i=0; i<localStorage.length; i++){
            const k = localStorage.key(i);
            out[k] = localStorage.getItem(k);
        }
        return out;
        """
    )
    return {"cookies": cookies, "localStorage": ls_items}


def import_session(driver: webdriver.Chrome,
                   session: Dict,
                   base_url: str = "https://www.geox.com/") -> None:
    """å°† cookies + localStorage æ³¨å…¥åˆ°æ–° driverã€‚å¿…é¡»å…ˆæ‰“å¼€åŒåŸŸé¡µé¢ã€‚"""
    driver.get(base_url)

    # å†™å…¥ cookies
    for c in session.get("cookies", []):
        to_add = {
            "name": c.get("name"),
            "value": c.get("value"),
            "path": c.get("path", "/"),
            "secure": c.get("secure", True),
            "httpOnly": c.get("httpOnly", False),
        }
        if c.get("domain"):
            to_add["domain"] = c["domain"]
        if c.get("expiry"):
            to_add["expiry"] = c["expiry"]
        try:
            driver.add_cookie(to_add)
        except Exception as e:
            print(f"cookie æ³¨å…¥å¤±è´¥ {to_add.get('name')}: {e}")

    # å†™å…¥ localStorage
    driver.execute_script("localStorage.clear();")
    for k, v in session.get("localStorage", {}).items():
        driver.execute_script("localStorage.setItem(arguments[0], arguments[1]);", k, v)


# ===================== é¡µé¢æŠ“å– =====================
def get_html(driver: webdriver.Chrome, url: str) -> Optional[str]:
    def _accept_cookies():
        for sel in [
            "button#onetrust-accept-btn-handler",
            "button.cookie-accept",
            "button.js-accept-all",
        ]:
            try:
                btn = WebDriverWait(driver, 0.1).until(
                    EC.element_to_be_clickable((By.CSS_SELECTOR, sel))
                )
                btn.click()
                time.sleep(0)
                return
            except Exception:
                continue

    def _scroll_warmup():
        driver.execute_script("window.scrollTo(0, 400);"); time.sleep(0)
        driver.execute_script(
            "window.scrollTo(0, document.body.scrollHeight - 400);"
        ); time.sleep(0)
        driver.execute_script("window.scrollTo(0, 0);"); time.sleep(0)

    driver.get(url)
    _accept_cookies()

    try:
        WebDriverWait(driver, 0.1).until(
            EC.presence_of_element_located(
                (
                    By.CSS_SELECTOR,
                    "div.product-info div.price, "
                    "div.right-side div.price, "
                    "div.price-mobile div.price, "
                    "div.price",
                )
            )
        )
        WebDriverWait(driver, 0.1).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "button.add-to-cart"))
        )
    except Exception:
        pass

    _scroll_warmup()

    try:
        WebDriverWait(driver, 0.1).until(
            EC.presence_of_element_located(
                (
                    By.CSS_SELECTOR,
                    "span.product-price span.sales span.value[content]",
                )
            )
        )
        try:
            WebDriverWait(driver, 1).until(
                EC.presence_of_element_located(
                    (
                        By.CSS_SELECTOR,
                        "span.product-price span.sales.discount span.value[content]",
                    )
                )
            )
        except Exception:
            pass
    except Exception:
        pass

    try:
        WebDriverWait(driver, 0.1).until(
            lambda d: (
                d.execute_script(
                    """
                    const btn = document.querySelector('button.add-to-cart');
                    if(!btn) return false;
                    try {
                        return typeof JSON.parse(
                            btn.getAttribute('data-gtmdata') || '{}'
                        ).item_promo === 'string';
                    } catch(e){ return false; }
                    """
                )
                is True
            )
        )
    except Exception:
        pass

    time.sleep(0)
    return driver.page_source


# ===================== ä¸šåŠ¡è§£æé€»è¾‘ï¼ˆåŸºæœ¬ä¿æŒä½ åŸæ¥çš„ï¼‰ =====================
def supplement_geox_sizes(size_stock: Dict[str, str], gender: str) -> Dict[str, str]:
    standard_sizes = SIZE_RANGE_CONFIG.get("geox", {}).get(gender, [])
    for size in standard_sizes:
        if size not in size_stock:
            size_stock[size] = "0"  # æ— è´§
    return size_stock


def detect_gender_by_code(code: str) -> str:
    if not code:
        return "æœªçŸ¥"
    code = code.strip().upper()
    if code.startswith("D"):
        return "å¥³æ¬¾"
    if code.startswith("U"):
        return "ç”·æ¬¾"
    if code.startswith("J"):
        return "ç«¥æ¬¾"
    return "æœªçŸ¥"


def parse_product(html: str, url: str) -> Dict:
    soup = BeautifulSoup(html, "html.parser")

    # åŸºæœ¬ä¿¡æ¯
    code_tag = soup.select_one("span.product-id")
    code = code_tag.text.strip() if code_tag else "No Data"

    name_tag = soup.select_one("div.sticky-image img")
    name = (
        name_tag["alt"].strip()
        if name_tag is not None and name_tag.has_attr("alt")
        else "No Data"
    )

    # ä»·æ ¼ï¼ˆä»…é™ PDP ä¸»åŒºåŸŸï¼›æ’é™¤æ¨è/è½®æ’­ï¼›åŒºé—´ä»·å–æœ€å¤§ï¼‰
    def _safe_select_value(_soup, selector: str):
        for node in _soup.select(selector):
            if node.find_parent(class_="product-tile") or node.find_parent(
                class_="product-carousel-tile"
            ):
                continue
            return node
        return None

    def extract_max_price(val):
        if not val:
            return "No Data"
        s = str(val).strip()
        if "-" in s:
            try:
                parts = [float(p.strip()) for p in s.split("-") if p.strip()]
                return f"{max(parts):.2f}"
            except Exception:
                return s
        return s

    price_tag = _safe_select_value(soup, "span.product-price span.value")
    discount_tag = _safe_select_value(
        soup, "span.sales.discount span.value"
    )

    full_price_raw = (
        (price_tag.get("content") or price_tag.get_text(strip=True).replace("Â£", ""))
        .strip()
        if price_tag
        else ""
    )
    discount_price_raw = (
        (
            discount_tag.get("content")
            or discount_tag.get_text(strip=True).replace("Â£", "")
        ).strip()
        if discount_tag
        else ""
    )

    original_price = extract_max_price(full_price_raw) or "No Data"

    # æŠ˜æ‰£ä»·æ ¡éªŒï¼šæ— æŠ˜æ‰£/å¼‚å¸¸å€¼ï¼Œå›é€€åŸä»·
    discount_price = extract_max_price(discount_price_raw) if discount_price_raw else ""
    try:
        op = float(original_price) if original_price not in ("", "No Data") else None
        dp = float(discount_price) if discount_price not in ("", "No Data") else None
        if dp is None or op is None or dp >= op or dp < op * 0.3:
            discount_price = original_price
    except Exception:
        discount_price = original_price

    # é¢œè‰² / æè´¨ / æè¿°
    color_block = soup.select_one("div.sticky-color")
    color = (
        color_block.get_text(strip=True).replace("Color:", "").strip()
        if color_block
        else "No Data"
    )

    materials_block = soup.select_one("div.materials-container")
    material_text = (
        materials_block.get_text(" ", strip=True) if materials_block else "No Data"
    )

    desc_block = soup.select_one("div.product-description div.value")
    description = desc_block.get_text(strip=True) if desc_block else "No Data"

    # æ€§åˆ«
    gender = detect_gender_by_code(code)

    # å°ºç åº“å­˜
    size_blocks = soup.select("div.size-value")
    size_stock: Dict[str, str] = {}
    for sb in size_blocks:
        size = (
            sb.get("data-attr-value")
            or sb.get("prodsize")
            or sb.get("aria-label")
        )
        size = size.strip().replace(",", ".") if size else "Unknown"
        available = "1" if "disabled" not in sb.get("class", []) else "0"
        size_stock[size] = available

    size_stock = supplement_geox_sizes(size_stock, gender)

    # Jingya æ¨¡å¼ï¼šè¾“å‡º SizeMap / SizeDetail
    size_map: Dict[str, str] = {}
    size_detail: Dict[str, Dict] = {}
    for eu, flag in size_stock.items():
        has = str(flag) == "1"
        size_map[eu] = "æœ‰è´§" if has else "æ— è´§"
        size_detail[eu] = {"stock_count": 3 if has else 0, "ean": "0000000000000"}

    # é£æ ¼åˆ†ç±»
    style_category = infer_style_category(f"{name} {description}")

    info = {
        "Product Code": code,
        "Product Name": name,
        "Product Description": description,
        "Product Gender": gender,
        "Product Color": color,
        "Product Price": original_price,
        "Adjusted Price": discount_price,
        "Product Material": material_text,
        "Style Category": style_category,
        "Feature": "No Data",
        "SizeMap": size_map,
        "SizeDetail": size_detail,
        "Source URL": url,
    }
    return info


def derive_code_from_url(url: str) -> str:
    """ä» URL æœ«å°¾æå–å•†å“ç¼–ç ï¼ˆâ€œ-<code>.htmlâ€ï¼‰ã€‚"""
    try:
        path = urlparse(url).path
        name = Path(path).name
        base = name.split("?", 1)[0]
        token = base.rsplit("-", 1)[-1]
        code = token.split(".", 1)[0].upper()
        if len(code) < 6 or not any(ch.isdigit() for ch in code):
            m = re.search(r"([A-Za-z0-9]{6,})\.html$", base)
            if m:
                code = m.group(1).upper()
        return code
    except Exception:
        return Path(urlparse(url).path).stem.upper()


# ===================== å¤šçº¿ç¨‹æŠ“å–æ ¸å¿ƒ =====================
_thread_local = threading.local()
_DRIVER_LIST_LOCK = threading.Lock()
_THREAD_DRIVERS: List[webdriver.Chrome] = []


def _get_thread_driver(session: Dict) -> webdriver.Chrome:
    """æ¯ä¸ªçº¿ç¨‹æ‡’åŠ è½½ä¸€ä¸ª headless driverï¼Œå¹¶æ³¨å…¥ sessionã€‚"""
    driver = getattr(_thread_local, "driver", None)
    if driver is None:
        driver = create_worker_driver()
        import_session(driver, session, base_url="https://www.geox.com/")
        with _DRIVER_LIST_LOCK:
            _THREAD_DRIVERS.append(driver)
        _thread_local.driver = driver
    return driver


def _process_one_url(
    idx: int, total: int, url: str, session: Dict
) -> Tuple[bool, str]:
    driver = _get_thread_driver(session)
    try:
        print(f"[{idx}/{total}] æŠ“å–: {url}")
        html = get_html(driver, url)
        if not html:
            print(f"[{idx}] âš  ç©ºé¡µé¢: {url}")
            return False, url

        info = parse_product(html, url)
        if not info:
            print(f"[{idx}] âš  è§£æå¤±è´¥: {url}")
            return False, url

        # å¦‚æœé¡µé¢æ²¡ç»™ç¼–ç ï¼Œæœ€åå…œåº•ç”¨ URL æ¨å¯¼
        if not info.get("Product Code") or info["Product Code"] == "No Data":
            info["Product Code"] = derive_code_from_url(url)

        code = info["Product Code"]
        txt_path = TXT_OUTPUT_DIR / f"{code}.txt"
        txt_path.parent.mkdir(parents=True, exist_ok=True)
        format_txt(info, txt_path, brand=BRAND)
        print(f"[{idx}] âœ… å†™å…¥æˆåŠŸ: {txt_path.name}")
        return True, url

    except Exception as e:
        print(f"[{idx}] âŒ å¤„ç†å¤±è´¥ {url} â†’ {e}")
        return False, url


def _cleanup_thread_drivers():
    with _DRIVER_LIST_LOCK:
        for d in _THREAD_DRIVERS:
            try:
                d.quit()
            except Exception:
                pass
        _THREAD_DRIVERS.clear()


# ===================== ä¸»å…¥å£ =====================
def fetch_all_product_info(links_file=None, max_workers: int = MAX_THREADS):
    """
    GEOX å•†å“æŠ“å–ä¸»å…¥å£ï¼ˆæ”¯æŒå¤–éƒ¨ä¼ å…¥ product_links.txt è¦†ç›–é»˜è®¤è·¯å¾„ï¼‰ã€‚
    prepare_jingya_listing.py é‡Œä¸¤æ¬¡è°ƒç”¨éƒ½å…¼å®¹ï¼š
        fetch_all_product_info()
        fetch_all_product_info(missing_product_link)
    """
    # 1) è§£æé“¾æ¥æ–‡ä»¶
    if links_file is None:
        links_path = PRODUCT_LINK_FILE
    else:
        links_path = Path(links_file)

    if not links_path.exists():
        print(f"âŒ ç¼ºå°‘é“¾æ¥æ–‡ä»¶: {links_path}")
        return

    with open(links_path, "r", encoding="utf-8") as f:
        urls = [u.strip() for u in f if u.strip()]

    if not urls:
        print(f"âš  é“¾æ¥åˆ—è¡¨ä¸ºç©º: {links_path}")
        return

    total = len(urls)
    print(f"\nğŸ“¦ æœ¬æ¬¡éœ€è¦æŠ“å– GEOX å•†å“æ•°é‡: {total}")

    # 2) ç™»å½•ä¸€æ¬¡ï¼Œå¯¼å‡º session
    login_driver = create_login_driver()
    try:
        # æ‰“å¼€ç¬¬ä¸€æ¡é“¾æ¥ï¼Œè®©ä½ æœ‰æœºä¼šç¡®è®¤ç™»å½•/æŠ˜æ‰£
        login_driver.get(urls[0])
        print(
            f"â³ å¦‚éœ€ç™»å½•ï¼Œè¯·åœ¨æ–°çª—å£æ‰‹åŠ¨ç™»å½• GEOXï¼ˆç­‰å¾… {LOGIN_WAIT_SECONDS} ç§’ï¼‰"
        )
        time.sleep(LOGIN_WAIT_SECONDS)
        session = export_session(login_driver)
        print("âœ… ç™»å½•æ€å·²å¯¼å‡ºï¼Œå°†æ³¨å…¥åˆ°å¤šçº¿ç¨‹ worker ä¸­")
    finally:
        login_driver.quit()

    # 3) å¤šçº¿ç¨‹æŠ“å–
    t0 = time.time()
    success = 0
    fail = 0

    print(f"ğŸš€ å¯åŠ¨å¤šçº¿ç¨‹æŠ“å–ï¼ˆçº¿ç¨‹æ•°: {max_workers}ï¼‰")
    try:
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {
                executor.submit(
                    _process_one_url, idx, total, url, session
                ): url
                for idx, url in enumerate(urls, 1)
            }
            for fut in as_completed(futures):
                ok, _ = fut.result()
                if ok:
                    success += 1
                else:
                    fail += 1
    finally:
        _cleanup_thread_drivers()

    dt = time.time() - t0
    print(
        f"\nâœ… GEOX æŠ“å–å®Œæˆï¼šæˆåŠŸ {success} æ¡ï¼Œå¤±è´¥ {fail} æ¡ï¼Œ"
        f"è€—æ—¶çº¦ {dt/60:.1f} åˆ†é’Ÿ"
    )


if __name__ == "__main__":
    fetch_all_product_info()
