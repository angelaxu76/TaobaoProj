import os
import re
import pandas as pd
import requests
import deepl
from config import CAMPER
from sqlalchemy import create_engine
from common_taobao.core.price_utils import calculate_camper_untaxed_and_retail

# ===== å‚æ•°é…ç½® =====
txt_folder = CAMPER["TXT_DIR"]
output_base = CAMPER["OUTPUT_DIR"] / "publication_excels"
pg_cfg = CAMPER["PGSQL_CONFIG"]
auth_key = "fbeb00ce-2b94-42c8-9126-65daaaf0e7dd:fx"
translator = deepl.Translator(auth_key)

# å›ºå®šå­—æ®µ
ä¸Šå¸‚å­£èŠ‚ = "2025æ˜¥å­£"
å­£èŠ‚ = "æ˜¥ç§‹"
æ¬¾å¼ = "ä¼‘é—²"
é—­åˆæ–¹å¼ = ""
è·Ÿåº•æ¬¾å¼ = "å¹³åº•"
å¼€å£æ·±åº¦ = "æµ…å£"
é‹å¤´æ¬¾å¼ = "åœ†å¤´"
åœ°åŒºå›½å®¶ = "è‹±å›½"
å‘è´§æ—¶é—´ = "7"
è¿è´¹æ¨¡ç‰ˆ = "parcelforce"
ç¬¬ä¸€è®¡é‡å•ä½ = "1"
ç¬¬äºŒè®¡é‡å•ä½ = "1"
é”€å”®å•ä½ = "åŒ"
å“å = "é‹"
æµ·å…³æ¬¾å¼ = "ä¼‘é—²é‹"
å¤–åº•ææ–™ = "EVA"
å†…åº•é•¿åº¦ = "27"
å“ç‰Œ = "camper"
default_exchange_rate = 9.1

# è·å–å®æ—¶æ±‡ç‡
def get_exchange_rate():
    try:
        res = requests.get('https://api.exchangerate.host/latest?base=GBP&symbols=CNY', timeout=5)
        return res.json()['rates']['CNY']
    except:
        return default_exchange_rate

exchange_rate = get_exchange_rate()
print(f"\nğŸ“ˆ å½“å‰è‹±é•‘å…‘äººæ°‘å¸æ±‡ç‡: {exchange_rate}")

print("\nğŸ”Œ æ­£åœ¨è¿æ¥æ•°æ®åº“...")
engine = create_engine(
    f"postgresql+psycopg2://{pg_cfg['user']}:{pg_cfg['password']}@{pg_cfg['host']}:{pg_cfg['port']}/{pg_cfg['dbname']}"
)

print("\nğŸ“Š æ­£åœ¨æŸ¥è¯¢ç¬¦åˆæ¡ä»¶çš„å•†å“...")
query = """
WITH size_counts AS (
    SELECT product_name,
           COUNT(*) AS available_sizes,
           SUM(stock_count) AS total_stock
    FROM camper_inventory
    WHERE stock_count > 1
    GROUP BY product_name
)
SELECT DISTINCT ci.product_name,
       ci.original_price_gbp,
       ci.discount_price_gbp
FROM camper_inventory ci
JOIN size_counts sc ON ci.product_name = sc.product_name
WHERE ci.is_published = FALSE
  AND sc.available_sizes >= 4
  AND sc.total_stock > 20
"""
df_codes = pd.read_sql(query, engine)
product_codes = df_codes["product_name"].tolist()
print(f"âœ… è·å–åˆ°ç¬¦åˆæ¡ä»¶çš„å•†å“æ•°: {len(product_codes)}")

price_map = df_codes.set_index("product_name")[["original_price_gbp", "discount_price_gbp"]].to_dict("index")

gender_map = {
    k.strip().upper(): v for k, v in
    pd.read_sql("SELECT DISTINCT product_name, gender FROM camper_inventory", engine)
    .dropna()
    .values
}

def extract_field(name, content):
    start = content.find(name)
    if start == -1:
        return ""
    start = content.find(':', start) + 1
    end = content.find('\n', start)
    return content[start:end].strip()

def translate_text(text):
    try:
        return translator.translate_text(text, source_lang="EN", target_lang="ZH").text
    except:
        return text

def get_category_v2(title: str, content: str, heel_height: str) -> str:
    t = title.lower()
    c = content.lower()
    if any(k in t for k in ["boot", "ankle", "chelsea"]):
        return "é´å­"
    if any(k in t for k in ["sandal", "slide", "slipper", "mule", "flip-flop"]):
        return "å‡‰é‹æ‹–é‹"
    if heel_height in ["é«˜è·Ÿ(5-8cm)", "ä¸­è·Ÿ(3-5cm)"]:
        return "å…¶ä»–ä¼‘é—²é‹"
    return "å…¶ä»–ä¼‘é—²é‹"

rows = []
print("\nğŸ“¦ æ­£åœ¨è¯»å– TXT å¹¶ç”Ÿæˆå•†å“è¡Œæ•°æ®...")
for idx, code in enumerate(product_codes, 1):
    code_clean = code.strip().upper()
    txt_path = txt_folder / f"{code_clean}.txt"
    if not txt_path.exists():
        print(f"âŒ ç¼ºå°‘ TXT æ–‡ä»¶: {txt_path}")
        continue

    if idx % 50 == 0:
        print(f"...å·²å¤„ç† {idx} ä¸ªå•†å“")

    with open(txt_path, 'r', encoding='utf-8') as f:
        content = f.read()

    title_en = extract_field("Product Name", content).strip()
    title_cn = translate_text(title_en)

    price_info = price_map.get(code, {"original_price_gbp": 0, "discount_price_gbp": 0})
    original = price_info.get("original_price_gbp", 0) or 0
    discount = price_info.get("discount_price_gbp", 0) or 0
    base_price = min(original, discount) if original and discount else discount or original
    try:
        _, rmb_price = calculate_camper_untaxed_and_retail(base_price, exchange_rate=exchange_rate)
    except:
        rmb_price = ""

    upper_info = content.lower()
    lining_info = content.lower()

    lining_material = "å¤´å±‚ç‰›çš®" if "leather" in lining_info else ("ç»‡ç‰©" if "recycled polyester" in lining_info else "")
    upper_material = "ç‰›çš®é©" if "leather" in upper_info else ("ç»‡ç‰©" if "recycled polyester" in upper_info else "")

    hscode = "6403990090" if 'upper' in content.lower() and 'leather' in upper_info else "6405200090"

    match = re.search(r'Height[:ï¼š]?\s*(\d+\.?\d*)', content)
    if match:
        height = float(match.group(1))
        heel_height = "é«˜è·Ÿ(5-8cm)" if height > 5 else "ä¸­è·Ÿ(3-5cm)" if height >= 3 else "ä½è·Ÿ(1-3cm)"
    else:
        heel_height = ""

    row = {
        "æ ‡é¢˜": title_cn,
        "å•†å“ç¼–ç ": code,
        "ä»·æ ¼": rmb_price,
        "å†…é‡Œæè´¨": lining_material,
        "å¸®é¢æè´¨": upper_material,
        "ä¸Šå¸‚å­£èŠ‚": ä¸Šå¸‚å­£èŠ‚,
        "å­£èŠ‚": å­£èŠ‚,
        "æ¬¾å¼": æ¬¾å¼,
        "é—­åˆæ–¹å¼": é—­åˆæ–¹å¼,
        "è·Ÿåº•æ¬¾å¼": è·Ÿåº•æ¬¾å¼,
        "å¼€å£æ·±åº¦": å¼€å£æ·±åº¦,
        "åè·Ÿé«˜": heel_height,
        "é‹å¤´æ¬¾å¼": é‹å¤´æ¬¾å¼,
        "åœ°åŒºå›½å®¶": åœ°åŒºå›½å®¶,
        "å‘è´§æ—¶é—´": å‘è´§æ—¶é—´,
        "è¿è´¹æ¨¡ç‰ˆ": è¿è´¹æ¨¡ç‰ˆ,
        "HSCODE": hscode,
        "ç¬¬ä¸€è®¡é‡å•ä½": ç¬¬ä¸€è®¡é‡å•ä½,
        "ç¬¬äºŒè®¡é‡å•ä½": ç¬¬äºŒè®¡é‡å•ä½,
        "é”€å”®å•ä½": é”€å”®å•ä½,
        "å“å": å“å,
        "æµ·å…³æ¬¾å¼": æµ·å…³æ¬¾å¼,
        "å¤–åº•ææ–™": å¤–åº•ææ–™,
        "å†…åº•é•¿åº¦": å†…åº•é•¿åº¦,
        "å“ç‰Œ": å“ç‰Œ,
        "æ€§åˆ«": gender_map.get(code_clean, "ç”·æ¬¾"),
        "ç±»ç›®": get_category_v2(title_en, content, heel_height)
    }
    rows.append(row)

os.makedirs(output_base, exist_ok=True)
df_all = pd.DataFrame(rows)
print("\nğŸ“Š åˆ†ç±»åˆ†å¸ƒç»Ÿè®¡ï¼š")
print(df_all.groupby(["æ€§åˆ«", "ç±»ç›®"]).size())

print("\nğŸ“¤ æ­£åœ¨å¯¼å‡º Excel æ–‡ä»¶...")
for (gender, category), sub_df in df_all.groupby(["æ€§åˆ«", "ç±»ç›®"]):
    out_file = output_base / f"camper_{gender}_{category}.xlsx"
    if out_file.exists():
        out_file.unlink()
    sub_df.drop(columns=["æ€§åˆ«", "ç±»ç›®"]).to_excel(out_file, index=False)
    print(f"âœ… å¯¼å‡ºï¼š{out_file}")
