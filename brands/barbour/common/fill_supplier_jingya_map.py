# -*- coding: utf-8 -*-
from __future__ import annotations
from pathlib import Path
from typing import Dict, List, Optional, Set

import openpyxl
from sqlalchemy import text
from sqlalchemy.engine import Connection

from config import BRAND_CONFIG, BARBOUR
from brands.barbour.core.site_utils import canonical_site

PUBLICATION_DIR = Path(BARBOUR["PUBLICATION_DIR"])
PATTERN = "barbour_publication_*.xlsx"
TABLE = "barbour_supplier_map"

SQL_CREATE = text(f"""
CREATE TABLE IF NOT EXISTS {TABLE} (
  product_code VARCHAR(50) PRIMARY KEY,
  site_name    VARCHAR(100) NOT NULL
);
""")

SQL_PUBLISHED_CODES = text("""
SELECT DISTINCT product_code
FROM barbour_inventory
WHERE is_published = TRUE
  AND product_code IS NOT NULL
""")  # is_published/product_code æ¥è‡ª inventoryã€‚:contentReference[oaicite:0]{index=0}

SQL_EXISTING_MAP = text(f"SELECT product_code FROM {TABLE}")

SQL_UPSERT = text(f"""
INSERT INTO {TABLE} (product_code, site_name)
VALUES (:code, :site)
ON CONFLICT (product_code) DO UPDATE SET site_name = EXCLUDED.site_name
""")

SQL_LOWEST_SITE = text("""
WITH agg AS (
  SELECT
    site_name,
    -- æœ‰è´§å°ºç æ•°
    SUM(CASE WHEN COALESCE(stock_count,0) > 0 THEN 1 ELSE 0 END) AS sizes_in_stock,
    -- ä»…åœ¨æœ‰è´§å°ºç ä¸­å–æœ€ä½ä»·
    MIN(COALESCE(NULLIF(price_gbp,0), original_price_gbp))
      FILTER (WHERE COALESCE(stock_count,0) > 0)                 AS min_price,
    MAX(last_checked)                                            AS latest
  FROM barbour_offers
  WHERE product_code = :code
    AND is_active = TRUE
  GROUP BY site_name
),
eligible AS (
  SELECT * FROM agg WHERE sizes_in_stock >= 3
)
SELECT site_name
FROM eligible
ORDER BY
  min_price ASC NULLS LAST,
  sizes_in_stock DESC,
  latest DESC
LIMIT 1
""")  # offers å­—æ®µå‚è€ƒï¼šsite_name/price_gbp/original_price_gbp/stock_count/last_checkedã€‚:contentReference[oaicite:1]{index=1}


def _load_publication_mappings(pub_dir: Path) -> Dict[str, str]:
    """
    è¯»å–ç›®å½•ä¸‹æ‰€æœ‰ barbour_publication_*.xlsxï¼Œè¿”å› {product_code -> canonical_site}
    åè¯»çš„æ–°æ–‡ä»¶è¦†ç›–æ—§æ–‡ä»¶ï¼ˆä»¥â€œæœ€æ–°å‘å¸ƒâ€ä¸ºå‡†ï¼‰ã€‚
    å…¼å®¹åˆ—åï¼š
      ç¼–ç ï¼šProduct Code / å•†å“ç¼–ç  / product_code / color_code / ç¼–ç 
      ç«™ç‚¹ï¼šSupplier / ä¾›åº”å•† / Site / site / ç«™ç‚¹
    """
    def _headers(ws) -> Dict[str, int]:
        h = {}
        for j, c in enumerate(ws[1], start=1):
            k = str(c.value or "").strip().lower().replace(" ", "")
            if k:
                h[k] = j
        return h

    mappings: Dict[str, str] = {}
    files = sorted(pub_dir.glob(PATTERN), key=lambda p: p.stat().st_mtime)
    for fp in files:
        try:
            wb = openpyxl.load_workbook(fp, data_only=True)
            ws = wb.active
            hdr = _headers(ws)
            col_code = next((hdr[k] for k in ("productcode","å•†å“ç¼–ç ","product_code","color_code","ç¼–ç ") if k in hdr), None)
            col_site = next((hdr[k] for k in ("supplier","ä¾›åº”å•†","site","ç«™ç‚¹") if k in hdr), None)
            if not col_code or not col_site:
                continue
            for i in range(2, ws.max_row + 1):
                code = str(ws.cell(i, col_code).value or "").strip()
                site_raw = str(ws.cell(i, col_site).value or "").strip()
                if not code or not site_raw:
                    continue
                site = canonical_site(site_raw)
                if site:
                    mappings[code] = site
        except Exception as e:
            print(f"âš ï¸ è§£æå¤±è´¥ {fp.name}: {e}")
    return mappings


def _pick_lowest_site(conn: Connection, code: str) -> Optional[str]:
    row = conn.execute(SQL_LOWEST_SITE, {"code": code}).fetchone()
    if not row:
        return None
    return canonical_site(row[0]) or row[0]


def fill_supplier_map(force_refresh: bool = False) -> None:
    cfg = BRAND_CONFIG["barbour"]["PGSQL_CONFIG"]
    engine = create_engine(
        f"postgresql+psycopg2://{cfg['user']}:{cfg['password']}@{cfg['host']}:{cfg['port']}/{cfg['dbname']}"
    )

    with engine.begin() as conn:
        # 0) ç¡®ä¿è¡¨å­˜åœ¨ï¼ˆNOT NULL çº¦æŸä¿æŒï¼‰
        conn.execute(SQL_CREATE)

        if force_refresh:
            conn.execute(text(f"TRUNCATE TABLE {TABLE};"))
            print(f"âš ï¸ å·²æ¸…ç©º {TABLE} è¡¨ã€‚")       

        # 1) å–â€œå·²å‘å¸ƒâ€çš„ç¼–ç é›†åˆï¼ˆä¸æ’å…¥ä»»ä½• NULLï¼‰
        published: Set[str] = {r[0] for r in conn.execute(SQL_PUBLISHED_CODES).fetchall()}
        print(f"ğŸ“¦ å·²å‘å¸ƒç¼–ç ï¼š{len(published)} ä¸ªã€‚")  # æ¥è‡ª inventoryã€‚:contentReference[oaicite:2]{index=2}

        # 2) å·²æœ‰æ˜ å°„ï¼ˆé¿å…é‡å¤å¤„ç†ï¼‰
        try:
            existing: Set[str] = {r[0] for r in conn.execute(SQL_EXISTING_MAP).fetchall()}
        except Exception:
            existing = set()

        # 3) ä»å‘å¸ƒæ¸…å•å†™å…¥æ˜ å°„ï¼ˆæœ€æ–°è¦†ç›–æ—§å€¼ï¼‰
        pub_map = _load_publication_mappings(PUBLICATION_DIR)
        pub_hit: List[str] = []
        for code, site in pub_map.items():
            if code in published:
                conn.execute(SQL_UPSERT, {"code": code, "site": site})
                pub_hit.append(code)
        print(f"âœ… æŒ‰å‘å¸ƒæ–‡ä»¶æ›´æ–°ï¼š{len(pub_hit)} æ¡ã€‚")
        # æ‰“å°å‘½ä¸­ç¼–ç ï¼ˆä¾¿äºä½ åŒºåˆ†æ¥æºï¼‰
        if pub_hit:
            print("â†’ æ¥è‡ª publication çš„ç¼–ç ï¼š", ", ".join(pub_hit))

        # 4) å…œåº•ï¼šå¯¹â€œå·²å‘å¸ƒä½†è¿˜æœªæ˜ å°„â€çš„ç¼–ç ï¼Œç”¨ offers é€‰æœ€ä½ä»·ç«™ç‚¹
        need = (published - set(pub_hit)) - existing
        offer_filled: List[str] = []
        for code in sorted(need):
            site = _pick_lowest_site(conn, code)
            if site:
                conn.execute(SQL_UPSERT, {"code": code, "site": site})
                offer_filled.append(code)
        print(f"âœ… æŒ‰ offers å…œåº•ï¼š{len(offer_filled)} æ¡ã€‚")
        if offer_filled:
            print("â†’ æ¥è‡ª offers å…œåº•çš„ç¼–ç ï¼š", ", ".join(offer_filled))

        # 5) ç»Ÿè®¡æ”¶å°¾
        total_now = conn.execute(text(f"SELECT COUNT(*) FROM {TABLE}")).scalar_one()
        print(f"ğŸ¯ å®Œæˆæ˜ å°„ï¼Œæ€»è®¡ {total_now} æ¡ã€‚")


def reassign_low_stock_suppliers(size_threshold: int = 3, dry_run: bool = True) -> list[dict]:
    """
    æ‰¾å‡ºå½“å‰æ˜ å°„ç«™ç‚¹â€œåœ¨å”®å°ºç æ•° < size_thresholdâ€çš„å•†å“ï¼›è‹¥å­˜åœ¨å…¶å®ƒç«™ç‚¹æ»¡è¶³(å°ºç â‰¥é˜ˆå€¼ & æœ€ä½ä»·æœ€ä½)ï¼Œåˆ™å»ºè®®/æ‰§è¡Œåˆ‡æ¢ã€‚
    - dry_run=Trueï¼šåªæ‰“å°ä¸è¿”å›å»ºè®®ï¼Œä¸æ”¹åº“
    - è¿”å›ï¼šå»ºè®®åˆ‡æ¢æ¸…å• [{code, old_site, old_sizes, new_site, new_sizes, old_min_price, new_min_price}]
    """
    cfg = BRAND_CONFIG["barbour"]["PGSQL_CONFIG"]
    eng = create_engine(f"postgresql+psycopg2://{cfg['user']}:{cfg['password']}@{cfg['host']}:{cfg['port']}/{cfg['dbname']}")
    suggest: list[dict] = []

    SQL_AGG = text("""
    WITH agg AS (
      SELECT
        product_code,
        site_name,
        SUM(CASE WHEN COALESCE(stock_count,0) > 0 THEN 1 ELSE 0 END) AS sizes_in_stock,
        MIN(COALESCE(NULLIF(sale_price_gbp,0), NULLIF(price_gbp,0), original_price_gbp))
            FILTER (WHERE COALESCE(stock_count,0) > 0)               AS min_eff_price,
        MAX(last_checked)                                            AS latest
      FROM barbour_offers
      WHERE is_active = TRUE
      GROUP BY product_code, site_name
    )
    SELECT * FROM agg
    """)

    with eng.begin() as conn:
        # æ˜ å°„è¡¨
        map_df = pd.read_sql("SELECT product_code, site_name FROM barbour_supplier_map", conn)
        map_df["site_name"] = map_df["site_name"].map(lambda s: canonical_site(s) or s)

        # å…¨éƒ¨ç«™ç‚¹èšåˆè¡¨ç°
        agg_df = pd.read_sql(SQL_AGG, conn)
        agg_df["site_name"] = agg_df["site_name"].map(lambda s: canonical_site(s) or s)

        # åˆå¹¶æ‹¿åˆ°å½“å‰ç«™ç‚¹è¡¨ç°
        cur_df = map_df.merge(
            agg_df.rename(columns={
                "sizes_in_stock": "cur_sizes_in_stock",
                "min_eff_price": "cur_min_eff_price",
                "latest": "cur_latest"
            }),
            on=["product_code", "site_name"], how="left"
        )

        # éå†ï¼šå½“å‰ç«™ç‚¹å°ºç ä¸è¶³é˜ˆå€¼ â†’ æ‰¾â€œå€™é€‰æœ€ä½³ç«™ç‚¹â€
        for _, r in cur_df.iterrows():
            code = str(r["product_code"])
            old_site = r["site_name"]
            cur_sizes = (r.get("cur_sizes_in_stock") or 0)

            if cur_sizes is None or int(cur_sizes) >= int(size_threshold):
                continue  # å½“å‰ç«™ç‚¹å°ºç æ•°å·²æ»¡è¶³ï¼Œä¸å¤„ç†

            # å€™é€‰ç«™ç‚¹ï¼šâ‰¥é˜ˆå€¼çš„ç«™ç‚¹é‡Œé€‰ä»·æ ¼æœ€ä½ï¼ˆè‹¥å¹¶åˆ—åˆ™å°ºç å¤šã€æ›´æ–°æ—¶é—´æ–°ï¼‰
            cand = (
                agg_df[(agg_df["product_code"] == code) & (agg_df["sizes_in_stock"] >= size_threshold) & agg_df["min_eff_price"].notna()]
                .sort_values(["min_eff_price", "sizes_in_stock", "latest"], ascending=[True, False, False])
                .head(1)
            )
            if cand.empty:
                continue

            new_site = cand.iloc[0]["site_name"]
            new_sizes = int(cand.iloc[0]["sizes_in_stock"])
            new_price = float(cand.iloc[0]["min_eff_price"] or 0.0)
            old_price = float(r.get("cur_min_eff_price") or 0.0)

            # è®°å½•å»ºè®®
            suggest.append({
                "product_code": code,
                "old_site": old_site,
                "old_sizes": int(cur_sizes or 0),
                "old_min_price": old_price,
                "new_site": new_site,
                "new_sizes": new_sizes,
                "new_min_price": new_price,
            })

        # æ‰§è¡Œåˆ‡æ¢ï¼ˆå¯é€‰ï¼‰
        if suggest and not dry_run:
            rows = [{"code": s["product_code"], "site": s["new_site"]} for s in suggest]
            conn.execute(text("""
                INSERT INTO barbour_supplier_map(product_code, site_name)
                VALUES (:code, :site)
                ON CONFLICT (product_code) DO UPDATE SET site_name = EXCLUDED.site_name
            """), rows)

    # æ‰“å°é¢„è§ˆ
    if suggest:
        print(f"å…±{len(suggest)}æ¡å»ºè®®ï¼š")
        for s in suggest[:30]:
            print(f"- {s['product_code']}: {s['old_site']}({s['old_sizes']}å°º) -> {s['new_site']}({s['new_sizes']}å°º), "
                  f"ä»· {s['old_min_price']} -> {s['new_min_price']}")
        if len(suggest) > 30:
            print("...ï¼ˆå…¶ä½™çœç•¥ï¼‰")
    else:
        print("æœªæ‰¾åˆ°éœ€è¦åˆ‡æ¢çš„å•†å“ï¼ˆå½“å‰æ˜ å°„ç«™ç‚¹å‡æ»¡è¶³å°ºç é˜ˆå€¼æˆ–æ— æ›´ä¼˜å€™é€‰ï¼‰ã€‚")

    return suggest


def export_supplier_stock_price_report(min_sizes_ok: int = 1, output_path: str | None = None) -> str:
    """
    å¯¼å‡ºæ¯ä¸ªå•†å“åœ¨å„ç«™ç‚¹çš„â€œåœ¨å”®å°ºç æ•°ã€æœ€ä½æœ‰æ•ˆä»·ã€æœ€è¿‘æ›´æ–°æ—¶é—´â€ï¼Œå¹¶æ ‡æ³¨å½“å‰æ˜ å°„ä¸æ¨èç«™ç‚¹ã€‚
    - min_sizes_ok: ç»Ÿè®¡â€œæœ‰è´§å°ºç æ•°â€çš„é˜ˆå€¼ï¼ˆé»˜è®¤>=1è§†ä¸ºæœ‰è´§å‚ä¸æœ€ä½ä»·è¯„é€‰ï¼‰
    - output_path: æŒ‡å®šå¯¼å‡ºxlsxè·¯å¾„ï¼›ä¸ä¼ åˆ™å†™åˆ° BARBOUR['OUTPUT_DIR']/barbour_supplier_report.xlsx
    """
    cfg = BRAND_CONFIG["barbour"]["PGSQL_CONFIG"]
    out_dir = Path(BARBOUR["OUTPUT_DIR"])
    out_dir.mkdir(parents=True, exist_ok=True)
    out_file = Path(output_path) if output_path else (out_dir / "barbour_supplier_report.xlsx")

    eng = create_engine(f"postgresql+psycopg2://{cfg['user']}:{cfg['password']}@{cfg['host']}:{cfg['port']}/{cfg['dbname']}")
    with eng.begin() as conn:
        # å½“å‰æ˜ å°„
        map_df = pd.read_sql("SELECT product_code, site_name FROM barbour_supplier_map", conn)

        # èšåˆå„ç«™ç‚¹è¡¨ç°ï¼ˆå’Œ fill_supplier_jingya_map å†…éƒ¨ SQL å£å¾„ä¸€è‡´ï¼‰
        sql = f"""
        WITH base AS (
          SELECT
            product_code,
            site_name,
            COALESCE(stock_count,0) AS stock_count,
            COALESCE(NULLIF(sale_price_gbp,0), NULLIF(price_gbp,0), original_price_gbp) AS eff_price,
            last_checked
          FROM barbour_offers
          WHERE is_active = TRUE
            AND product_code IS NOT NULL AND product_code <> ''
            AND site_name IS NOT NULL AND site_name <> ''
        ),
        agg AS (
          SELECT
            product_code,
            site_name,
            SUM(CASE WHEN stock_count > 0 THEN 1 ELSE 0 END)                       AS sizes_in_stock,
            MIN(eff_price) FILTER (WHERE stock_count > 0)                           AS min_eff_price,
            MAX(last_checked)                                                       AS latest
          FROM base
          GROUP BY product_code, site_name
        ),
        ranked AS (
          SELECT
            *,
            ROW_NUMBER() OVER (
              PARTITION BY product_code
              ORDER BY
                CASE WHEN sizes_in_stock >= 3 THEN 0 ELSE 1 END,   -- â‰¥3å°ºæœ‰è´§ä¼˜å…ˆ
                min_eff_price ASC NULLS LAST,
                sizes_in_stock DESC,
                latest DESC
            ) AS rank_all,
            ROW_NUMBER() OVER (
              PARTITION BY product_code
              ORDER BY
                CASE WHEN sizes_in_stock >= 3 THEN 0 ELSE 1 END,
                min_eff_price ASC NULLS LAST
            ) AS rank_price_first
          FROM agg
        )
        SELECT * FROM ranked
        """
        df = pd.read_sql(sql, conn)

    # è§„èŒƒ
    df["site_name"] = df["site_name"].map(lambda s: canonical_site(s) or s)
    map_df["site_name"] = map_df["site_name"].map(lambda s: canonical_site(s) or s)

    # æ ‡æ³¨â€œå½“å‰æ˜ å°„â€
    df = df.merge(map_df, on="product_code", how="left", suffixes=("", "_mapped"))
    df["is_current"] = (df["site_name"] == df["site_name_mapped"]).fillna(False)

    # æ¨èç«™ç‚¹ï¼ˆâ‰¥3å°ºæœ‰è´§ & ä»·æ ¼æœ€ä½ï¼‰
    best = (
        df[(df["sizes_in_stock"] >= 3) & df["min_eff_price"].notna()]
        .sort_values(["product_code", "min_eff_price", "sizes_in_stock", "latest"], ascending=[True, True, False, False])
        .drop_duplicates(["product_code"])
        .rename(columns={"site_name":"best_site", "min_eff_price":"best_min_eff_price", "sizes_in_stock":"best_sizes_in_stock"})
        [["product_code","best_site","best_min_eff_price","best_sizes_in_stock"]]
    )
    df = df.merge(best, on="product_code", how="left")

    # åªä¿ç•™æœ‰æ„ä¹‰çš„åˆ—
    out = df[[
        "product_code",
        "site_name",
        "is_current",
        "sizes_in_stock",
        "min_eff_price",
        "latest",
        "site_name_mapped",
        "best_site",
        "best_min_eff_price",
        "best_sizes_in_stock",
        "rank_all",
        "rank_price_first",
    ]].sort_values(["product_code", "is_current"], ascending=[True, False])

    out.to_excel(out_file, index=False)
    return str(out_file)


import pandas as pd
from sqlalchemy import create_engine, text

def apply_barbour_supplier_overrides(xlsx_path: str, dry_run: bool = False) -> None:
    """
    æŒ‰ Excel æ–‡ä»¶æ‰‹åŠ¨æŒ‡å®š Barbour å•†å“ä¾›è´§å•†ã€‚
    Excel è¦æ±‚ï¼š
      - ç¬¬ä¸€åˆ—ï¼šå•†å“ç¼–ç ï¼ˆåˆ—åå¿…é¡»ä¸º â€œå•†å“ç¼–ç â€ï¼‰
      - ç¬¬äºŒåˆ—ï¼šä¾›è´§å•†ï¼ˆåˆ—åå¿…é¡»ä¸º â€œä¾›è´§å•†â€ï¼‰
    ä¼šå°†å¯¹åº”å…³ç³»å†™å…¥ barbour_supplier_mapï¼ˆæœ‰åˆ™æ›´æ–°ï¼Œæ— åˆ™æ’å…¥ï¼‰ã€‚
    dry_run=True æ—¶åªé¢„è§ˆä¸å†™åº“ã€‚
    """
    cfg = BRAND_CONFIG["barbour"]["PGSQL_CONFIG"]
    engine = create_engine(
        f"postgresql+psycopg2://{cfg['user']}:{cfg['password']}@{cfg['host']}:{cfg['port']}/{cfg['dbname']}"
    )

    # 1) è¯»å– Excelï¼ˆè¦æ±‚å«è¡¨å¤´ï¼‰
    df = pd.read_excel(xlsx_path, dtype=str)
    required_cols = ["å•†å“ç¼–ç ", "ä¾›è´§å•†"]
    if not all(c in df.columns for c in required_cols):
        raise ValueError(f"Excel å¿…é¡»åŒ…å«åˆ—ï¼š{required_cols}ï¼Œå½“å‰è¡¨å¤´ï¼š{list(df.columns)}")

    df = df[required_cols].rename(columns={"å•†å“ç¼–ç ": "product_code", "ä¾›è´§å•†": "site_name"})
    df["product_code"] = df["product_code"].astype(str).str.strip()
    df["site_name"] = df["site_name"].astype(str).str.strip()
    df = df[(df["product_code"] != "") & (df["site_name"] != "")].drop_duplicates()

    if df.empty:
        print("[INFO] Excel ä¸­æ— æœ‰æ•ˆæ•°æ®ã€‚")
        return

    # ç«™ç‚¹å½’ä¸€åŒ–
    df["site_name"] = df["site_name"].map(lambda s: canonical_site(s) or s)

    print(f"[INFO] è¯»å– {len(df)} æ¡ä¾›è´§å•†æŒ‡å®šè®°å½•ã€‚ç¤ºä¾‹å‰5æ¡ï¼š")
    for _, row in df.head(5).iterrows():
        print(f"  - {row['product_code']} -> {row['site_name']}")
    if len(df) > 5:
        print("  ...")

    # 2) æ‰§è¡Œå†™å…¥
    if dry_run:
        print("[DRY-RUN] ä»…é¢„è§ˆï¼Œä¸å†™å…¥æ•°æ®åº“ã€‚")
        return

    with engine.begin() as conn:
        conn.execute(text("""
            CREATE TABLE IF NOT EXISTS barbour_supplier_map (
              product_code VARCHAR(50) PRIMARY KEY,
              site_name    VARCHAR(100) NOT NULL
            )
        """))
        conn.execute(text("""
            INSERT INTO barbour_supplier_map(product_code, site_name)
            VALUES (:product_code, :site_name)
            ON CONFLICT (product_code) DO UPDATE SET site_name = EXCLUDED.site_name
        """), df.to_dict(orient="records"))
        print(f"[OK] å·²æˆåŠŸæ›´æ–° {len(df)} æ¡ä¾›è´§å•†æ˜ å°„ã€‚")
