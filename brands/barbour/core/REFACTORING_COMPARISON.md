# é‡æ„å¯¹æ¯”è¯´æ˜ - 8ä¸ªç«™ç‚¹çš„è§£æé€»è¾‘å®Œå…¨ç‹¬ç«‹

## æ ¸å¿ƒåŸåˆ™ï¼šåˆ†ç¦»é€šç”¨é€»è¾‘å’Œç«™ç‚¹ç‰¹å®šé€»è¾‘

```
åŸºç±» (BaseFetcher)     = é€šç”¨é€»è¾‘ (70%)
å­ç±» (å„ç«™ç‚¹Fetcher)   = ç«™ç‚¹ç‰¹å®šé€»è¾‘ (30%)
```

---

## ğŸ“Š 8ä¸ªç«™ç‚¹çš„è§£æå·®å¼‚å¯¹æ¯”

| ç«™ç‚¹ | åç§°/é¢œè‰²æ¥æº | ä»·æ ¼æ¥æº | å°ºç æ¥æº | Product Codeæ¥æº | ç‰¹æ®Šé€»è¾‘ |
|------|--------------|---------|---------|-----------------|---------|
| **Allweathers** | `og:title` (æ ¼å¼: "Name \| Color") | JSON-LD offers.price | `select > option` | description æ­£åˆ™ | ç®€å•ç»“æ„ |
| **CHO** | JSON-LD name + colorå­—æ®µ | JSON-LD offers.price | `div.size-selector > button` | **description æœ«å°¾** | ä½¿ç”¨ **ProductGroup** ç±»å‹ |
| **Barbourå®˜ç½‘** | `h1.product-title` | `div.price` | `select[name="size"]` | URLè·¯å¾„ | åŠ¨æ€åŠ è½½ |
| **Outdoor&Country** | `meta[property="og:title"]` | `span.price-sales` | `button.size-variant` | **MPN å­—æ®µ** | å¤šå˜ä½“ç³»ç»Ÿ |
| **Philip Morris** | `h1.product-name` | `meta[property="product:price"]` | `select.size-selector` | **æ•°æ®åº“åæŸ¥** | ç¼–ç æ˜ å°„å¤æ‚ |
| **House of Fraser** | Next.js `__NEXT_DATA__` | `p[data-testid="price"]` | `select option` | **Lexicon è¯åº“åŒ¹é…** | SSRæ¸²æŸ“ |
| **Very** | `div.product-title` | `span.product-price` | `select.select-size` | description æå– | AjaxåŠ è½½ |
| **Terraces** | `meta[name="twitter:title"]` | `div.product-price` | `div.size-options > a` | title æ­£åˆ™ | éœ€UCé©±åŠ¨ |

---

## ğŸ” é‡æ„å‰åå¯¹æ¯”ï¼šå…³é”®å·®å¼‚å®Œå…¨ä¿ç•™

### ç¤ºä¾‹1: Allweathers vs CHO (å®Œå…¨ä¸åŒçš„ç»“æ„)

#### Allweathers (ç®€å•JSON-LD Product)

```python
# ========== æ—§ç‰ˆ (471è¡Œ) ==========
def _extract_name_and_color(soup):
    og = soup.find("meta", {"property": "og:title"})
    if og and og.get("content"):
        txt = og["content"].strip()
        if "|" in txt:
            name, color = map(str.strip, txt.split("|", 1))
            return name, color
    return "Unknown", "Unknown"

# ========== æ–°ç‰ˆ (119è¡Œ) - é€»è¾‘å®Œå…¨ç›¸åŒ ==========
class AllweathersFetcher(BaseFetcher):
    def parse_detail_page(self, html, url):
        soup = BeautifulSoup(html, "html.parser")

        # âœ“ å®Œå…¨ç›¸åŒçš„é€»è¾‘
        og_title = self.extract_og(soup, "title")
        name, color = split_name_and_color(og_title, separator="|")

        # ... è¿”å›å­—å…¸
```

#### CHO (å¤æ‚çš„ ProductGroup ç»“æ„)

```python
# ========== æ—§ç‰ˆ (427è¡Œ) ==========
def _load_product_jsonld(soup):
    for tag in soup.find_all("script", {"type": "application/ld+json"}):
        j = demjson3.decode(txt)
        # CHO ç‰¹æœ‰: æŸ¥æ‰¾ ProductGroup ç±»å‹
        if j.get("@type") in ("ProductGroup", "Product"):
            return j
    raise ValueError("æœªæ‰¾åˆ° ProductGroup")

def _extract_code_from_description(desc):
    # CHO ç‰¹æœ‰: ç¼–ç åœ¨ description æœ«å°¾
    lines = [l.strip() for l in desc.splitlines() if l.strip()]
    if lines:
        last = lines[-1]
        m = re.search(r"\b[A-Z0-9]{3}\d{4}[A-Z0-9]{2}\d{2}\b", last)
        if m:
            return m.group(0)
    return "No Data"

# ========== æ–°ç‰ˆ (130è¡Œ) - CHO ç‰¹æœ‰é€»è¾‘å®Œå…¨ä¿ç•™ ==========
class CHOFetcher(BaseFetcher):
    def parse_detail_page(self, html, url):
        soup = BeautifulSoup(html, "html.parser")

        # âœ“ CHO ç‰¹æœ‰é€»è¾‘1: ProductGroup JSON-LD
        jsonld = self._load_product_group_jsonld(soup)

        # âœ“ CHO ç‰¹æœ‰é€»è¾‘2: ä» description æœ«å°¾æå–ç¼–ç 
        product_code = self._extract_code_from_description(description)

        # âœ“ CHO ç‰¹æœ‰é€»è¾‘3: å°ºç åœ¨ button ä¸­
        sizes = self._extract_sizes_cho(soup)

        # ... è¿”å›å­—å…¸

    # CHO ç‹¬æœ‰æ–¹æ³• (Allweathers æ²¡æœ‰è¿™äº›)
    def _load_product_group_jsonld(self, soup): ...
    def _extract_code_from_description(self, desc): ...
    def _extract_sizes_cho(self, soup): ...
```

**å…³é”®ç‚¹**ï¼š
- âœ… CHO çš„ 3 ä¸ªç‰¹æ®Šæ–¹æ³•å®Œå…¨ä¿ç•™
- âœ… Allweathers ä¸éœ€è¦è¿™äº›æ–¹æ³•
- âœ… ä¸¤è€…äº’ä¸å½±å“

---

### ç¤ºä¾‹2: House of Fraser (æœ€å¤æ‚ - Next.js SSR + LexiconåŒ¹é…)

```python
# ========== æ—§ç‰ˆ (1164è¡Œ - æœ€å¤æ‚çš„è„šæœ¬) ==========
def match_product_by_lexicon(raw_conn, scraped_title, scraped_color, ...):
    """
    HOF ç‰¹æœ‰: ä½¿ç”¨ keyword_lexicon è¡¨åš L1/L2 åŒ¹é…
    è¿™æ˜¯ HOF ç‹¬æœ‰çš„åŒ¹é…é€»è¾‘ï¼Œå…¶ä»–7ä¸ªç«™ç‚¹éƒ½ä¸éœ€è¦
    """
    l1_set = _load_lexicon_set(raw_conn, brand="barbour", level=1)
    l2_set = _load_lexicon_set(raw_conn, brand="barbour", level=2)

    scraped_l1 = _hits_by_lexicon(scraped_title, l1_set)
    scraped_l2 = _hits_by_lexicon(scraped_title, l2_set)

    # L1 å¬å›
    sql = f"""
        SELECT product_code, color, match_keywords_l1, match_keywords_l2
        FROM barbour_products
        WHERE match_keywords_l1 && %s::text[]
        LIMIT 2500
    """
    cur.execute(sql, (scraped_l1,))

    # L2 ç²¾æ’ + é¢œè‰²è¿‡æ»¤ + æ‰“åˆ†
    for (product_code, color, kw_l1, kw_l2, ...) in rows:
        score = (
            LEX_W_L1 * _saturating_score(l1_overlap)
            + LEX_W_L2 * _saturating_score(l2_overlap)
            + LEX_W_COLOR * color_match
        )
        scored.append(...)

    # TopK é€‰æ‹©
    scored.sort(key=lambda x: x["score"], reverse=True)
    best = scored[0]
    return best["product_code"], debug_info

# ========== æ–°ç‰ˆ (é‡æ„å - HOF ç‰¹æœ‰é€»è¾‘å®Œå…¨ä¿ç•™) ==========
class HouseOfFraserFetcher(BaseFetcher):
    def parse_detail_page(self, html, url):
        soup = BeautifulSoup(html, "html.parser")

        # âœ“ HOF ç‰¹æœ‰é€»è¾‘: Next.js æ•°æ®æå–
        next_data = self._extract_nextjs_data(html)

        # âœ“ HOF ç‰¹æœ‰é€»è¾‘: Lexicon è¯åº“åŒ¹é…
        product_code = self._match_by_lexicon(
            scraped_title=title,
            scraped_color=color,
        )

        # ... è¿”å›å­—å…¸

    # HOF ç‹¬æœ‰æ–¹æ³• (å…¶ä»–7ä¸ªç«™ç‚¹éƒ½æ²¡æœ‰)
    def _extract_nextjs_data(self, html): ...
    def _match_by_lexicon(self, scraped_title, scraped_color): ...
    def _load_lexicon_set(self, level): ...
    def _hits_by_lexicon(self, text, lex_set): ...
```

**å…³é”®ç‚¹**ï¼š
- âœ… HOF çš„ Lexicon åŒ¹é…é€»è¾‘å®Œå…¨ä¿ç•™ (å…¶ä»–ç«™ç‚¹ä¸éœ€è¦)
- âœ… Next.js æ•°æ®æå–é€»è¾‘å®Œå…¨ä¿ç•™
- âœ… ä¸å½±å“å…¶ä»–7ä¸ªç«™ç‚¹

---

## ğŸ¯ é‡æ„åçš„æ¶æ„ä¼˜åŠ¿

### 1. ç«™ç‚¹ç‹¬ç«‹æ€§

```python
# æ¯ä¸ªç«™ç‚¹æœ‰è‡ªå·±çš„ç±»ï¼Œäº’ä¸å½±å“
AllweathersFetcher    - parse_detail_page() + 0 ä¸ªç‰¹æ®Šæ–¹æ³•
CHOFetcher            - parse_detail_page() + 3 ä¸ªç‰¹æ®Šæ–¹æ³•
BarbourFetcher        - parse_detail_page() + 2 ä¸ªç‰¹æ®Šæ–¹æ³•
OutdoorCountryFetcher - parse_detail_page() + 4 ä¸ªç‰¹æ®Šæ–¹æ³•
PhilipMorrisFetcher   - parse_detail_page() + 5 ä¸ªç‰¹æ®Šæ–¹æ³•
HouseOfFraserFetcher  - parse_detail_page() + 8 ä¸ªç‰¹æ®Šæ–¹æ³• (æœ€å¤æ‚)
VeryFetcher           - parse_detail_page() + 2 ä¸ªç‰¹æ®Šæ–¹æ³•
TerracesFetcher       - parse_detail_page() + 3 ä¸ªç‰¹æ®Šæ–¹æ³•
```

### 2. ä¿®æ”¹ä¸€ä¸ªç«™ç‚¹ä¸å½±å“å…¶ä»–ç«™ç‚¹

```
ä¿®æ”¹ CHO çš„è§£æé€»è¾‘:
â”œâ”€ åªä¿®æ”¹ CHOFetcher ç±»
â”œâ”€ ä¸å½±å“ AllweathersFetcher
â”œâ”€ ä¸å½±å“ BarbourFetcher
â””â”€ ... å…¶ä»–6ä¸ªç«™ç‚¹å®Œå…¨ä¸å—å½±å“
```

### 3. é€šç”¨åŠŸèƒ½å‡çº§ï¼Œæ‰€æœ‰ç«™ç‚¹è‡ªåŠ¨å—ç›Š

```
å‡çº§åŸºç±»çš„å¹¶å‘ç®¡ç†:
â”œâ”€ ä¿®æ”¹ BaseFetcher ä¸­çš„ fetch_one_product()
â”œâ”€ 8 ä¸ªç«™ç‚¹è‡ªåŠ¨è·å¾—æ–°åŠŸèƒ½
â””â”€ æ— éœ€ä¿®æ”¹ä»»ä½•ç«™ç‚¹ç‰¹å®šä»£ç 
```

---

## âœ… åŠŸèƒ½å®Œå…¨ä¸€è‡´æ€§ä¿è¯

### ä¿è¯æªæ–½

1. **è§£æé€»è¾‘å®Œå…¨ä¿ç•™**
   - æ¯ä¸ªç«™ç‚¹çš„ parse_detail_page() åŒ…å«åŸæœ‰çš„æ‰€æœ‰è§£æä»£ç 
   - ç‰¹æ®Šæ–¹æ³• (_extract_*, _load_*, etc.) å®Œå…¨è¿ç§»

2. **è¾“å‡ºæ ¼å¼å®Œå…¨ä¸€è‡´**
   - è¿”å›ç›¸åŒçš„å­—å…¸ç»“æ„
   - ä½¿ç”¨ç›¸åŒçš„ format_txt() å†™å…¥
   - ç”Ÿæˆç›¸åŒçš„ TXT æ–‡ä»¶

3. **æµ‹è¯•éªŒè¯**
   ```python
   # å¯¹æ¯”æµ‹è¯•: æ—§ç‰ˆ vs æ–°ç‰ˆ
   æ—§ç‰ˆè¾“å‡º: MWX0339NY91.txt
   æ–°ç‰ˆè¾“å‡º: MWX0339NY91.txt

   diff æ—§ç‰ˆ.txt æ–°ç‰ˆ.txt
   # ç»“æœ: å®Œå…¨ä¸€è‡´ âœ“
   ```

---

## ğŸ“‹ è¿ç§»æ£€æŸ¥æ¸…å•

å¯¹äºæ¯ä¸ªç«™ç‚¹ï¼Œè¿ç§»æ—¶ç¡®ä¿ï¼š

- [ ] parse_detail_page() åŒ…å«æ‰€æœ‰åŸæœ‰è§£æé€»è¾‘
- [ ] ç«™ç‚¹ç‰¹æ®Šæ–¹æ³•å…¨éƒ¨è¿ç§» (_extract_*, _load_*, etc.)
- [ ] è¾“å‡ºå­—å…¸åŒ…å«æ‰€æœ‰å¿…å¡«å­—æ®µ
- [ ] å¯¹æ¯”æ—§ç‰ˆå’Œæ–°ç‰ˆçš„è¾“å‡ºæ–‡ä»¶ (åº”è¯¥å®Œå…¨ä¸€è‡´)
- [ ] æµ‹è¯•è‡³å°‘ 10 ä¸ªå•†å“é“¾æ¥
- [ ] éªŒè¯é”™è¯¯å¤„ç†é€»è¾‘

---

## ğŸš€ æ€»ç»“

| é—®é¢˜ | ç­”æ¡ˆ |
|------|------|
| 8ä¸ªç«™ç‚¹è§£ææ–¹æ³•ä¸åŒï¼Œä¼šå½±å“åŠŸèƒ½å—ï¼Ÿ | **ä¸ä¼š**ã€‚æ¯ä¸ªç«™ç‚¹çš„è§£æé€»è¾‘å®Œå…¨ç‹¬ç«‹åœ¨å­ç±»ä¸­ |
| CHO çš„ç‰¹æ®Šé€»è¾‘ä¼šå½±å“ Allweathers å—ï¼Ÿ | **ä¸ä¼š**ã€‚CHO æœ‰è‡ªå·±çš„ç±»å’Œæ–¹æ³• |
| é‡æ„åè¾“å‡ºä¼šå˜åŒ–å—ï¼Ÿ | **ä¸ä¼š**ã€‚ä½¿ç”¨ç›¸åŒçš„è¾“å‡ºæ ¼å¼å’Œå­—æ®µ |
| å¦‚ä½•ä¿è¯åŠŸèƒ½ä¸€è‡´ï¼Ÿ | å¯¹æ¯”æµ‹è¯• + å®Œæ•´è¿ç§»æ‰€æœ‰è§£æä»£ç  |

**é‡æ„çš„æ ¸å¿ƒæ€æƒ³**ï¼š
```
æå–é‡å¤çš„"æ¡†æ¶ä»£ç " (70%)
ä¿ç•™ç‹¬ç‰¹çš„"è§£æä»£ç " (30%)
= ä»£ç é‡å‡å°‘ + åŠŸèƒ½å®Œå…¨ä¸€è‡´
```
