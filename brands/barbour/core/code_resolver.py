# -*- coding: utf-8 -*-
"""
Barbour | é€šç”¨ç¼–ç è§£æå™¨
ä¾› house / philipmorrisdirect / ä»¥åå…¶å®ƒç«™ç‚¹å…±äº«ï¼š
  - å¯åŠ¨æ—¶é¢„çƒ­ URLâ†’Code ç¼“å­˜
  - æ¯ä¸ªå•†å“é¡µé¢è§£ææ—¶ï¼Œç»Ÿä¸€é€šè¿‡ resolve_barbour_code ç¡®å®š Product Code
"""

from __future__ import annotations
from typing import Optional, Dict
from collections import OrderedDict

from sqlalchemy.engine import Connection

from brands.barbour.core.sim_matcher import match_product, choose_best
from brands.barbour.common.barbour_import_candidates import find_code_by_site_url  # ä½ å·²æœ‰çš„å°å·¥å…·

# ===== URLâ†’Code ç¼“å­˜ =====
URL_CODE_CACHE: Dict[str, str] = {}
_URL_CODE_CACHE_READY = False


def _normalize_url(u: str) -> str:
    return u.strip() if u else ""


def get_dbapi_connection(conn_or_engine):
    """ä» SQLAlchemy Connection/Engine æå–åŸå§‹ psycopg2 è¿æ¥ã€‚"""
    if hasattr(conn_or_engine, "cursor"):
        return conn_or_engine
    if hasattr(conn_or_engine, "raw_connection"):
        return conn_or_engine.raw_connection()
    c = getattr(conn_or_engine, "connection", None)
    if c is not None:
        dbapi = getattr(c, "dbapi_connection", None)
        if dbapi is not None and hasattr(dbapi, "cursor"):
            return dbapi
        inner = getattr(c, "connection", None)
        if inner is not None and hasattr(inner, "cursor"):
            return inner
        if hasattr(c, "cursor"):
            return c
    return conn_or_engine


def _safe_sql_to_cache(raw_conn, sql: str, params=None) -> Dict[str, str]:
    cache = OrderedDict()
    try:
        with raw_conn.cursor() as cur:
            cur.execute(sql, params or {})
            for url, code in cur.fetchall():
                if url and code:
                    cache[_normalize_url(str(url))] = str(code).strip()
    except Exception:
        try:
            raw_conn.rollback()
        except Exception:
            pass
    return cache


def build_url_code_cache(raw_conn, products_table: str, offers_table: Optional[str], site_name: str):
    """
    å¯åŠ¨æ—¶æ„å»ºä¸€æ¬¡ URLâ†’ProductCode æ˜ å°„ç¼“å­˜ã€‚
    - å…ˆçœ‹ offers è¡¨ï¼ˆä»¥ site_name åŒºåˆ†ç«™ç‚¹ï¼‰
    - å†çœ‹ barbour_products é‡Œçš„ source_url/offer_url/product_url
    """
    global URL_CODE_CACHE, _URL_CODE_CACHE_READY
    if _URL_CODE_CACHE_READY:
        return URL_CODE_CACHE

    cache = OrderedDict()

    # 1) offers è¡¨é‡Œè®°å½•è¿‡ç¼–ç çš„
    if offers_table:
        candidates = [
            ("offer_url",   "product_code"),
            ("source_url",  "product_code"),
            ("product_url", "product_code"),
            ("offer_url",   "color_code"),
            ("source_url",  "color_code"),
            ("product_url", "color_code"),
        ]
        for url_col, code_col in candidates:
            sql = f"""
                SELECT {url_col}, {code_col}
                  FROM {offers_table}
                 WHERE site_name = %(site)s
                   AND {url_col} IS NOT NULL
                   AND {code_col} IS NOT NULL
            """
            cache.update(_safe_sql_to_cache(raw_conn, sql, {"site": site_name}))

    # 2) barbour_products é‡Œçš„ URLâ†’product_code
    for url_col in ("source_url", "offer_url", "product_url"):
        sql = f"""
            SELECT {url_col}, product_code
              FROM {products_table}
             WHERE {url_col} IS NOT NULL
               AND product_code IS NOT NULL
        """
        cache.update(_safe_sql_to_cache(raw_conn, sql))

    URL_CODE_CACHE = dict(cache)
    _URL_CODE_CACHE_READY = True
    print(f"ğŸ§  URLâ†’Code ç¼“å­˜æ„å»ºå®Œæˆï¼š{len(URL_CODE_CACHE)} æ¡")
    return URL_CODE_CACHE


def resolve_barbour_code(
    conn: Connection,
    *,
    site_name: str,
    url: str,
    products_table: str,
    offers_table: Optional[str],
    scraped_title: str,
    scraped_color: str,
    sku_guess: Optional[str],
    # ä¸‹é¢è¿™äº›åŸºæœ¬ç”¨ house å½“å‰çš„é»˜è®¤å€¼
    min_score: float = 0.72,
    min_lead: float = 0.04,
    name_weight: float = 0.75,
    color_weight: float = 0.25,
) -> str:
    """
    ç»™å®šä¸€ä¸ªç«™ç‚¹ + URL + æ ‡é¢˜/é¢œè‰²/sku_guessï¼Œè¿”å›æœ€ç»ˆ Product Codeï¼š

      1. å…ˆæŸ¥ barbour_products ä¸­æ˜¯å¦å·²ç»™è¿™ä¸ª (site,url) åšè¿‡äººå·¥æ˜ å°„
         ï¼ˆbarbour_import_candidates å¯¼å…¥åçš„ç»“æœï¼‰
      2. å†ç”¨ URLâ†’Code ç¼“å­˜ï¼ˆoffers + productsï¼‰
      3. å†ç”¨ sim_matcher åœ¨ barbour_products é‡Œåšæ¨¡ç³ŠåŒ¹é…
      4. å†å…œåº•ç”¨ sku_guess
    """
    raw_conn = get_dbapi_connection(conn)
    norm_url = _normalize_url(url)

    # 0. æ‰‹åŠ¨é…ç½®ä¼˜å…ˆï¼ˆä½ åœ¨ barbour_product_candidates é‡Œå¡«å¥½ï¼Œè·‘ import ä¹‹å
    #    ä¼šå†™è¿› barbour_productsï¼Œå¹¶ä¸” find_code_by_site_url å°±èƒ½å‘½ä¸­ï¼‰
    manual_code = find_code_by_site_url(raw_conn, site_name, norm_url)
    if manual_code:
        return manual_code

    # 1. URLâ†’Code ç¼“å­˜ï¼ˆå¯åŠ¨æ—¶å·² buildï¼Œä¸€èˆ¬å‘½ä¸­ç‡å¾ˆé«˜ï¼‰
    if not _URL_CODE_CACHE_READY:
        build_url_code_cache(raw_conn, products_table, offers_table, site_name)

    final_code = URL_CODE_CACHE.get(norm_url)
    if final_code:
        return final_code

    # 2. DB æ¨¡ç³ŠåŒ¹é…ï¼ˆæ ‡é¢˜ + é¢œè‰²ï¼‰
    results = match_product(
        raw_conn,
        scraped_title=scraped_title or "",
        scraped_color=scraped_color or "",
        table=products_table,
        name_weight=name_weight,
        color_weight=color_weight,
        type_weight=(1.0 - name_weight - color_weight),
        topk=5,
        recall_limit=2000,
        min_name=0.92,
        min_color=0.85,
        require_color_exact=False,
        require_type=False,
    )
    chosen = choose_best(results, min_score=min_score, min_lead=min_lead)
    if chosen:
        return chosen

    # 3. å…œåº•ï¼šç”¨ JSON-LD é‡Œçš„ sku_guess
    sku_guess = (sku_guess or "").strip()
    if sku_guess and sku_guess != "No Data":
        return sku_guess

    return "No Data"
