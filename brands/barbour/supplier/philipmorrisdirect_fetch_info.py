# -*- coding: utf-8 -*-
"""
Philip Morris Direct é‡‡é›†å™¨ - é‡æ„ç‰ˆ (ä½¿ç”¨ BaseFetcher)

åŸºäº philipmorrisdirect_fetch_info_v2.py é‡æ„
ç‰¹ç‚¹:
- æ•°æ®åº“åæŸ¥ç¼–ç  (barbour_color_map + barbour_products)
- meta[property="product:price"] ä»·æ ¼
- å¤æ‚çš„ç¼–ç æ˜ å°„ (MPN æå– + DB å…œåº•)
- å¤šé¢œè‰²é¡µé¢é€è‰²å¤„ç†

å¯¹æ¯”:
- æ—§ç‰ˆ (philipmorrisdirect_fetch_info_v2.py): 912 è¡Œ
- æ–°ç‰ˆ (æœ¬æ–‡ä»¶): ~400 è¡Œ
- ä»£ç å‡å°‘: 56%

ä½¿ç”¨æ–¹å¼:
    python -m brands.barbour.supplier.philipmorrisdirect_fetch_info_v3
"""

from __future__ import annotations

import re
import time
from pathlib import Path
from typing import Dict, Any, List, Optional
from bs4 import BeautifulSoup

# å¯¼å…¥åŸºç±»å’Œå·¥å…·
from brands.barbour.core.base_fetcher import BaseFetcher, setup_logging

# Selenium
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# é…ç½®
from config import BARBOUR
import psycopg2

SITE_NAME = "Philip Morris"
LINKS_FILE = BARBOUR["LINKS_FILES"]["philipmorris"]
OUTPUT_DIR = BARBOUR["TXT_DIRS"]["philipmorris"]
PGSQL_CONFIG = BARBOUR["PGSQL_CONFIG"]

# é—®é¢˜æ–‡ä»¶ç›®å½•
TXT_PROBLEM_DIR = OUTPUT_DIR.parent / "TXT.problem"
TXT_PROBLEM_DIR.mkdir(parents=True, exist_ok=True)


# ================== é¢œè‰²æ˜ å°„ç¼“å­˜ ==================

_COLOR_MAP_CACHE: Dict[str, List[str]] = {}
_COLOR_MAP_LOADED = False


def _normalize_color_tokens(s: str) -> List[str]:
    """æ ‡å‡†åŒ–é¢œè‰²æ–‡æœ¬ä¸ºè¯åˆ—è¡¨"""
    if not s:
        return []
    s = s.lower()
    s = re.sub(r"[\/,&\-]+", " ", s)
    s = re.sub(r"[^a-z0-9\s]+", " ", s)
    tokens = [t for t in s.split() if t]
    return tokens


def _color_key(s: str) -> str:
    """ç”Ÿæˆé¢œè‰²é”®"""
    tokens = _normalize_color_tokens(s)
    if not tokens:
        return ""
    return " ".join(sorted(tokens))


def load_color_map_from_db() -> None:
    """ä»æ•°æ®åº“åŠ è½½é¢œè‰²æ˜ å°„"""
    global _COLOR_MAP_LOADED, _COLOR_MAP_CACHE

    if _COLOR_MAP_LOADED:
        return

    try:
        conn = psycopg2.connect(**PGSQL_CONFIG)
        cur = conn.cursor()
        cur.execute(
            """
            SELECT color_code, raw_name, norm_key, source, is_confirmed
            FROM barbour_color_map
            ORDER BY
                norm_key,
                CASE
                    WHEN source = 'config_code_map' THEN 0
                    WHEN source = 'products'       THEN 1
                    ELSE 2
                END,
                color_code
            """
        )
        rows = cur.fetchall()
        cur.close()
        conn.close()
    except Exception as e:
        print(f"âš ï¸ ä» barbour_color_map è¯»å–é¢œè‰²æ˜ å°„å¤±è´¥: {e}")
        _COLOR_MAP_LOADED = True
        _COLOR_MAP_CACHE = {}
        return

    cache: Dict[str, List[str]] = {}

    for color_code, raw_name, norm_key, source, is_confirmed in rows:
        key = norm_key or _color_key(raw_name or "")
        if not key:
            continue

        codes = cache.setdefault(key, [])
        if color_code in codes:
            continue

        if source == "config_code_map":
            codes.insert(0, color_code)
        else:
            codes.append(color_code)

    _COLOR_MAP_CACHE = cache
    _COLOR_MAP_LOADED = True
    print(f"ğŸ¨ å·²ä» barbour_color_map è½½å…¥ {len(rows)} æ¡é¢œè‰²è®°å½•")


def map_color_to_codes(color: str) -> List[str]:
    """é¢œè‰²æ–‡æœ¬ -> é¢œè‰²ç åˆ—è¡¨"""
    if not color:
        return []

    load_color_map_from_db()

    key = _color_key(color)
    if not key:
        return []

    codes = _COLOR_MAP_CACHE.get(key, [])
    return codes


def map_color_to_code(color: str) -> Optional[str]:
    """é¢œè‰²æ–‡æœ¬ -> é¦–ä¸ªé¢œè‰²ç """
    codes = map_color_to_codes(color)
    return codes[0] if codes else None


# ================== MPN æå– ==================

def extract_all_mpns_plus(html: str) -> List[str]:
    """
    PLUS ç‰ˆ: æå–é¡µé¢æ‰€æœ‰ Barbour MPN
    - MPN: <span>XXXX, YYYY</span>
    - JSON-LD é‡Œçš„ "MPN:\u00a0XXXX"
    - MANUFACTURER'S CODES ç´§æŒ¨ç€
    """
    if not html:
        return []

    results: List[str] = []
    seen = set()

    # è§„èŒƒåŒ–æ–‡æœ¬: å¤„ç† \u00a0 / &nbsp;
    text_norm = html.replace("\\u00a0", " ").replace("&nbsp;", " ")

    # 1) MPN: <span>XXX, YYY</span>
    m = re.search(
        r"MPN:\s*(?:<[^>]*>)*\s*([A-Z0-9,\s]+)</",
        text_norm,
        flags=re.IGNORECASE,
    )
    if m:
        raw = m.group(1)
        for token in re.split(r"[,\s]+", raw):
            token = token.strip().upper()
            if re.match(r"^[A-Z]{3}\d{4}[A-Z]{2}\d{2,4}$", token):
                if token not in seen:
                    seen.add(token)
                    results.append(token)

    # 2) MPN: XXX, YYY Colour: ...
    m = re.search(r"MPN:\s*([A-Z0-9,\s]+)", text_norm, re.I)
    if m:
        raw = m.group(1)
        for token in re.split(r"[,\s]+", raw):
            token = token.strip().upper()
            if re.match(r"^[A-Z]{3}\d{4}[A-Z]{2}\d{2,4}$", token):
                if token not in seen:
                    seen.add(token)
                    results.append(token)

    # 3) MANUFACTURER'S CODES ç´§æŒ¨ç€
    for m in re.finditer(
        r"MANUFACTURER'?S\s+CODE\S*([A-Z]{3}\d{4}[A-Z]{2}\d{2,4})",
        text_norm,
        flags=re.IGNORECASE,
    ):
        token = m.group(1).upper()
        if re.match(r"^[A-Z]{3}\d{4}[A-Z]{2}\d{2,4}$", token):
            if token not in seen:
                seen.add(token)
                results.append(token)

    # 4) å…¨å±€å…œåº•
    for token in re.findall(r"([A-Z]{3}\d{4}[A-Z]{2}\d{2,4})", text_norm):
        token = token.upper()
        if token not in seen:
            seen.add(token)
            results.append(token)

    return results


def extract_style_code(html: str) -> Optional[str]:
    """æå– 7 ä½æ¬¾å¼ç¼–ç  (ä¸å«é¢œè‰²/å°ºç )"""
    text = html or ""

    # å…ˆå°è¯•å®Œæ•´ MPN
    mpns = extract_all_mpns_plus(text)
    if mpns:
        return mpns[0][:7]

    # å…œåº•
    m = re.search(r"MPN:\s*([A-Z0-9,\s]+)", text, re.I)
    if m:
        raw = m.group(1)
        for token in re.split(r"[,\s]+", raw):
            token = token.strip().upper()
            if re.match(r"^[A-Z]{3}\d{4}[A-Z0-9]{0,6}$", token):
                return token[:7]

    m = re.search(r"([A-Z]{3}\d{4}[A-Z]{2}\d{2,4})", text)
    if m:
        return m.group(1)[:7]

    m = re.search(r"([A-Z]{3}\d{4})", text)
    if m:
        return m.group(1)

    return None


# ================== æ•°æ®åº“åŒ¹é… ==================

def find_product_code_in_db(style: str, color: str, url: str) -> Optional[str]:
    """
    é€šè¿‡æ¬¾å¼ + é¢œè‰²ä»æ•°æ®åº“æŸ¥æ‰¾ product_code

    ä¼˜å…ˆ: style + color_map é¢œè‰²ç å‰ç¼€
    å…œåº•: style + é¢œè‰²æ–‡æœ¬ç›´æ¥åŒ¹é…
    """
    if not style or not color:
        return None

    style_u = style.strip().upper()
    color_s = (color or "").strip()

    sql_prefix = """
        SELECT product_code
        FROM barbour_products
        WHERE product_code ILIKE %s
        ORDER BY product_code
        LIMIT 1
    """

    sql_fallback = """
        SELECT product_code
        FROM barbour_products
        WHERE SUBSTRING(product_code, 1, 7) = %s
          AND (
                LOWER(TRIM(color)) = LOWER(TRIM(%s))
                OR color ILIKE %s
          )
        ORDER BY product_code
        LIMIT 1
    """

    color_codes = map_color_to_codes(color_s) or []

    try:
        conn = psycopg2.connect(**PGSQL_CONFIG)
        cur = conn.cursor()

        # A) é»˜è®¤: style + code2 å‰ç¼€æŸ¥æ‰¾
        if color_codes:
            for abbr in color_codes:
                prefix = f"{style_u}{abbr}"
                cur.execute(sql_prefix, (prefix + "%",))
                row = cur.fetchone()
                if row and row[0]:
                    cur.close()
                    conn.close()
                    return row[0]

            # ç‰¹ä¾‹: Sage SG -> GN
            if color_s.lower() == "sage" and "SG" in color_codes and "GN" not in color_codes:
                alt_prefix = f"{style_u}GN"
                cur.execute(sql_prefix, (alt_prefix + "%",))
                row = cur.fetchone()
                if row and row[0]:
                    cur.close()
                    conn.close()
                    return row[0]

        # B) å…œåº•: style + é¢œè‰²æ–‡æœ¬ç›´æ¥åŒ¹é…
        cur.execute(sql_fallback, (style_u, color_s, f"%{color_s}%"))
        row = cur.fetchone()

        cur.close()
        conn.close()

        if row and row[0]:
            print(f"âœ… DB å…œåº•åŒ¹é…æˆåŠŸ: {style_u} / {color_s} -> {row[0]}")
            return row[0]

    except Exception as e:
        print(f"âš ï¸ æ•°æ®åº“åŒ¹é…å¤±è´¥: {e}")

    return None


def choose_mpn_for_color(style: str, color: str, all_mpns: List[str]) -> Optional[str]:
    """ä» all_mpns ä¸­é€‰æ‹©åŒ¹é…é¢œè‰²çš„ MPN"""
    if not style or not color or not all_mpns:
        return None

    style = style.upper()
    codes_for_color = map_color_to_codes(color) or []
    if not codes_for_color:
        return None

    candidates: List[str] = []
    for mpn in all_mpns:
        if not mpn.startswith(style):
            continue
        color_code_part = mpn[len(style): len(style) + 2]
        if color_code_part in codes_for_color:
            candidates.append(mpn)

    if len(candidates) == 1:
        return candidates[0]

    # åŒæ¬¾å¼åªæœ‰ä¸€ä¸ª MPN
    same_style = [m for m in all_mpns if m.startswith(style)]
    if len(same_style) == 1:
        return same_style[0]

    return None


# ================== é‡‡é›†å™¨å®ç° ==================

class PhilipMorrisFetcher(BaseFetcher):
    """
    Philip Morris Direct é‡‡é›†å™¨

    ç‰¹ç‚¹:
    - å¤šé¢œè‰²é¡µé¢é€è‰²ç‚¹å‡»
    - MPN æå– + æ•°æ®åº“å…œåº•
    - æ¯ä¸ªé¢œè‰²ç”Ÿæˆç‹¬ç«‹ TXT
    """

    def _fetch_html(self, url: str) -> str:
        """
        è¦†ç›–åŸºç±»æ–¹æ³• - ä¸ä½¿ç”¨åŸºç±»çš„ HTML è·å–
        Philip Morris éœ€è¦äº¤äº’å¼å¤„ç†å¤šé¢œè‰²
        """
        # è¿™ä¸ªæ–¹æ³•ä¸ä¼šè¢«è°ƒç”¨ï¼Œå› ä¸ºæˆ‘ä»¬é‡å†™äº† fetch_one_product
        return ""

    def fetch_one_product(self, url: str, idx: int, total: int):
        """
        è¦†ç›–åŸºç±»æ–¹æ³• - å¤„ç†å¤šé¢œè‰²é¡µé¢

        Philip Morris ç‰¹æ®Šé€»è¾‘:
        1. ç‚¹å‡»æ¯ä¸ªé¢œè‰²é€‰é¡¹
        2. ä¸ºæ¯ä¸ªé¢œè‰²ç”Ÿæˆç‹¬ç«‹ TXT
        """
        for attempt in range(1, self.max_retries + 1):
            try:
                self.logger.info(f"[{idx}/{total}] [{attempt}/{self.max_retries}] æŠ“å–: {url}")

                driver = self.get_driver()

                try:
                    driver.get(url)
                    self._accept_cookies(driver)
                    time.sleep(2)

                    html = driver.page_source
                    soup = BeautifulSoup(html, "html.parser")

                    # åŸºç¡€ä¿¡æ¯
                    style = extract_style_code(html) or ""
                    name = soup.find("h1", class_="productView-title")
                    product_name = name.text.strip() if name else "No Data"

                    desc = soup.find("div", id="tab-description")
                    product_desc = " ".join(desc.stripped_strings) if desc else "No Data"

                    base_orig, base_sale = self._extract_prices(soup)

                    # æ•´é¡µæ‰€æœ‰ MPN
                    all_mpns = extract_all_mpns_plus(html)

                    # é¢œè‰²æŒ‰é’®
                    color_elems = driver.find_elements(By.CSS_SELECTOR, "label.form-option.label-img")
                    variants = []

                    if color_elems:
                        # å¤šé¢œè‰²: é€ä¸ªç‚¹å‡»
                        for idx_color in range(len(color_elems)):
                            color_elems = driver.find_elements(
                                By.CSS_SELECTOR, "label.form-option.label-img"
                            )
                            if idx_color >= len(color_elems):
                                break

                            elem = color_elems[idx_color]
                            color = elem.text.strip() or (elem.get_attribute("title") or "No Data")
                            self.logger.info(f"  ğŸ¨ {idx_color + 1}/{len(color_elems)}: {color}")

                            if color == "No Data":
                                continue

                            driver.execute_script("arguments[0].click();", elem)
                            time.sleep(1.3)

                            html_c = driver.page_source
                            soup_c = BeautifulSoup(html_c, "html.parser")

                            orig, sale = self._extract_prices(soup_c)
                            sizes = self._extract_sizes(html_c)
                            size_str = self._build_size_str(sizes)

                            adjusted = sale if sale and sale != orig else ""

                            variants.append({
                                "_style": style,
                                "Product Name": product_name,
                                "Product Description": product_desc,
                                "Product Color": color,
                                "Product Price": orig or sale or "0",
                                "Adjusted Price": adjusted,
                                "Product Size": size_str,
                                "Site Name": SITE_NAME,
                                "Source URL": url,
                            })
                    else:
                        # å•è‰²
                        self.logger.warning("æ— é¢œè‰²é€‰é¡¹ -> è§†ä¸ºå•è‰²")
                        color = "No Data"
                        sizes = self._extract_sizes(html)
                        size_str = self._build_size_str(sizes)
                        adjusted = base_sale if base_sale != base_orig else ""

                        variants.append({
                            "_style": style,
                            "Product Name": product_name,
                            "Product Description": product_desc,
                            "Product Color": color,
                            "Product Price": base_orig or base_sale or "0",
                            "Adjusted Price": adjusted,
                            "Product Size": size_str,
                            "Site Name": SITE_NAME,
                            "Source URL": url,
                        })

                    if not variants:
                        self.logger.warning("æ— å˜ä½“ -> è·³è¿‡")
                        return url, False

                    # å†™å…¥æ¯ä¸ªé¢œè‰²çš„ TXT
                    single_color_mode = (not color_elems) or (len(color_elems) <= 1)

                    for info in variants:
                        style = info.pop("_style") or ""
                        color = info["Product Color"]

                        product_code: Optional[str] = None

                        # A) ä¼˜å…ˆä½¿ç”¨ç½‘é¡µ MPN
                        if single_color_mode and all_mpns:
                            product_code = all_mpns[0]
                            self.logger.info(f"  âœ… å•è‰²é¡µé¢ä½¿ç”¨å®Œæ•´ MPN: {product_code}")
                        elif all_mpns:
                            mpn_for_color = choose_mpn_for_color(style, color, all_mpns)
                            if mpn_for_color:
                                product_code = mpn_for_color
                                self.logger.info(f"  âœ… å¤šé¢œè‰²é¡µé¢: ä¸º {color} é€‰æ‹© MPN {product_code}")

                        # B) MPN å¤±è´¥ -> æ•°æ®åº“å…œåº•
                        if not product_code and style:
                            product_code = find_product_code_in_db(style, color, url)

                        # C) å†³å®šè¾“å‡ºç›®å½•
                        if product_code:
                            target_dir = self.output_dir
                            info["Product Code"] = product_code
                        else:
                            target_dir = TXT_PROBLEM_DIR
                            info["Product Code"] = style or "UNKNOWN"

                        # å†™å…¥æ–‡ä»¶
                        from common.ingest.txt_writer import format_txt

                        fname = self._sanitize_filename(info["Product Code"]) + ".txt"
                        fpath = target_dir / fname
                        format_txt(info, fpath, brand="Barbour")

                        if target_dir == self.output_dir:
                            self.logger.info(f"  âœ… å†™å…¥ TXT: {fname}")
                        else:
                            self.logger.warning(f"  âš ï¸ å†™å…¥ TXT.problem: {fname}")

                    with self._lock:
                        self._success_count += 1

                    return url, True

                finally:
                    self.quit_driver()

            except Exception as e:
                self.logger.error(
                    f"âŒ [{idx}/{total}] å°è¯• {attempt}/{self.max_retries} å¤±è´¥: {url} - {e}",
                    exc_info=(attempt == self.max_retries),
                )

                if attempt < self.max_retries:
                    wait_time = min(2 ** attempt, 30)
                    time.sleep(wait_time)

                if attempt == self.max_retries:
                    with self._lock:
                        self._fail_count += 1
                    return url, False

        return url, False

    def _accept_cookies(self, driver):
        """æ¥å— Cookie"""
        try:
            WebDriverWait(driver, 5).until(
                EC.element_to_be_clickable(
                    (By.CSS_SELECTOR, "button#onetrust-accept-btn-handler")
                )
            ).click()
            time.sleep(1)
        except Exception:
            pass

    def _sanitize_filename(self, name: str) -> str:
        """æ–‡ä»¶åæ¸…ç†"""
        return re.sub(r"[\\/:*?\"<>|\s]+", "_", (name or "")).strip("_")

    def _extract_prices(self, soup: BeautifulSoup):
        """æå–ä»·æ ¼"""
        sale = ""
        orig = ""

        for span in soup.select("span.price.price--withTax"):
            sale = self._clean_price(span.text)
            break

        for span in soup.select("span.price.price--rrp"):
            orig = self._clean_price(span.text)
            break

        if not sale:
            meta = soup.find("meta", {"property": "product:price:amount"})
            if meta:
                sale = meta.get("content") or ""

        if not orig:
            orig = sale

        return orig, sale

    def _clean_price(self, t: str) -> str:
        """ä»æ–‡æœ¬æå–ä»·æ ¼"""
        if not t:
            return ""
        m = re.search(r"([0-9]+(?:\.[0-9]{1,2})?)", t.replace(",", ""))
        return m.group(1) if m else ""

    def _extract_sizes(self, html: str):
        """æå–å°ºç """
        soup = BeautifulSoup(html, "html.parser")
        labels = soup.select("label.form-option")
        out = []

        for lb in labels:
            classes = lb.get("class", [])
            if "label-img" in classes:
                continue

            span = lb.find("span", class_="form-option-variant")
            if not span:
                continue

            size = span.text.strip()
            stock = "æ— è´§" if "unavailable" in classes else "æœ‰è´§"
            out.append((size, stock))

        return out

    def _build_size_str(self, sizes):
        """æ„å»ºå°ºç å­—ç¬¦ä¸²"""
        order = []
        agg = {}

        for size, st in sizes:
            if size not in agg:
                agg[size] = st
                order.append(size)
            else:
                if st == "æœ‰è´§":
                    agg[size] = "æœ‰è´§"

        return ";".join([f"{s}:{agg[s]}" for s in order])

    def parse_detail_page(self, html: str, url: str) -> Dict[str, Any]:
        """
        è¿™ä¸ªæ–¹æ³•ä¸ä¼šè¢«è°ƒç”¨
        å› ä¸ºæˆ‘ä»¬é‡å†™äº† fetch_one_product
        """
        return {}


# ================== ä¸»å…¥å£ ==================

def philipmorris_fetch_info(
    max_workers: int = 3,
    headless: bool = True,
):
    """
    ä¸»å‡½æ•° - å…¼å®¹æ—§ç‰ˆæ¥å£

    Args:
        max_workers: å¹¶å‘çº¿ç¨‹æ•°
        headless: æ˜¯å¦æ— å¤´æ¨¡å¼
    """
    setup_logging()

    # é¢„åŠ è½½é¢œè‰²æ˜ å°„
    load_color_map_from_db()

    fetcher = PhilipMorrisFetcher(
        site_name="philipmorris",
        links_file=LINKS_FILE,
        output_dir=OUTPUT_DIR,
        max_workers=max_workers,
        max_retries=2,
        wait_seconds=2.0,
        headless=headless,
    )

    success, fail = fetcher.run_batch()
    print(f"\nâœ… Philip Morris æŠ“å–å®Œæˆ: æˆåŠŸ {success}, å¤±è´¥ {fail}")


if __name__ == "__main__":
    philipmorris_fetch_info(max_workers=3, headless=True)
