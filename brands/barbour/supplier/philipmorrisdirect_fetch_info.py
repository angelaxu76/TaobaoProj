# -*- coding: utf-8 -*-
"""
Philip Morris Direct | Barbour å•†å“æŠ“å–ï¼ˆv3 å¢å¼ºç‰ˆï¼‰

åœ¨ v2 åŸºç¡€ä¸Šå¢å¼ºç‚¹ï¼š
1. ä¿ç•™ v2 çš„ MPN æå–é€»è¾‘ (basic)ï¼Œæ–°å¢ PLUS ç‰ˆæœ¬åšå…œåº•ï¼Œä¸å½±å“åŸæœ‰æˆåŠŸæ¡ˆä¾‹ã€‚
2. PLUS ç‰ˆæœ¬é¢å¤–æ”¯æŒï¼š
   - MPN: <span>MSH5303PI51, MSH5303BL32</span> è¿™ç±»å¸¦æ ‡ç­¾å½¢å¼
   - JSON-LD é‡ŒåŒ…å« \u00a0 çš„ "MPN: ..." å­—ç¬¦ä¸²
   - MANUFACTURER'S CODESDAC0004BR15 è¿™ç±»ç´§æŒ¨ç€çš„æ–‡æœ¬
3. å¤šé¢œè‰²é¡µé¢ï¼šä¾ç„¶é€è‰²ç‚¹å‡»è·å–åº“å­˜/ä»·æ ¼ï¼Œå¹¶åˆ©ç”¨ MPN + é¢œè‰²ç ä¸ºæ¯ä¸ªé¢œè‰²é€‰æ‹©æ­£ç¡®çš„ç¼–ç  â†’ å¤šä¸ª TXTã€‚
4. å•è‰²é¡µé¢ï¼šå¦‚æœæœ‰å®Œæ•´ MPNï¼ˆå« DAC0004BR15 è¿™ç§ï¼‰ï¼Œç›´æ¥ç”¨ MPN å†™ TXTï¼Œä¸ä¾èµ– DBã€‚
5. è‹¥æ‰€æœ‰ç½‘é¡µæ–¹æ³•éƒ½å¤±è´¥ï¼Œå†ä½¿ç”¨æ¬¾å¼ + é¢œè‰² â†’ color_map + barbour_products çš„å…œåº•æ–¹æ¡ˆã€‚
"""

import re
import time
import threading
import traceback
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import List, Dict, Optional

import psycopg2
from bs4 import BeautifulSoup

from config import BARBOUR
from common_taobao.ingest.txt_writer import format_txt

# selenium imports
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import (
    InvalidSessionIdException,
    WebDriverException,
)

try:
    from selenium_stealth import stealth
except ImportError:  # noqa: D401
    def stealth(*args, **kwargs):
        return


#########################################
# é…ç½®ä¸è·¯å¾„
#########################################

LINKS_FILE: Path = BARBOUR["LINKS_FILES"]["philipmorris"]
TXT_DIR: Path = BARBOUR["TXT_DIRS"]["philipmorris"]
SITE_NAME = "Philip Morris"
PGSQL_CONFIG = BARBOUR["PGSQL_CONFIG"]

TXT_DIR.mkdir(parents=True, exist_ok=True)

TXT_PROBLEM_DIR: Path = TXT_DIR.parent / "TXT.problem"
TXT_PROBLEM_DIR.mkdir(parents=True, exist_ok=True)

UNKNOWN_COLOR_FILE = TXT_DIR.parent / "unknown_colors.csv"
PROBLEM_SUMMARY_FILE = TXT_DIR.parent / "problem_summary.csv"


#########################################
# æµè§ˆå™¨ç®¡ç†ï¼šçº¿ç¨‹å±€éƒ¨ driver
#########################################

drivers_lock = threading.Lock()
_all_drivers = set()
thread_local = threading.local()


def create_driver(headless: bool = True):
    """
    åˆ›å»ºä¸€ä¸ªç‹¬ç«‹ Chrome driverï¼ˆPhilip Morris ä¸“ç”¨ï¼‰
    """
    chrome_options = Options()
    if headless:
        chrome_options.add_argument("--headless=new")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--window-size=1920,1080")
    chrome_options.add_argument("user-agent=Mozilla/5.0")
    chrome_options.add_argument("--blink-settings=imagesEnabled=false")

    print("ğŸš— [get_driver] åˆ›å»ºæ–°çš„ Chrome driver (PhilipMorris v3)")
    driver = webdriver.Chrome(options=chrome_options)

    try:
        stealth(
            driver,
            languages=["en-GB", "en-US", "en"],
            vendor="Google Inc.",
            platform="Win32",
            webgl_vendor="Intel Inc.",
            renderer="Intel Iris OpenGL Engine",
            fix_hairline=True,
        )
    except Exception:
        pass

    with drivers_lock:
        _all_drivers.add(driver)

    return driver


def get_driver(headless: bool = True):
    if not hasattr(thread_local, "driver") or thread_local.driver is None:
        thread_local.driver = create_driver(headless=headless)
    return thread_local.driver


def invalidate_current_driver():
    """
    å½“å‰çº¿ç¨‹ driver å´©äº† â†’ ç§»é™¤ + quit + é‡å»º
    """
    d = getattr(thread_local, "driver", None)
    if d:
        with drivers_lock:
            if d in _all_drivers:
                _all_drivers.remove(d)
        try:
            d.quit()
        except Exception:
            pass
    thread_local.driver = None


def shutdown_all_drivers():
    """
    æ‰€æœ‰çº¿ç¨‹ç»“æŸåç»Ÿä¸€å…³é—­ driver
    """
    with drivers_lock:
        for d in list(_all_drivers):
            try:
                d.quit()
            except Exception:
                pass
        _all_drivers.clear()


#########################################
# å·¥å…·å‡½æ•°
#########################################

def accept_cookies(driver, timeout: int = 5):
    try:
        WebDriverWait(driver, timeout).until(
            EC.element_to_be_clickable(
                (By.CSS_SELECTOR, "button#onetrust-accept-btn-handler")
            )
        ).click()
        time.sleep(1)
    except Exception:
        pass


def sanitize_filename(name: str) -> str:
    return re.sub(r"[\\/:*?\"<>|\s]+", "_", (name or "")).strip("_")


#########################################
# é¢œè‰²å¤„ç†ï¼šbarbour_color_map ç¼“å­˜
#########################################

_COLOR_MAP_CACHE: Dict[str, List[str]] = {}
_COLOR_MAP_LOADED: bool = False
_COLOR_MAP_LOCK = threading.Lock()


def _normalize_color_tokens(s: str) -> List[str]:
    if not s:
        return []
    s = s.lower()
    s = re.sub(r"[\/,&\-]+", " ", s)
    s = re.sub(r"[^a-z0-9\s]+", " ", s)
    tokens = [t for t in s.split() if t]
    return tokens


def _color_key(s: str) -> str:
    tokens = _normalize_color_tokens(s)
    if not tokens:
        return ""
    return " ".join(sorted(tokens))


def _load_color_map_from_db() -> None:
    global _COLOR_MAP_LOADED, _COLOR_MAP_CACHE

    with _COLOR_MAP_LOCK:
        if _COLOR_MAP_LOADED:
            return

        try:
            conn = psycopg2.connect(**PGSQL_CONFIG)
            cur = conn.cursor()
            cur.execute(
                """
                SELECT color_code, raw_name, norm_key, source, is_confirmed
                FROM barbour_color_map
                ORDER BY
                    norm_key,
                    CASE
                        WHEN source = 'config_code_map' THEN 0
                        WHEN source = 'products'       THEN 1
                        ELSE 2
                    END,
                    color_code
                """
            )
            rows = cur.fetchall()
            cur.close()
            conn.close()
        except Exception as e:  # noqa: BLE001
            print("âš ï¸ ä» barbour_color_map è¯»å–é¢œè‰²æ˜ å°„å¤±è´¥ï¼š", e)
            _COLOR_MAP_LOADED = True
            _COLOR_MAP_CACHE = {}
            return

        cache: Dict[str, List[str]] = {}

        for color_code, raw_name, norm_key, source, is_confirmed in rows:
            key = norm_key or _color_key(raw_name or "")
            if not key:
                continue
            codes = cache.setdefault(key, [])
            if color_code in codes:
                continue
            if source == "config_code_map":
                codes.insert(0, color_code)
            else:
                codes.append(color_code)

        _COLOR_MAP_CACHE = cache
        _COLOR_MAP_LOADED = True
        print(
            f"ğŸ¨ å·²ä» barbour_color_map è½½å…¥ {len(rows)} æ¡é¢œè‰²è®°å½•ï¼Œ"
            f"å½’ä¸€åŒ– key æ•°é‡ï¼š{len(cache)}"
        )


def map_color_to_codes(color: str) -> List[str]:
    if not color:
        return []
    _load_color_map_from_db()
    key = _color_key(color)
    if not key:
        return []
    codes = _COLOR_MAP_CACHE.get(key, [])
    print(f"ğŸ§© map_color_to_codes: '{color}' (key='{key}') -> {codes}")
    return codes


def map_color_to_code(color: str) -> Optional[str]:
    codes = map_color_to_codes(color)
    return codes[0] if codes else None


#########################################
# è®°å½• unknown_color / problem_summary
#########################################

def record_unknown_color(style: str, color: str, url: str):
    from datetime import datetime

    with open(UNKNOWN_COLOR_FILE, "a", encoding="utf-8") as f:
        f.write(
            f"{style},{color},{url},"
            f"{datetime.now().isoformat(timespec='seconds')}\n"
        )


def record_problem_item(style, color, product_code, reason, url):
    from datetime import datetime

    with open(PROBLEM_SUMMARY_FILE, "a", encoding="utf-8") as f:
        f.write(
            f"{style},{color},{product_code},{reason},"
            f"{url},{datetime.now().isoformat(timespec='seconds')}\n"
        )


#########################################
# å•†å“ç¼–ç æå–ï¼šbasic + PLUS
#########################################

def extract_all_mpns_basic(html: str) -> List[str]:
    """
    v2 åŸæœ‰é€»è¾‘ï¼šæå–ç½‘é¡µæ‰€æœ‰å¯èƒ½å‡ºç°çš„ Barbour å®Œæ•´ MPNã€‚
    ä¿æŒä¸å˜ï¼Œä½œä¸º basic ç‰ˆæœ¬ã€‚
    """
    if not html:
        return []

    text = html
    results: List[str] = []
    seen = set()

    # 1) åŒ¹é… MPN åˆ—è¡¨
    m = re.search(r"MPN:\s*([A-Z0-9,\s]+)", text, re.I)
    if m:
        raw = m.group(1)
        for token in re.split(r"[,\s]+", raw):
            token = token.strip().upper()
            if re.match(r"^[A-Z]{3}\d{4}[A-Z]{2}\d{2,4}$", token):
                if token not in seen:
                    seen.add(token)
                    results.append(token)

    # 2) MANUFACTURER'S CODES æ®µ
    for m in re.finditer(
        r"MANUFACTURER'?S\s+CODE\S*([A-Z]{3}\d{4}[A-Z]{2}\d{2,4})",
        text,
        re.I,
    ):
        token = m.group(1).upper()
        if token not in seen:
            seen.add(token)
            results.append(token)

    # 3) å…¨æ–‡å…œåº•åŒ¹é…
    for token in re.findall(r"([A-Z]{3}\d{4}[A-Z]{2}\d{2,4})", text):
        token = token.upper()
        if token not in seen:
            seen.add(token)
            results.append(token)

    return results


def extract_all_mpns_plus(html: str) -> List[str]:
    """
    PLUS ç‰ˆï¼šåœ¨ basic ç»“æœåŸºç¡€ä¸Šï¼Œé¢å¤–å¤„ç†ï¼š
      - MPN: <span>XXXX, YYYY</span>
      - JSON-LD é‡Œçš„ "MPN:\u00a0XXXX"
      - MANUFACTURER'S CODESDAC0004BR15 è¿™ç±»ç´§æŒ¨ç€çš„æƒ…å†µ
    """
    if not html:
        return []

    # å…ˆæ‹¿ basic ç»“æœ
    base = extract_all_mpns_basic(html)
    seen = set(base)
    results = list(base)

    # è§„èŒƒåŒ–æ–‡æœ¬ï¼šå¤„ç† \u00a0 / &nbsp;
    text_norm = (
        html.replace("\\u00a0", " ")
        .replace("&nbsp;", " ")
    )

    # 1) MPN: <span>XXX, YYY</span>
    m = re.search(
        r"MPN:\s*(?:<[^>]*>)*\s*([A-Z0-9,\s]+)</",
        text_norm,
        flags=re.IGNORECASE,
    )
    if m:
        raw = m.group(1)
        for token in re.split(r"[,\s]+", raw):
            token = token.strip().upper()
            if re.match(r"^[A-Z]{3}\d{4}[A-Z]{2}\d{2,4}$", token):
                if token not in seen:
                    seen.add(token)
                    results.append(token)

    # 2) JSON-LD é‡Œæˆ–æ–‡æœ¬ä¸­ï¼šMPN: XXX, YYY Colour: ...
    m = re.search(r"MPN:\s*([A-Z0-9,\s]+)", text_norm, re.I)
    if m:
        raw = m.group(1)
        for token in re.split(r"[,\s]+", raw):
            token = token.strip().upper()
            if re.match(r"^[A-Z]{3}\d{4}[A-Z]{2}\d{2,4}$", token):
                if token not in seen:
                    seen.add(token)
                    results.append(token)

    # 3) MANUFACTURER'S CODES ç´§æŒ¨ç€
    for m in re.finditer(
        r"MANUFACTURER'?S\s+CODE\S*([A-Z]{3}\d{4}[A-Z]{2}\d{2,4})",
        text_norm,
        flags=re.IGNORECASE,
    ):
        token = m.group(1).upper()
        if re.match(r"^[A-Z]{3}\d{4}[A-Z]{2}\d{2,4}$", token):
            if token not in seen:
                seen.add(token)
                results.append(token)

    # 4) å†åšä¸€æ¬¡å…¨å±€å…œåº•ï¼ˆåœ¨è§„èŒƒåŒ–æ–‡æœ¬ä¸Šï¼‰
    for token in re.findall(r"([A-Z]{3}\d{4}[A-Z]{2}\d{2,4})", text_norm):
        token = token.upper()
        if token not in seen:
            seen.add(token)
            results.append(token)

    if results:
        print(f"ğŸ” extract_all_mpns_plus: {results}")
    return results


# v3 å¯¹å¤–ç»Ÿä¸€ä½¿ç”¨ PLUS ç‰ˆæœ¬
def extract_all_mpns(html: str) -> List[str]:
    return extract_all_mpns_plus(html)


def extract_full_mpn_basic(html: str) -> Optional[str]:
    """
    å…¼å®¹æ—§æ¥å£ï¼šbasic ç‰ˆæœ¬ï¼Œä»…ä½¿ç”¨ v2 çš„é€»è¾‘ã€‚
    """
    mpns = extract_all_mpns_basic(html)
    return mpns[0] if mpns else None


def extract_full_mpn_plus(html: str) -> Optional[str]:
    """
    PLUS ç‰ˆæœ¬ï¼šåŸºäº extract_all_mpns_plusã€‚
    """
    mpns = extract_all_mpns_plus(html)
    return mpns[0] if mpns else None


def extract_style_code(html: str) -> Optional[str]:
    """
    æå– 7 ä½æ¬¾å¼ç¼–ç ï¼ˆä¸å«é¢œè‰²/å°ºç ï¼Œä¾‹å¦‚ MCA1053 / DAC0004ï¼‰ã€‚

    ä¼˜å…ˆçº§ï¼š
      1ï¼‰extract_full_mpn_basic
      2ï¼‰extract_full_mpn_plus
      3ï¼‰åŸæœ‰å…œåº•é€»è¾‘ï¼ˆä¿æŒå…¼å®¹ï¼‰
    """
    text = html or ""

    full_mpn = extract_full_mpn_basic(text)
    if not full_mpn:
        full_mpn = extract_full_mpn_plus(text)

    if full_mpn:
        return full_mpn[:7]

    # ä¸‹é¢æ˜¯ v2 çš„å…œåº•é€»è¾‘

    mpn = re.search(r"MPN:\s*([A-Z0-9,\s]+)", text, re.I)
    if mpn:
        raw = mpn.group(1)
        for token in re.split(r"[,\s]+", raw):
            token = token.strip().upper()
            if re.match(r"^[A-Z]{3}\d{4}[A-Z0-9]{0,6}$", token):
                return token[:7]

    m = re.search(r"([A-Z]{3}\d{4}[A-Z]{2}\d{2,4})", text)
    if m:
        return m.group(1)[:7]

    m = re.search(r"([A-Z]{3}\d{4})", text)
    if m:
        return m.group(1)

    return None


#########################################
# ä»·æ ¼ & å°ºç 
#########################################

def _clean_price(t: str) -> str:
    if not t:
        return ""
    m = re.search(r"([0-9]+(?:\.[0-9]{1,2})?)", t.replace(",", ""))
    return m.group(1) if m else ""


def extract_prices(soup: BeautifulSoup):
    sale = ""
    orig = ""

    for span in soup.select("span.price.price--withTax"):
        sale = _clean_price(span.text)
        break

    for span in soup.select("span.price.price--rrp"):
        orig = _clean_price(span.text)
        break

    if not sale:
        meta = soup.find("meta", {"property": "product:price:amount"})
        if meta:
            sale = meta.get("content") or ""

    if not orig:
        orig = sale

    return orig, sale


def extract_sizes(html: str):
    soup = BeautifulSoup(html, "html.parser")
    labels = soup.select("label.form-option")
    out = []

    for lb in labels:
        classes = lb.get("class", [])
        if "label-img" in classes:
            continue

        span = lb.find("span", class_="form-option-variant")
        if not span:
            continue

        size = span.text.strip()
        stock = "æ— è´§" if "unavailable" in classes else "æœ‰è´§"
        out.append((size, stock))

    return out


def build_size_str(sizes):
    order = []
    agg = {}
    for size, st in sizes:
        if size not in agg:
            agg[size] = st
            order.append(size)
        else:
            if st == "æœ‰è´§":
                agg[size] = "æœ‰è´§"
    return ";".join([f"{s}:{agg[s]}" for s in order])


#########################################
# æ•°æ®åº“åŒ¹é…
#########################################

def find_product_code_in_db(style: str, color: str, conn, url: str):
    """
    é€šè¿‡ æ¬¾å¼ç¼–ç  + é¢œè‰²è‹±æ–‡ï¼Œä» barbour_products ä¸­æ‰¾åˆ°çœŸæ­£çš„ product_codeã€‚
    """
    if not style or not color or not conn:
        return None

    color_codes = map_color_to_codes(color)
    if not color_codes:
        print(f"âš ï¸ æœªæ‰¾åˆ°é¢œè‰²ç®€å†™æ˜ å°„ï¼š{style} / {color}")
        record_unknown_color(style, color, url)
        return None

    sql = """
        SELECT product_code FROM barbour_products
        WHERE product_code ILIKE %s
        ORDER BY product_code
        LIMIT 1
    """

    with conn.cursor() as cur:
        for abbr in color_codes:
            prefix = f"{style}{abbr}"
            cur.execute(sql, (prefix + "%",))
            row = cur.fetchone()
            if row and row[0]:
                return row[0]

        # ç‰¹ä¾‹ï¼šSage SG â†’ GN
        if color.strip().lower() == "sage" and "SG" in color_codes and "GN" not in color_codes:
            alt_prefix = f"{style}GN"
            cur.execute(sql, (alt_prefix + "%",))
            row = cur.fetchone()
            if row and row[0]:
                return row[0]

    print(f"âš ï¸ æ•°æ®åº“æœªåŒ¹é…åˆ°ï¼š{style} / {color} / codes={color_codes}")
    return None


#########################################
# å¤šé¢œè‰²é¡µé¢ï¼šé¢œè‰² â†’ MPN é€‰æ‹©
#########################################

def choose_mpn_for_color(
    style: str,
    color: str,
    all_mpns: List[str],
) -> Optional[str]:
    """
    å¤šé¢œè‰²é¡µé¢æ—¶ï¼Œç»™å®šæ¬¾å¼ + é¢œè‰²åï¼Œä» all_mpns ä¸­æŒ‘å‡ºå¯¹åº”çš„å®Œæ•´ç¼–ç ã€‚

    è§„åˆ™ï¼š
      1ï¼‰åªè€ƒè™‘ä»¥ style å¼€å¤´çš„ç¼–ç 
      2ï¼‰color é€šè¿‡ map_color_to_codes æ˜ å°„åˆ°é¢œè‰²ç ï¼ˆå¦‚ Navy -> ['NY']ï¼‰
      3ï¼‰åŒ¹é… style + color_code å‰ç¼€ï¼Œä¾‹å¦‚ MQU0888NY%%
      4ï¼‰è‹¥åˆšå¥½åªæœ‰ä¸€ä¸ªå€™é€‰ï¼Œåˆ™è¿”å›
      5ï¼‰å¦åˆ™ï¼Œå¦‚æœ all_mpns ä¸­åªæœ‰ä¸€ä¸ªä»¥ style å¼€å¤´çš„ç¼–ç ï¼Œä¹Ÿæ¥å—
    """
    if not style or not color or not all_mpns:
        return None

    style = style.upper()
    codes_for_color = map_color_to_codes(color) or []
    if not codes_for_color:
        return None

    candidates: List[str] = []
    for mpn in all_mpns:
        if not mpn.startswith(style):
            continue
        color_code_part = mpn[len(style): len(style) + 2]
        if color_code_part in codes_for_color:
            candidates.append(mpn)

    if len(candidates) == 1:
        return candidates[0]

    same_style = [m for m in all_mpns if m.startswith(style)]
    if len(same_style) == 1:
        return same_style[0]

    return None


#########################################
# ä¸»æµç¨‹ï¼šå¤„ç†å• URL
#########################################

def process_url(url: str, output_dir: Path):
    """
    å¤„ç†å•ä¸ª URLï¼ˆå«è‡ªåŠ¨é‡è¯• 2 æ¬¡ï¼‰
    """
    for attempt in range(2):
        driver = get_driver(headless=True)

        try:
            print(f"\nğŸŒ [v3] æŠ“å–({attempt+1}/2): {url}")
            driver.get(url)
            accept_cookies(driver)
            time.sleep(2)

            html = driver.page_source
            soup = BeautifulSoup(html, "html.parser")

            # åŸºç¡€ä¿¡æ¯
            style = extract_style_code(html) or ""
            name = soup.find("h1", class_="productView-title")
            product_name = name.text.strip() if name else "No Data"

            desc = soup.find("div", id="tab-description")
            product_desc = " ".join(desc.stripped_strings) if desc else "No Data"

            base_orig, base_sale = extract_prices(soup)

            # æ•´é¡µæ‰€æœ‰ MPNï¼ˆå¯èƒ½å¤šè‰²ï¼‰
            all_mpns = extract_all_mpns(html)

            # é¢œè‰²æŒ‰é’®
            color_elems = driver.find_elements(By.CSS_SELECTOR, "label.form-option.label-img")
            variants = []

            if color_elems:
                # å¤šé¢œè‰²ï¼šé€ä¸ªç‚¹å‡»é¢œè‰²
                for idx in range(len(color_elems)):
                    color_elems = driver.find_elements(
                        By.CSS_SELECTOR, "label.form-option.label-img"
                    )
                    if idx >= len(color_elems):
                        break

                    elem = color_elems[idx]
                    color = elem.text.strip() or (elem.get_attribute("title") or "No Data")
                    print(f"  ğŸ¨ {idx+1}/{len(color_elems)}: {color}")

                    if color == "No Data":
                        continue

                    driver.execute_script("arguments[0].click();", elem)
                    time.sleep(1.3)

                    html_c = driver.page_source
                    soup_c = BeautifulSoup(html_c, "html.parser")

                    orig, sale = extract_prices(soup_c)
                    sizes = extract_sizes(html_c)
                    size_str = build_size_str(sizes)

                    adjusted = sale if sale and sale != orig else ""

                    variants.append(
                        {
                            "_style": style,
                            "Product Name": product_name,
                            "Product Description": product_desc,
                            "Product Color": color,
                            "Product Price": orig or sale or "0",
                            "Adjusted Price": adjusted,
                            "Product Size": size_str,
                            "Site Name": SITE_NAME,
                            "Source URL": url,
                        }
                    )
            else:
                # å•è‰²
                print("âš ï¸ æ— é¢œè‰²é€‰é¡¹ â†’ è§†ä¸ºå•è‰²")
                color = "No Data"
                sizes = extract_sizes(html)
                size_str = build_size_str(sizes)
                adjusted = base_sale if base_sale != base_orig else ""

                variants.append(
                    {
                        "_style": style,
                        "Product Name": product_name,
                        "Product Description": product_desc,
                        "Product Color": color,
                        "Product Price": base_orig or base_sale or "0",
                        "Adjusted Price": adjusted,
                        "Product Size": size_str,
                        "Site Name": SITE_NAME,
                        "Source URL": url,
                    }
                )

            if not variants:
                print("âŒ æ— å˜ä½“ â†’ è·³è¿‡")
                return

            # å»ºç«‹ DB è¿æ¥
            conn = None
            try:
                conn = psycopg2.connect(**PGSQL_CONFIG)
                print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
            except Exception:
                print("âš ï¸ æ•°æ®åº“è¿æ¥å¤±è´¥ â†’ å¦‚æ— å®Œæ•´ç¼–ç ï¼Œå°†å…¨éƒ¨ç®—é—®é¢˜æ–‡ä»¶")

            single_color_mode = (not color_elems) or (len(color_elems) <= 1)

            for info in variants:
                style = info.pop("_style") or ""
                color = info["Product Color"]

                product_code: Optional[str] = None
                reason = ""
                codes_for_color: List[str] = []

                # A) ä¼˜å…ˆä½¿ç”¨ç½‘é¡µä¸Šèƒ½æ‹¿åˆ°çš„å®Œæ•´ç¼–ç 
                if single_color_mode and all_mpns:
                    # å•è‰²ï¼šç›´æ¥ç”¨ç¬¬ä¸€ä¸ª MPN
                    product_code = all_mpns[0]
                    print(f"  âœ… å•è‰²é¡µé¢ä½¿ç”¨å®Œæ•´ MPN: {product_code}")
                elif all_mpns:
                    # å¤šé¢œè‰²ï¼šæŒ‰é¢œè‰²é€‰å¯¹åº” MPN
                    mpn_for_color = choose_mpn_for_color(style, color, all_mpns)
                    if mpn_for_color:
                        product_code = mpn_for_color
                        print(f"  âœ… å¤šé¢œè‰²é¡µé¢ï¼šä¸º {color} é€‰æ‹© MPN {product_code}")

                # B) A å¤±è´¥ â†’ æ¬¾å¼ + é¢œè‰² + DB
                if not product_code:
                    if conn:
                        codes_for_color = map_color_to_codes(color)
                    else:
                        codes_for_color = []

                    if style and conn:
                        product_code = find_product_code_in_db(style, color, conn, url)

                # C) æ ¹æ®æ˜¯å¦æ‹¿åˆ°å®Œæ•´ç¼–ç å†³å®š TXT ç›®å½•
                if product_code:
                    target_dir = TXT_DIR
                    info["Product Code"] = product_code
                else:
                    target_dir = TXT_PROBLEM_DIR
                    info["Product Code"] = style or "UNKNOWN"

                    if not codes_for_color:
                        reason = "unknown_color"
                    else:
                        reason = "no_db_match"

                    record_problem_item(
                        style,
                        color,
                        info["Product Code"],
                        reason,
                        url,
                    )

                fname = sanitize_filename(info["Product Code"]) + ".txt"
                fpath = target_dir / fname
                format_txt(info, fpath, brand="Barbour")

                if target_dir == TXT_DIR:
                    print(f"  âœ… å†™å…¥ TXT: {fname}")
                else:
                    print(f"  âš ï¸ å†™å…¥ TXT.problem: {fname}  ({reason})")

            return  # æœ¬é“¾æ¥æˆåŠŸå®Œæˆ

        except InvalidSessionIdException as e:
            print(f"âš ï¸ driver ä¼šè¯å¤±æ•ˆ â†’ é‡å»º: {e}")
            invalidate_current_driver()
            time.sleep(2)
        except WebDriverException as e:
            print(f"âš ï¸ WebDriverExceptionï¼ˆç¬¬ {attempt+1} æ¬¡ï¼‰: {e}")
            invalidate_current_driver()
            time.sleep(2)
        except Exception as e:
            print(f"âŒ æŠ“å–å¤±è´¥ï¼ˆç¬¬ {attempt+1} æ¬¡ï¼‰: {e}")
            traceback.print_exc()
            break

    print(f"âŒ æœ€ç»ˆå¤±è´¥: {url}")


#########################################
# æ‰¹é‡å…¥å£ï¼ˆv3ï¼‰
#########################################

def philipmorris_fetch_info_v3(max_workers: int = 3):
    print(f"LINKS_FILE = {LINKS_FILE}")
    print(f"TXT_DIR    = {TXT_DIR}")

    urls: List[str] = []
    with open(LINKS_FILE, "r", encoding="utf-8") as f:
        for line in f:
            u = line.strip()
            if u:
                urls.append(u)

    print(
        f"ğŸš€ [v3] å¯åŠ¨ Philip Morris æŠ“å–ï¼Œæ€» {len(urls)} æ¡ï¼Œçº¿ç¨‹æ•°={max_workers}"
    )

    try:
        with ThreadPoolExecutor(max_workers=max_workers) as exe:
            futures = [exe.submit(process_url, u, TXT_DIR) for u in urls]
            for _ in as_completed(futures):
                pass
    finally:
        shutdown_all_drivers()
        print("ğŸ§¹ å·²å…³é—­æ‰€æœ‰ driver")


if __name__ == "__main__":
    # å»ºè®®å…ˆå•æµ‹å°‘é‡é“¾æ¥ï¼Œå†è·‘å…¨é‡ï¼š
    #   python philipmorrisdirect_fetch_info_v3.py
    philipmorris_fetch_info_v3(max_workers=10)
