# -*- coding: utf-8 -*-
"""
Outdoor & Country | Barbour å•†å“æŠ“å–ï¼ˆç»Ÿä¸€ TXT æ¨¡æ¿ç‰ˆï¼‰
ä¿æŒå¯¹å¤–æ¥å£ & pipeline å…¼å®¹ï¼š
- process_url(url, output_dir)
- fetch_outdoor_product_offers_concurrent(max_workers=3)

æ”¹åŠ¨è¦ç‚¹ï¼š
1) å¤ç”¨ä½ å·²æœ‰çš„ parse_offer_info(html, url) è§£æç«™ç‚¹
2) è½ç›˜ç»Ÿä¸€èµ° txt_writer.format_txtï¼ˆä¸å…¶å®ƒç«™ç‚¹ä¸€è‡´ï¼‰
3) å†™å…¥å‰ç»Ÿä¸€å­—æ®µï¼š
   - Product Code = Product Color Codeï¼ˆä½ å½“å‰çš„ç»„åˆç ç­–ç•¥ï¼‰
   - Site Name = "Outdoor and Country"
   - ä¸å†™ SizeMap
   - è¿‡æ»¤ 52 åŠæ›´å¤§çš„ç”·è£…æ•°å­—å°ºç 
4) ç±»ç›®å…œåº•ï¼šé‡åˆ° wax + jacket æˆ– code å‰ç¼€ MWX/LWX æ—¶ï¼Œå¼ºåˆ¶ "waxed jacket"
   - å¦åˆ™æŒ‰ä½ åœ¨ category_utils ä¸­çš„æ—§é€»è¾‘
5) Outdoor ä¸“å±çš„ä»·æ ¼å¤„ç†ï¼ˆå½“é¡µé¢ä¸Šæ—  price å­—æ®µæ—¶ï¼Œä» offers è¡¥é½ï¼‰
6) å°ºç è¡Œç»Ÿä¸€ï¼š
   - ä¸å†™ SizeMapï¼Œåªå†™ Product Size Detail
   - å¯¹ Product Size / Product Size Detail çš„å°ºç åšæ¸…æ´—
   - è‹¥æ—  Product Size Detailï¼ŒæŒ‰ Size å…œåº•ç”Ÿæˆï¼ˆæœ‰è´§=3/æ— è´§=0ï¼ŒEAN å ä½ï¼‰
"""

import time
import json
import threading
import re
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urlparse, parse_qs, unquote

import undetected_chromedriver as uc
from bs4 import BeautifulSoup

from config import BARBOUR
from brands.barbour.supplier.outdoorandcountry_parse_offer_info import parse_offer_info

# âœ… ç»Ÿä¸€ TXT å†™å…¥ï¼ˆä¸å…¶å®ƒç«™ç‚¹ä¸€è‡´ï¼‰
from common_taobao.ingest.txt_writer import format_txt
from common_taobao.core.selenium_utils import get_driver, quit_all_drivers

# âœ… å°ºç æ¸…æ´—ï¼ˆä¿å®ˆï¼šè¯†åˆ«ä¸äº†å°±åŸæ ·è¿”å›ï¼‰
from common_taobao.core.size_utils import clean_size_for_barbour  # è§ä½ ä¸Šä¼ çš„å®ç°
from brands.barbour.core.site_utils import assert_site_or_raise as canon
CANON_SITE = canon("outdoorandcountry")

from config import BARBOUR, BRAND_CONFIG, SETTINGS
DEFAULT_STOCK_COUNT = SETTINGS.get("DEFAULT_STOCK_COUNT", 3)


# ========== æµè§ˆå™¨ä¸ Cookie ==========
def accept_cookies(driver, timeout=8):
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    try:
        WebDriverWait(driver, timeout).until(
            EC.element_to_be_clickable((By.ID, "onetrust-accept-btn-handler"))
        ).click()
        time.sleep(1)
    except Exception:
        pass


# ========== å·¥å…· ==========
def _normalize_color_from_url(url: str) -> str:
    try:
        qs = parse_qs(urlparse(url).query)
        c = qs.get("c", [None])[0]
        if not c:
            return ""
        c = unquote(c)  # %2F -> /
        c = c.replace("\\", "/")
        c = re.sub(r"\s*/\s*", " / ", c)
        c = re.sub(r"\s+", " ", c).strip()
        c = " ".join(w.capitalize() for w in c.split(" "))
        return c
    except Exception:
        return ""


def sanitize_filename(name: str) -> str:
    return re.sub(r'[\\/:*?"<>|\s]+', "_", name or "NoName")


def _extract_description(html: str) -> str:
    soup = BeautifulSoup(html, "html.parser")
    tag = soup.find("meta", attrs={"property": "og:description"})
    if tag and tag.get("content"):
        desc = tag["content"].replace("<br>", "").replace("<br/>", "").replace("<br />", "")
        return desc.strip()
    tab = soup.select_one(".product_tabs .tab_content[data-id='0'] div")
    return tab.get_text(" ", strip=True) if tab else "No Data"


def _extract_features(html: str) -> str:
    soup = BeautifulSoup(html, "html.parser")
    h3 = soup.find("h3", attrs={"title": "Features"})
    if h3:
        ul = h3.find_next("ul")
        if ul:
            items = [li.get_text(" ", strip=True) for li in ul.find_all("li")]
            return "; ".join(items)
    return "No Data"


def _extract_color_code_from_jsonld(html: str) -> str:
    """
    å…¼å®¹ outdoorandcountry æ–°/æ—§ JSON-LD ç»“æ„:
    - offers[].mpn æœ‰æ—¶æ˜¯ "MWX0017NY9108"ï¼ˆæœ€å2ä½æ˜¯å°ºç ï¼‰
    - æœ‰æ—¶æ˜¯ "MWX0017NY91"ï¼ˆç›´æ¥æ˜¯ç»„åˆç ï¼‰
    - æœ‰æ—¶å¹²è„†æ˜¯ "MWX0017NY91_08"
    ä½ å½“å‰ç­–ç•¥æ˜¯ï¼šç”¨é¢œè‰²ç»„åˆç ï¼Œå³ "MWX0017NY91" è¿™ç§ 3+4+2+2 ç»“æ„ä¸ºä½³ã€‚
    """
    soup = BeautifulSoup(html, "html.parser")
    for script in soup.find_all("script", type="application/ld+json"):
        try:
            data = script.string and script.string.strip()
            if not data:
                continue
            j = json.loads(data)
            if isinstance(j, dict) and j.get("@type") == "Product" and isinstance(j.get("offers"), list):
                for off in j["offers"]:
                    mpn = (off or {}).get("mpn")
                    if isinstance(mpn, str):
                        # å…ˆå°è¯•å– MWX0017NY91 è¿™ç§å®Œæ•´ç»„åˆç ï¼ˆæˆªæ‰æœ€å2ä½å°ºç ï¼‰
                        if len(mpn) >= 11:
                            maybe_code = mpn[:-2]
                            if re.match(r"^[A-Z]{3}\d{4}[A-Z]{2}\d{2}$", maybe_code):
                                return maybe_code
                        # å…¶æ¬¡å›é€€åˆ°æœ«å°¾é¢œè‰²å—ï¼ˆOL99/NY91ï¼‰
                        m = re.search(r'([A-Z]{2}\d{2})(\d{2})$', mpn)
                        if m:
                            return m.group(1)
        except Exception:
            continue
    return ""


def _infer_gender_from_name(name: str) -> str:
    n = (name or "").lower()
    if any(x in n for x in ["women", "women's", "womens", "ladies", "lady"]):
        return "å¥³æ¬¾"
    if any(x in n for x in ["men", "men's", "mens"]):
        return "ç”·æ¬¾"
    if any(x in n for x in ["kids", "kid", "boy", "girl"]):
        return "ç«¥æ¬¾"
    return "ç”·æ¬¾"  # Outdoor ä»¥ç”·æ¬¾ä¸ºä¸»ï¼Œå…œåº•ç”·æ¬¾


# ========== Outdoor ä¸“å±å°ºç é€»è¾‘ ==========
WOMEN_NUM = ["6", "8", "10", "12", "14", "16", "18", "20"]
MEN_ALPHA = ["S", "M", "L", "XL", "XXL", "XXXL"]
MEN_NUM = [str(s) for s in range(32, 52, 2)]  # 32..50 å¶æ•°


def _clean_size(raw: str) -> str:
    raw = (raw or "").strip()
    if not raw:
        return ""
    s = clean_size_for_barbour(raw) or raw
    return s.strip()


def _filter_and_sort_sizes(sizes, gender: str):
    """
    - å¥³æ¬¾ï¼šç»Ÿä¸€æ˜ å°„ä¸º 6-20
    - ç”·æ¬¾ï¼šå­—æ¯ + æ•°å­—ï¼Œè¿‡æ»¤ 52 åŠä»¥ä¸Š
    """
    gender = gender or ""
    sizes = [s for s in (sizes or []) if s]

    cleaned = []
    for s, status in sizes:
        val = _clean_size(s)
        if not val:
            continue
        cleaned.append((val, status))

    if not cleaned:
        return []

    # æŒ‰æ€§åˆ«åˆ†æ”¯
    if gender == "å¥³æ¬¾":
        bucket = {}
        for s, status in cleaned:
            m = re.match(r"^(\d{1,2})$", s)
            if not m:
                continue
            num = int(m.group(1))
            if num < 6 or num > 20:
                continue
            bucket[num] = status
        ordered = []
        for num in WOMEN_NUM:
            n = int(num)
            if n in bucket:
                ordered.append((num, bucket[n]))
        return ordered

    # ç”·æ¬¾ / ç«¥æ¬¾ï¼ˆç«¥æ¬¾ä¹ŸæŒ‰ç”·è£…æ•°å­—å­—æ¯æ··åˆå¤„ç†ï¼‰
    bucket = {}
    for s, status in cleaned:
        # è¿‡æ»¤ 52 åŠä»¥ä¸Š
        m = re.match(r"^(\d{2})$", s)
        if m:
            num = int(m.group(1))
            if num >= 52:
                continue
            bucket[s] = status
        else:
            bucket[s] = status

    # æŒ‰å­—æ¯ä¼˜å…ˆ + æ•°å­—åºæ¬¡
    alpha_part = [(s, bucket[s]) for s in MEN_ALPHA if s in bucket]
    num_part = []
    for n in MEN_NUM:
        if n in bucket:
            num_part.append((n, bucket[n]))

    # å¯èƒ½ä»æœ‰æ®‹ä½™ç ï¼ˆæ¯”å¦‚ XS, XXL ä¹‹ç±»ï¼‰ï¼ŒåŸé¡ºåºè¿½åŠ 
    used = {s for s, _ in alpha_part + num_part}
    others = [(s, bucket[s]) for s in bucket if s not in used]

    return alpha_part + num_part + others


def _build_sizes_from_offers(offers, gender: str):
    """
    offers: [(size_str, price, stock_text, can_order), ...]
    è¾“å‡ºï¼š
      Product Size:        "6:æœ‰è´§;8:æœ‰è´§;10:æ— è´§;..."
      Product Size Detail: "6:3:0000000000000;8:0:0000000000000;..."
    """
    if not offers:
        return "No Data", "No Data"

    norm = []
    for size, price, stock_text, can_order in offers:
        size = (size or "").strip()
        stock = 0
        if (stock_text or "").strip().lower() in ("in stock", "available"):
            stock = DEFAULT_STOCK_COUNT
        if can_order and stock == 0:
            stock = DEFAULT_STOCK_COUNT
        norm.append((size, stock))

    # ç»Ÿä¸€æ¸…æ´— + è¿‡æ»¤å¤§å°ºç 
    temp = []
    for size, stock in norm:
        cs = _clean_size(size)
        if not cs:
            continue
        # âš ï¸ Outdoor ä»…è¿‡æ»¤ 52 åŠä»¥ä¸Š
        m = re.match(r"^(\d{2})$", cs)
        if m and int(m.group(1)) >= 52:
            continue
        temp.append((cs, stock))

    if not temp:
        return "No Data", "No Data"

    # æŒ‰æ€§åˆ«æ’åº
    # æˆ‘ä»¬åªå…³å¿ƒæ˜¯å¦æœ‰è´§ (>=1)ï¼Œæ— è´§å°±è®°ä¸º 0
    bucket = {}
    for size, stock in temp:
        bucket[size] = max(bucket.get(size, 0), stock)

    # æ€§åˆ«æ˜ å°„
    g = gender or ""
    if "å¥³" in g:
        chosen = WOMEN_NUM[:]
    else:
        # ç”·æ¬¾/ç«¥æ¬¾ï¼šå­—æ¯+æ•°å­—
        # ä¼˜å…ˆ MEN_ALPHA + MEN_NUMï¼Œæœ€å append å…¶å®ƒ
        chosen = []
        for s in MEN_ALPHA:
            if s in bucket:
                chosen.append(s)
        for s in MEN_NUM:
            if s in bucket:
                chosen.append(s)
        # others
        for s in bucket:
            if s not in chosen:
                chosen.append(s)

    # æ„å»ºè¾“å‡º
    size_line = []
    detail = []
    for s in chosen:
        stock = bucket.get(s, 0)
        status = "æœ‰è´§" if stock > 0 else "æ— è´§"
        size_line.append(f"{s}:{status}")
        qty = DEFAULT_STOCK_COUNT if stock > 0 else 0
        detail.append(f"{s}:{qty}:0000000000000")

    if not size_line:
        return "No Data", "No Data"

    return ";".join(size_line), ";".join(detail)


def _fallback_style_category(name: str, desc: str, code: str) -> str:
    n = (name or "").lower()
    d = (desc or "").lower()
    c = (code or "").upper()

    def has(*words):
        return any(w in n or w in d for w in words)

    # 1) waxed jacket å…œåº•ï¼ˆå…³é”®ï¼‰
    if ("wax" in n or "wax" in d) and ("jacket" in n or "coat" in n or "jacket" in d or "coat" in d):
        return "waxed jacket"
    if c.startswith("MWX") or c.startswith("LWX"):
        return "waxed jacket"

    # 2) quilted
    if has("quilt"):
        return "quilted jacket"

    # 3) gilet/bodywarmer
    if has("gilet", "bodywarmer", "vest"):
        return "gilet"

    # 4) knitwear
    if has("knit", "sweater", "jumper", "crew"):
        return "knitwear"

    # 5) shirt
    if has("shirt"):
        return "shirt"

    # 6) é€šç”¨ jacket
    if has("jacket", "coat", "parka"):
        return "jacket"

    return "No Data"


def _inject_price_from_offers(info: dict):
    """
    ä¸‡ä¸€ parse_offer_info æ²¡ç»™åŸä»·/æŠ˜æ‰£ä»·ï¼Œå°±ä» offers å…œåº•ä¸€ä¸ªæœ€å°ä»·æ ¼ã€‚
    """
    offers = info.get("Offers") or []
    prices = []
    for _, price, _, _ in offers:
        try:
            if price is None:
                continue
            prices.append(float(price))
        except Exception:
            continue

    if not prices:
        return

    # æœ€å°ä»·æ ¼å…œåº•
    base = min(prices)
    info.setdefault("Product Price", base)
    info.setdefault("Adjusted Price", base)


def _clean_sizes(info: dict):
    """
    æ¸…æ´— Product Size / Product Size Detailï¼ˆå¦‚æœå­˜åœ¨çš„è¯ï¼‰
    """
    gender = info.get("Product Gender") or ""
    # å½“å‰å®ç°åªå¯¹ Detail ç”Ÿæ•ˆï¼ŒSize æœ¬èº«ä¸å†å†™ï¼ˆæŒ‰ä½ è¦æ±‚ï¼‰
    detail = info.get("Product Size Detail")
    if not detail or detail == "No Data":
        return

    parts = []
    for item in str(detail).split(";"):
        item = item.strip()
        if not item:
            continue
        try:
            size, stock, ean = item.split(":")
        except ValueError:
            continue
        csize = _clean_size(size)
        if not csize:
            continue
        try:
            stock_val = int(stock)
        except Exception:
            stock_val = 0
        parts.append((csize, stock_val, ean))

    if not parts:
        return

    # æŒ‰æ€§åˆ«æ’åºï¼ˆä¸ä¸Šé¢ _filter_and_sort_sizes ä¸€è‡´ï¼‰
    if "å¥³" in gender:
        order = WOMEN_NUM
    else:
        order = MEN_ALPHA + MEN_NUM

    ordered = []
    used = set()
    for s in order:
        for size, stock, ean in parts:
            if size == s and size not in used:
                used.add(size)
                ordered.append((size, stock, ean))

    for size, stock, ean in parts:
        if size not in used:
            ordered.append((size, stock, ean))

    detail_line = []
    for size, stock, ean in ordered:
        detail_line.append(f"{size}:{stock}:{ean or '0000000000000'}")

    if detail_line:
        info["Product Size Detail"] = ";".join(detail_line)


def _ensure_detail_from_size(info: dict):
    """
    è‹¥æ—  Detail ä½†æœ‰ Sizeï¼Œåˆ™æ ¹æ® Size ç”Ÿæˆ Detailï¼ˆæœ‰è´§=3ï¼Œæ— è´§=0ï¼ŒEAN å ä½ï¼‰
    """
    if info.get("Product Size Detail") and info.get("Product Size Detail") != "No Data":
        return
    size = info.get("Product Size") or "No Data"
    if not size or size == "No Data":
        return

    detail = []
    for item in str(size).split(";"):
        item = item.strip()
        if not item:
            continue
        try:
            s, status = item.split(":")
        except ValueError:
            continue
        stock = DEFAULT_STOCK_COUNT if status == "æœ‰è´§" else 0
        detail.append(f"{s}:{stock}:0000000000000")
    if detail:
        info["Product Size Detail"] = ";".join(detail)


# ========== ä¸»æµç¨‹ ==========

# ========== å¤šçº¿ç¨‹ Chrome driver ç®¡ç†ï¼ˆv2ï¼‰ ==========
# ========== å¤šçº¿ç¨‹ Chrome driver ç®¡ç†ï¼ˆv3ï¼šæ”¹ç”¨ selenium_utilsï¼Œä»ç„¶å¤šçº¿ç¨‹ï¼‰ ==========
import threading
from common_taobao.core.selenium_utils import get_driver as _get_driver_v2
from common_taobao.core.selenium_utils import quit_all_drivers as _quit_all_drivers_v2

_thread_local_driver = threading.local()

def create_driver(headless: bool = False):
    # ä»ç„¶è¿”å›ä¸€ä¸ª driverï¼›å®é™…åˆ›å»ºäº¤ç»™ selenium_utils
    # name å›ºå®šå³å¯ï¼›selenium_utils å†…éƒ¨ä¼šè‡ªåŠ¨å¸¦çº¿ç¨‹ idï¼Œç¡®ä¿æ¯ä¸ªçº¿ç¨‹ä¸€ä¸ª driver
    return _get_driver_v2(
        name="outdoorandcountry",
        headless=headless,
        window_size="1920,1080",
    )

def get_driver(headless: bool = False):
    driver = getattr(_thread_local_driver, "driver", None)
    if driver is None:
        driver = create_driver(headless=headless)
        _thread_local_driver.driver = driver
    return driver

def shutdown_all_drivers():
    # å…³é—­æ‰€æœ‰çº¿ç¨‹çš„ driver
    _quit_all_drivers_v2()


def process_url(url, output_dir):
    
    try:
        driver = get_driver()
        print(f"\nğŸŒ æ­£åœ¨æŠ“å–: {url}")
        driver.get(url)
        accept_cookies(driver)
        time.sleep(3)
        html = driver.page_source

        # 1) è§£æï¼ˆå¤ç”¨ä½ å·²æœ‰çš„ç«™ç‚¹è§£æï¼‰
        info = parse_offer_info(html, url, site_name=CANON_SITE) or {}
        url_color = _normalize_color_from_url(url)

        if info.get("original_price_gbp"):
            info["Product Price"] = info["original_price_gbp"]
        if info.get("discount_price_gbp"):
            info["Adjusted Price"] = info["discount_price_gbp"]
        # 2) åŸºç¡€å­—æ®µè¡¥é½ï¼ˆç»Ÿä¸€ï¼‰
        info.setdefault("Brand", "Barbour")
        info.setdefault("Product Name", "No Data")
        info.setdefault("Product Color", url_color or "No Data")
        info.setdefault("Product Description", _extract_description(html))
        info.setdefault("Feature", _extract_features(html))
        info.setdefault("Site Name", CANON_SITE)
        info["Source URL"] = url  # ä¸å…¶ä»–ç«™ç‚¹ä¿æŒä¸€è‡´çš„å­—æ®µå

        # 3) Product Code / Product Color Codeï¼ˆä½ çš„ç­–ç•¥ï¼šç»„åˆç å³å¯ï¼‰
        color_code = info.get("Product Color Code") or _extract_color_code_from_jsonld(html)
        if color_code:
            info["Product Color Code"] = color_code
            info["Product Code"] = color_code  # âœ… ä½ è¦æ±‚ï¼šç›´æ¥æŠŠç»„åˆç å½“ Product Code

        # 4) æ€§åˆ«ï¼ˆä¼˜å…ˆæ ‡é¢˜/åç§°å…³é”®è¯ï¼Œå…œåº•ç”·æ¬¾ï¼‰
        if not info.get("Product Gender"):
            info["Product Gender"] = _infer_gender_from_name(info.get("Product Name", ""))

        # 5) Offers â†’ ä¸¤è¡Œå°ºç ï¼ˆä¸å†™ SizeMapï¼Œä¸”è¿‡æ»¤ 52ï¼‰
        offers = info.get("Offers") or []
        # âš ï¸ æŒ‰ä½ çš„è¦æ±‚ï¼šä¸å†å†™å…¥ Product Sizeï¼Œåªä¿ç•™ Detail
        _, psd = _build_sizes_from_offers(offers, info["Product Gender"])
        info["Product Size Detail"] = psd

        # 6) ç±»ç›®ï¼ˆæœ¬åœ°å…œåº•ï¼Œé˜²æ­¢ category_utils æ—§ç‰ˆè¯¯åˆ¤ï¼‰
        if not info.get("Style Category"):
            info["Style Category"] = _fallback_style_category(
                info.get("Product Name", ""),
                info.get("Product Description", ""),
                info.get("Product Code", "") or ""
            )

        # ========= âœ… Outdoor ä¸“å±å¢å¼ºï¼šå†™ç›˜å‰ä¸€æ¬¡æ€§å¤„ç† =========
        _inject_price_from_offers(info)   # Outdoor æ— ä»· â†’ ä» offers è¡¥
        _clean_sizes(info)                # æ¸…æ´—ï¼ˆä»… Detail ç”Ÿæ•ˆï¼‰
        _ensure_detail_from_size(info)    # æ²¡ Detail å°±ä» Size å…œåº•ï¼ˆDetail ç”¨ 3/0ï¼‰

        # 7) æ–‡ä»¶åç­–ç•¥
        if color_code:
            filename = f"{sanitize_filename(color_code)}.txt"
        else:
            safe_name = sanitize_filename(info.get('Product Name', 'NoName'))
            safe_color = sanitize_filename(info.get('Product Color', 'NoColor'))
            filename = f"{safe_name}_{safe_color}.txt"

        # 8) âœ… ç»Ÿä¸€ç”¨ txt_writer.format_txt å†™å‡ºï¼ˆä¸å…¶å®ƒç«™ç‚¹å®Œå…¨ä¸€è‡´ï¼‰
        output_dir.mkdir(parents=True, exist_ok=True)
        txt_path = output_dir / filename
        format_txt(info, txt_path, brand="Barbour")
        print(f"âœ… å†™å…¥: {txt_path.name}")

    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {url}\n    {e}")


def outdoorandcountry_fetch_info(max_workers=3):
    links_file = BARBOUR["LINKS_FILES"]["outdoorandcountry"]
    output_dir = BARBOUR["TXT_DIRS"]["outdoorandcountry"]
    output_dir.mkdir(parents=True, exist_ok=True)

    urls = []
    with open(links_file, "r", encoding="utf-8") as f:
        for line in f:
            url = line.strip()
            if url:
                urls.append(url)

    print(f"ğŸ”„ å¯åŠ¨å¤šçº¿ç¨‹æŠ“å–ï¼Œæ€»é“¾æ¥æ•°: {len(urls)}ï¼Œå¹¶å‘çº¿ç¨‹æ•°: {max_workers}")

    try:
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = [executor.submit(process_url, url, output_dir) for url in urls]
            for fut in as_completed(futures):
                fut.result()
    finally:
        shutdown_all_drivers()


if __name__ == "__main__":
    outdoorandcountry_fetch_info(max_workers=3)
