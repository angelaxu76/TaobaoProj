# -*- coding: utf-8 -*-
"""
Outdoor & Country | Barbour å•†å“æŠ“å–ï¼ˆv4 - åŠ é€Ÿç‰ˆï¼‰
ä¿æŒå¯¹å¤–æ¥å£ & pipeline å…¼å®¹ï¼š
- process_url(url, output_dir)
- outdoorandcountry_fetch_info(max_workers=3)

v4 æé€Ÿç‚¹ï¼š
1) æ¯ä¸ª driver åª accept cookies ä¸€æ¬¡ï¼ˆé¿å…æ¯é¡µç­‰å¾…ï¼‰
2) å»æ‰å›ºå®š sleep(3)ï¼Œæ”¹ä¸ºç­‰å¾… body å‡ºç° + çŸ­æš‚åœ 0.6s
3) é‡åˆ° Cloudflare/æŒ‘æˆ˜é¡µï¼šè‡ªåŠ¨é‡è¯• 1 æ¬¡
4) driver ä½¿ç”¨ common_taobao.core.selenium_utilsï¼ˆé”æ­»æœ¬åœ° chromedriverï¼Œä¸”ç¦å›¾ï¼‰
"""

import time
import json
import threading
import re
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urlparse, parse_qs, unquote

from bs4 import BeautifulSoup

from config import BARBOUR, SETTINGS
from brands.barbour.supplier.outdoorandcountry_parse_offer_info import parse_offer_info

# âœ… ç»Ÿä¸€ TXT å†™å…¥
from common_taobao.ingest.txt_writer import format_txt

# âœ… ä½¿ç”¨ç¨³å®š driver æ± ï¼ˆé”æ­» chromedriver + çº¿ç¨‹éš”ç¦» key + ç¦å›¾ï¼‰
from common_taobao.core.selenium_utils import get_driver as _get_driver_v2
from common_taobao.core.selenium_utils import quit_all_drivers as _quit_all_drivers_v2

# âœ… å°ºç æ¸…æ´—ï¼ˆä¿å®ˆï¼šè¯†åˆ«ä¸äº†å°±åŸæ ·è¿”å›ï¼‰
from common_taobao.core.size_utils import clean_size_for_barbour
from brands.barbour.core.site_utils import assert_site_or_raise as canon

CANON_SITE = canon("outdoorandcountry")
DEFAULT_STOCK_COUNT = SETTINGS.get("DEFAULT_STOCK_COUNT", 3)

# ========== æµè§ˆå™¨ä¸ Cookie ==========
def accept_cookies(driver, timeout=4):
    """
    v4ï¼šæ¯ä¸ª driver åªç‚¹ä¸€æ¬¡ cookieã€‚
    """
    if getattr(driver, "_cookies_accepted", False):
        return

    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC

    try:
        btn = WebDriverWait(driver, timeout).until(
            EC.element_to_be_clickable((By.ID, "onetrust-accept-btn-handler"))
        )
        btn.click()
        driver._cookies_accepted = True
        time.sleep(0.2)
    except Exception:
        # æ‰¾ä¸åˆ°ä¹Ÿå½“ä½œå·²å¤„ç†ï¼Œé¿å…æ¯æ¬¡éƒ½ç­‰
        driver._cookies_accepted = True


# ========== å·¥å…· ==========
def _normalize_color_from_url(url: str) -> str:
    try:
        qs = parse_qs(urlparse(url).query)
        c = qs.get("c", [None])[0]
        if not c:
            return ""
        c = unquote(c)  # %2F -> /
        c = c.replace("\\", "/")
        c = re.sub(r"\s*/\s*", " / ", c)
        c = re.sub(r"\s+", " ", c).strip()
        c = " ".join(w.capitalize() for w in c.split(" "))
        return c
    except Exception:
        return ""


def sanitize_filename(name: str) -> str:
    return re.sub(r'[\\/:*?"<>|\s]+', "_", name or "NoName")


def _extract_description(html: str) -> str:
    soup = BeautifulSoup(html, "html.parser")
    tag = soup.find("meta", attrs={"property": "og:description"})
    if tag and tag.get("content"):
        desc = tag["content"].replace("<br>", "").replace("<br/>", "").replace("<br />", "")
        return desc.strip()
    tab = soup.select_one(".product_tabs .tab_content[data-id='0'] div")
    return tab.get_text(" ", strip=True) if tab else "No Data"


def _extract_features(html: str) -> str:
    soup = BeautifulSoup(html, "html.parser")
    h3 = soup.find("h3", attrs={"title": "Features"})
    if h3:
        ul = h3.find_next("ul")
        if ul:
            items = [li.get_text(" ", strip=True) for li in ul.find_all("li")]
            return "; ".join(items)
    return "No Data"


def _extract_color_code_from_jsonld(html: str) -> str:
    """
    å…¼å®¹ outdoorandcountry JSON-LDï¼š
    - offers[].mpn æœ‰æ—¶æ˜¯ "MWX0017NY9108"ï¼ˆæœ«å°¾ä¸¤ä½å°ºç ï¼‰ -> æˆªæ‰å°ºç å¾—åˆ° MWX0017NY91
    - æœ‰æ—¶æ˜¯ "MWX0017NY91" æˆ– "MWX0017NY91_08"
    """
    soup = BeautifulSoup(html, "html.parser")
    for script in soup.find_all("script", type="application/ld+json"):
        try:
            data = script.string and script.string.strip()
            if not data:
                continue
            j = json.loads(data)

            # list/dict å…¼å®¹
            candidates = j if isinstance(j, list) else [j]
            for obj in candidates:
                if not isinstance(obj, dict):
                    continue
                if obj.get("@type") != "Product":
                    continue
                offers = obj.get("offers")
                if not offers:
                    continue
                offers_list = offers if isinstance(offers, list) else [offers]
                for off in offers_list:
                    mpn = (off or {}).get("mpn")
                    if not isinstance(mpn, str):
                        continue
                    mpn = mpn.split("_")[0].strip()

                    if len(mpn) >= 11:
                        maybe_code = mpn[:-2]
                        if re.match(r"^[A-Z]{3}\d{4}[A-Z]{2}\d{2}$", maybe_code):
                            return maybe_code

                    m = re.search(r'([A-Z]{2}\d{2})(\d{2})$', mpn)
                    if m:
                        return m.group(1)
        except Exception:
            continue
    return ""


def _infer_gender_from_name(name: str) -> str:
    n = (name or "").lower()
    if any(x in n for x in ["women", "women's", "womens", "ladies", "lady"]):
        return "å¥³æ¬¾"
    if any(x in n for x in ["men", "men's", "mens"]):
        return "ç”·æ¬¾"
    if any(x in n for x in ["kids", "kid", "boy", "girl"]):
        return "ç«¥æ¬¾"
    return "ç”·æ¬¾"


# ========== Outdoor ä¸“å±å°ºç é€»è¾‘ï¼ˆä¿æŒä½ ç°æœ‰é£æ ¼ï¼‰ ==========
WOMEN_NUM = ["6", "8", "10", "12", "14", "16", "18", "20"]
MEN_ALPHA = ["S", "M", "L", "XL", "XXL", "XXXL"]
MEN_NUM = [str(s) for s in range(32, 52, 2)]  # 32..50 å¶æ•°


def _clean_size(raw: str) -> str:
    raw = (raw or "").strip()
    if not raw:
        return ""
    s = clean_size_for_barbour(raw) or raw
    return s.strip()


def _build_sizes_from_offers(offers, gender: str):
    """
    offers: [(size_str, price, stock_text, can_order), ...]
    è¾“å‡ºï¼š
      Product Size Detail: "6:3:0000000000000;8:0:0000000000000;..."
    v4ï¼šåªå†™ Detailï¼Œä¸å†™ SizeMap
    """
    if not offers:
        return "No Data"

    temp = []
    for size, price, stock_text, can_order in offers:
        size = (size or "").strip()
        if not size:
            continue

        stock = 0
        if (stock_text or "").strip().lower() in ("in stock", "available"):
            stock = DEFAULT_STOCK_COUNT
        if can_order and stock == 0:
            stock = DEFAULT_STOCK_COUNT

        cs = _clean_size(size)
        if not cs:
            continue

        # è¿‡æ»¤ 52 åŠä»¥ä¸Šç”·è£…æ•°å­—å°ºç 
        m = re.match(r"^(\d{2})$", cs)
        if m and int(m.group(1)) >= 52:
            continue

        temp.append((cs, stock))

    if not temp:
        return "No Data"

    # å»é‡åˆå¹¶ï¼ˆåŒå°ºç å–æœ€å¤§åº“å­˜ï¼‰
    bucket = {}
    for s, stock in temp:
        bucket[s] = max(bucket.get(s, 0), stock)

    # æ’åºï¼šå¥³æ¬¾æŒ‰ 6-20ï¼›ç”·æ¬¾æŒ‰å­—æ¯+æ•°å­—
    ordered = []
    if "å¥³" in (gender or ""):
        for s in WOMEN_NUM:
            if s in bucket:
                ordered.append(s)
        for s in bucket:
            if s not in ordered:
                ordered.append(s)
    else:
        for s in MEN_ALPHA:
            if s in bucket:
                ordered.append(s)
        for s in MEN_NUM:
            if s in bucket:
                ordered.append(s)
        for s in bucket:
            if s not in ordered:
                ordered.append(s)

    # ç”Ÿæˆ Detail
    out = []
    for s in ordered:
        qty = DEFAULT_STOCK_COUNT if bucket.get(s, 0) > 0 else 0
        out.append(f"{s}:{qty}:0000000000000")

    return ";".join(out) if out else "No Data"


# ========== å¤šçº¿ç¨‹ driver ç®¡ç†ï¼ˆæ¥å£ä¸å˜ï¼‰ ==========
# ========== å¤šçº¿ç¨‹ driver ç®¡ç†ï¼ˆv4.1ï¼šå®šæœŸé‡å¯ï¼Œé˜²æ­¢è¶Šè·‘è¶Šæ…¢ï¼‰ ==========
_thread_local_driver = threading.local()

# æ¯ä¸ªçº¿ç¨‹è·‘å¤šå°‘ä¸ªé¡µé¢å°±é‡å¯ä¸€æ¬¡ driverï¼ˆå»ºè®® 30~80 ä¹‹é—´ï¼‰
_RESTART_EVERY = 50

def create_driver(headless: bool = False):
    return _get_driver_v2(
        name="outdoorandcountry",
        headless=True,
        window_size="1200,1600",
    )

def get_driver(headless: bool = False):
    d = getattr(_thread_local_driver, "driver", None)
    n = getattr(_thread_local_driver, "count", 0)

    # å¦‚æœæ²¡æœ‰ driverï¼Œæˆ–åˆ°è¾¾é‡å¯é˜ˆå€¼ï¼Œåˆ™é‡å»º
    if d is None or n >= _RESTART_EVERY:
        try:
            if d is not None:
                d.quit()
        except Exception:
            pass

        d = create_driver(headless=headless)
        _thread_local_driver.driver = d
        _thread_local_driver.count = 0
        return d

    return d

def mark_driver_used():
    _thread_local_driver.count = getattr(_thread_local_driver, "count", 0) + 1

def shutdown_all_drivers():
    _quit_all_drivers_v2()



# ========== v4ï¼šæŒ‘æˆ˜é¡µæ£€æµ‹ + è½»é‡é‡è¯• ==========
def _is_challenge_page(html: str) -> bool:
    low = (html or "").lower()
    return (
        "checking your browser" in low
        or "attention required" in low
        or "cloudflare" in low
        or "access denied" in low
        or "captcha" in low
        or "<title>just a moment" in low
    )


def process_url(url, output_dir):
    """
    âœ… å¤–éƒ¨æ¥å£ä¿æŒä¸å˜ï¼šprocess_url(url, output_dir)
    """
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC

    try:
        driver = get_driver()
        print(f"\nğŸŒ æ­£åœ¨æŠ“å–: {url}", flush=True)

        # 1) é¦–æ¬¡åŠ è½½ï¼ˆv4ï¼šåªç­‰ body + 0.6s çŸ­æš‚åœï¼‰
        driver.get(url)
        accept_cookies(driver)

        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.TAG_NAME, "body"))
        )
        time.sleep(0.6)
        html = driver.page_source

        # 2) æŒ‘æˆ˜é¡µåˆ™é‡è¯•ä¸€æ¬¡
        if _is_challenge_page(html):
            print("âš ï¸ æ£€æµ‹åˆ°æŒ‘æˆ˜é¡µï¼Œé‡è¯•ä¸€æ¬¡...", flush=True)
            time.sleep(1.2)
            driver.get(url)
            accept_cookies(driver)
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
            time.sleep(0.6)
            html = driver.page_source

        # 3) è§£æï¼ˆå¤ç”¨ä½ å·²æœ‰è§£æå™¨ï¼‰
        info = parse_offer_info(html, url, site_name=CANON_SITE) or {}
        url_color = _normalize_color_from_url(url)

        # ä»·æ ¼å­—æ®µå…¼å®¹
        if info.get("original_price_gbp"):
            info["Product Price"] = info["original_price_gbp"]
        if info.get("discount_price_gbp"):
            info["Adjusted Price"] = info["discount_price_gbp"]

        # 4) åŸºç¡€å­—æ®µè¡¥é½
        info.setdefault("Brand", "Barbour")
        info.setdefault("Product Name", "No Data")
        info.setdefault("Product Color", url_color or "No Data")
        info.setdefault("Product Description", _extract_description(html))
        info.setdefault("Feature", _extract_features(html))
        info.setdefault("Site Name", CANON_SITE)
        info["Source URL"] = url

        # 5) Product Code / Product Color Codeï¼ˆç»„åˆç ç­–ç•¥ï¼‰
        color_code = info.get("Product Color Code") or _extract_color_code_from_jsonld(html)
        if color_code:
            info["Product Color Code"] = color_code
            info["Product Code"] = color_code

        # 6) æ€§åˆ«å…œåº•
        if not info.get("Product Gender"):
            info["Product Gender"] = _infer_gender_from_name(info.get("Product Name", ""))

        # 7) Offers â†’ Product Size Detailï¼ˆåªå†™ Detailï¼‰
        offers = info.get("Offers") or []
        info["Product Size Detail"] = _build_sizes_from_offers(offers, info.get("Product Gender") or "")

        # 8) æ–‡ä»¶åç­–ç•¥
        if color_code:
            filename = f"{sanitize_filename(color_code)}.txt"
        else:
            safe_name = sanitize_filename(info.get("Product Name", "NoName"))
            safe_color = sanitize_filename(info.get("Product Color", "NoColor"))
            filename = f"{safe_name}_{safe_color}.txt"

        output_dir.mkdir(parents=True, exist_ok=True)
        txt_path = output_dir / filename
        format_txt(info, txt_path, brand="Barbour")
        print(f"âœ… å†™å…¥: {txt_path.name}", flush=True)

    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {url}\n    {repr(e)}", flush=True)
    finally:
        mark_driver_used()


def outdoorandcountry_fetch_info(max_workers=3):
    """
    âœ… å¤–éƒ¨æ¥å£ä¿æŒä¸å˜ï¼šoutdoorandcountry_fetch_info(max_workers=3)
    """
    links_file = BARBOUR["LINKS_FILES"]["outdoorandcountry"]
    output_dir = BARBOUR["TXT_DIRS"]["outdoorandcountry"]
    output_dir.mkdir(parents=True, exist_ok=True)

    urls = []
    with open(links_file, "r", encoding="utf-8") as f:
        for line in f:
            u = line.strip()
            if u:
                urls.append(u)

    print(f"ğŸ”„ å¯åŠ¨å¤šçº¿ç¨‹æŠ“å–ï¼ˆv4 åŠ é€Ÿï¼‰ï¼Œæ€»é“¾æ¥æ•°: {len(urls)}ï¼Œå¹¶å‘çº¿ç¨‹æ•°: {max_workers}", flush=True)

    try:
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = [executor.submit(process_url, url, output_dir) for url in urls]
            for fut in as_completed(futures):
                fut.result()
    finally:
        shutdown_all_drivers()


if __name__ == "__main__":
    outdoorandcountry_fetch_info(max_workers=3)
