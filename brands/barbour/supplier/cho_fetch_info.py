# brands/barbour/supplier/cho_fetch_info.py
# -*- coding: utf-8 -*-

"""
CHO | Barbour å•†å“æŠ“å–è„šæœ¬
- è§£æ Shopify JSON-LD ProductGroup + DOM ä»·æ ¼åŒº
- TXT è¾“å‡ºæ¨¡æ¿ä¸ Outdoor / Allweathers å®Œå…¨ä¸€è‡´ï¼ˆä½¿ç”¨ format_txtï¼‰
"""

import re
import time
import tempfile
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Tuple

from bs4 import BeautifulSoup
from selenium import webdriver

import demjson3

from brands.barbour.core.site_utils import assert_site_or_raise as canon

# ç»Ÿä¸€ TXT å†™å…¥
from common_taobao.ingest.txt_writer import format_txt
from config import BARBOUR, BRAND_CONFIG, SETTINGS
DEFAULT_STOCK_COUNT = SETTINGS.get("DEFAULT_STOCK_COUNT", 3)
# å¯é€‰ stealth
try:
    from selenium_stealth import stealth
except ImportError:
    def stealth(*args, **kwargs):
        return

# å¯é€‰ï¼šBarbour æ€§åˆ«ä¿®æ­£ï¼ˆæ ¹æ®ç¼–ç å‰ç¼€ç­‰ï¼‰
try:
    from common_taobao.core.size_normalizer import infer_gender_for_barbour
except Exception:
    infer_gender_for_barbour = None

# ========== å…¨å±€é…ç½® ==========

CANON_SITE = canon("cho")  # ç¡®ä¿åœ¨ site_utils é‡Œæœ‰æ˜ å°„
LINK_FILE = BARBOUR["LINKS_FILES"]["cho"]
TXT_DIR = BARBOUR["TXT_DIRS"]["cho"]
TXT_DIR.mkdir(parents=True, exist_ok=True)

MAX_WORKERS = 4


# ========== Selenium Driver ==========

def get_driver():
    """
    ç®€å•ç‰ˆ driverï¼›å¦‚æœä½ åé¢ç»Ÿä¸€æ”¹æˆ selenium_utilsï¼Œè¿™é‡Œç›´æ¥æ›¿æ¢å³å¯ã€‚
    """
    temp_profile = tempfile.mkdtemp()
    options = webdriver.ChromeOptions()
    options.add_argument("--headless=new")
    options.add_argument(f"--user-data-dir={temp_profile}")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-gpu")
    options.add_argument("--window-size=1920,1080")

    driver = webdriver.Chrome(options=options)
    try:
        stealth(
            driver,
            languages=["en-GB", "en-US", "en"],
            vendor="Google Inc.",
            platform="Win32",
            webgl_vendor="Intel Inc.",
            renderer="Intel Iris OpenGL Engine",
            fix_hairline=True,
        )
    except Exception:
        # æ²¡æœ‰ stealth ä¹Ÿä¸å½±å“
        pass
    return driver


# ========== å·¥å…·å‡½æ•°ï¼ˆä¸ Allweathers åŒé£æ ¼ï¼‰ ==========

def _clean_text(s: str) -> str:
    return re.sub(r"\s+", " ", (s or "").strip())


def _infer_gender_from_title(title_or_name: str) -> str:
    t = (title_or_name or "").lower()
    if re.search(r"\b(women|woman|women's|ladies)\b", t):
        return "å¥³æ¬¾"
    if re.search(r"\b(men|men's|man)\b", t):
        return "ç”·æ¬¾"
    if re.search(r"\b(kids?|boys?|girls?)\b", t):
        return "ç«¥æ¬¾"
    return "æœªçŸ¥"


def _to_float(x: str) -> float | None:
    if not x:
        return None
    try:
        m = re.search(r"([0-9]+(?:\.[0-9]+)?)", x.replace(",", ""))
        return float(m.group(1)) if m else None
    except Exception:
        return None


def _extract_price_pair_from_dom_cho(soup: BeautifulSoup) -> Tuple[float | None, float | None]:
    """
    ä» CHO DOM ä¸­æŠ“å– (original_price, current_price)
    - æ‰“æŠ˜æ—¶ï¼š
        .price__sale .price-item--sale        => ç°ä»·
        .savings-price .price-item--regular   => åŸä»·
    - æ— æ‰“æŠ˜ï¼š
        .price__regular .price-item--regular  => åŸä»· == ç°ä»·
    """
    # æœ‰æ‰“æŠ˜
    sale_span = soup.select_one(".price__sale .price-item--sale")
    was_span = soup.select_one(".price__sale .savings-price .price-item--regular")
    sale_price = _to_float(sale_span.get_text(" ", strip=True)) if sale_span else None
    was_price = _to_float(was_span.get_text(" ", strip=True)) if was_span else None

    if sale_price is not None and was_price is not None:
        return was_price, sale_price  # (åŸä»·, æŠ˜åä»·)

    # æ— æ‰“æŠ˜ â†’ ç›´æ¥ç”¨ regular ä»·
    reg_span = soup.select_one(".price__regular .price-item--regular")
    reg_price = _to_float(reg_span.get_text(" ", strip=True)) if reg_span else None
    if reg_price is not None:
        return reg_price, reg_price

    return None, None


def _load_product_jsonld(soup: BeautifulSoup) -> dict:
    """
    è¿”å› JSON-LD ä¸­çš„ ProductGroup / Product èŠ‚ç‚¹ï¼ˆCHO ç”¨ ProductGroupï¼‰
    """
    for tag in soup.find_all("script", {"type": "application/ld+json"}):
        txt = (tag.string or tag.text or "").strip()
        if not txt:
            continue
        try:
            j = demjson3.decode(txt)
        except Exception:
            continue
        if isinstance(j, dict) and j.get("@type") in ("ProductGroup", "Product"):
            return j
    raise ValueError("æœªæ‰¾åˆ° ProductGroup/Product JSON-LD æ•°æ®")


def _extract_code_from_description(desc: str) -> str:
    """
    ä» description æœ«å°¾æå– Barbour ç¼–ç ï¼Œå¦‚ MQU0281NY71ã€‚
    ä¸€èˆ¬åœ¨æœ€åä¸€è¡Œã€‚
    """
    if not desc:
        return "No Data"
    # å…ˆæŒ‰è¡Œæ‹†åˆ†ï¼Œå–æœ€åä¸€ä¸ªéç©ºè¡Œ
    lines = [l.strip() for l in desc.splitlines() if l.strip()]
    if lines:
        last = lines[-1]
        m = re.search(r"\b[A-Z0-9]{3}\d{4}[A-Z0-9]{2}\d{2}\b", last)
        if m:
            return m.group(0)

    # å…¨æ–‡å…œåº•ï¼šå–æœ€åä¸€ä¸ªåŒ¹é…
    m_all = list(re.finditer(r"\b[A-Z0-9]{3}\d{4}[A-Z0-9]{2}\d{2}\b", desc))
    if m_all:
        return m_all[-1].group(0)
    return "No Data"


def _strip_code_from_description(desc: str, code: str) -> str:
    if not desc:
        return "No Data"
    if not code or code == "No Data":
        return _clean_text(desc)
    return _clean_text(desc.replace(code, "")).strip(" -â€“|,")


# ========== å°ºç å¤„ç†ï¼ˆç›´æ¥å¤ç”¨ Allweathers é€»è¾‘ï¼‰ ==========

WOMEN_ORDER = ["4", "6", "8", "10", "12", "14", "16", "18", "20"]
MEN_ALPHA_ORDER = ["2XS", "XS", "S", "M", "L", "XL", "2XL", "3XL"]
MEN_NUM_ORDER = [str(n) for n in range(30, 52, 2)]  # 30..50ï¼ˆä¸å«52ï¼‰

ALPHA_MAP = {
    "XXXS": "2XS", "2XS": "2XS",
    "XXS": "XS",  "XS": "XS",
    "S": "S", "SMALL": "S",
    "M": "M", "MEDIUM": "M",
    "L": "L", "LARGE": "L",
    "XL": "XL", "X-LARGE": "XL",
    "XXL": "2XL", "2XL": "2XL",
    "XXXL": "3XL", "3XL": "3XL",
}


def _choose_full_order_for_gender(gender: str, present: set[str]) -> list[str]:
    """ä¸ Allweathers ä¿æŒä¸€è‡´ï¼šç”·æ¬¾åœ¨ã€å­—æ¯ç³»ã€‘ä¸ã€æ•°å­—ç³»ã€‘äºŒé€‰ä¸€ï¼›å¥³æ¬¾å›ºå®š 4â€“20ã€‚"""
    g = (gender or "").lower()
    if "å¥³" in g:
        return WOMEN_ORDER[:]

    has_num = any(k in MEN_NUM_ORDER for k in present)
    has_alpha = any(k in MEN_ALPHA_ORDER for k in present)
    if has_num and not has_alpha:
        return MEN_NUM_ORDER[:]
    if has_alpha and not has_num:
        return MEN_ALPHA_ORDER[:]
    if has_num or has_alpha:
        num_count = sum(1 for k in present if k in MEN_NUM_ORDER)
        alpha_count = sum(1 for k in present if k in MEN_ALPHA_ORDER)
        return MEN_NUM_ORDER[:] if num_count >= alpha_count else MEN_ALPHA_ORDER[:]
    return MEN_ALPHA_ORDER[:]


def _normalize_size(token: str, gender: str) -> str | None:
    """
    ä¸ Allweathers ä¸€è‡´çš„å½’ä¸€åŒ–é€»è¾‘ï¼š
    - å¥³æ¬¾ï¼š4â€“20 æ•°å­—
    - ç”·æ¬¾ï¼š30â€“50 å¶æ•° æˆ– 2XS..3XL
    """
    s = (token or "").strip().upper()
    s = s.replace("UK ", "").replace("EU ", "").replace("US ", "")
    s = re.sub(r"\s*\(.*?\)\s*", "", s)
    s = re.sub(r"\s+", " ", s)

    # æ•°å­—ä¼˜å…ˆ
    m = re.findall(r"\d{1,3}", s)
    if m:
        n = int(m[0])
        if gender == "å¥³æ¬¾" and n in {4, 6, 8, 10, 12, 14, 16, 18, 20}:
            return str(n)
        if gender == "ç”·æ¬¾":
            if 30 <= n <= 50 and n % 2 == 0:
                return str(n)
            if 28 <= n <= 54:
                cand = n if n % 2 == 0 else n - 1
                cand = max(30, min(50, cand))
                return str(cand)
        return None

    key = s.replace("-", "").replace(" ", "")
    return ALPHA_MAP.get(key)


def _build_size_lines_from_sizedetail(size_detail: dict, gender: str) -> tuple[str, str]:
    """
    è¾“å…¥ï¼šSizeDetail = { raw_size: {stock_count:int, ean:str}, ... }
    è¾“å‡ºï¼š
      Product Size        = "M:æœ‰è´§;L:æ— è´§;..."
      Product Size Detail = "M:3:000...;L:0:000...;..."
    """
    bucket_status: dict[str, str] = {}
    bucket_stock: dict[str, int] = {}

    # 1) æ±‡æ€»é¡µé¢å‡ºç°çš„å°ºç 
    for raw_size, meta in (size_detail or {}).items():
        norm = _normalize_size(raw_size, gender or "ç”·æ¬¾")
        if not norm:
            continue
        stock = int(meta.get("stock_count", 0) or 0)
        status = "æœ‰è´§" if stock > 0 else "æ— è´§"
        prev = bucket_status.get(norm)
        if prev is None or (prev == "æ— è´§" and status == "æœ‰è´§"):
            bucket_status[norm] = status
            bucket_stock[norm] = DEFAULT_STOCK_COUNT if stock > 0 else 0

    # 2) é€‰æ‹©å•ä¸€å°ºç ç³»
    present_keys = set(bucket_status.keys())
    full_order = _choose_full_order_for_gender(gender or "ç”·æ¬¾", present_keys)

    # 2.5) æ¸…é™¤ä¸åœ¨è¯¥ä½“ç³»å†…çš„å°ºç 
    for k in list(bucket_status.keys()):
        if k not in full_order:
            bucket_status.pop(k, None)
            bucket_stock.pop(k, None)

    # 3) è¡¥é½æœªå‡ºç°çš„å°ºç ä¸ºæ— è´§/0
    for size in full_order:
        if size not in bucket_status:
            bucket_status[size] = "æ— è´§"
            bucket_stock[size] = 0

    ordered = list(full_order)
    ps = ";".join(f"{k}:{bucket_status[k]}" for k in ordered)
    psd = ";".join(f"{k}:{bucket_stock[k]}:0000000000000" for k in ordered)
    return ps, psd


# ========== è§£æè¯¦æƒ…é¡µ ==========

def parse_detail_page(html: str, url: str) -> dict:
    soup = BeautifulSoup(html, "html.parser")

    data = _load_product_jsonld(soup)
    name = data.get("name") or (soup.title.get_text(strip=True) if soup.title else "No Data")
    desc = data.get("description") or ""
    desc = desc.replace("\\n", "\n")
    desc = desc.replace("<br>", "\n").replace("<br/>", "\n").replace("<br />", "\n")

    product_code = _extract_code_from_description(desc)
    description = _strip_code_from_description(desc, product_code)

    # å°ºç /åº“å­˜
    variants = data.get("hasVariant", [])
    if isinstance(variants, dict):
        variants = [variants]
    if not variants:
        raise ValueError("æœªæ‰¾åˆ° hasVariant å˜ä½“æ•°æ®")

    size_detail = {}
    color = "No Data"

    for v in variants:
        v_name = v.get("name") or ""
        # name å½¢å¦‚ï¼šBarbour Powell Mens Quilted Jacket - Navy - Navy / L
        tail = v_name.split(" - ")[-1] if " - " in v_name else v_name
        if " / " in tail:
            c_txt, sz_txt = [p.strip() for p in tail.split(" / ", 1)]
        else:
            c_txt, sz_txt = (tail.strip() or "No Data"), "Unknown"
        if color == "No Data":
            color = c_txt or "No Data"

        offers = v.get("offers") or {}
        avail = (offers.get("availability") or "").lower()
        in_stock = "instock" in avail

        size_detail[sz_txt] = {
            "stock_count": DEFAULT_STOCK_COUNT if in_stock else 0,
            "ean": v.get("gtin") or v.get("sku") or "0000000000000",
        }

    gender_guess = _infer_gender_from_title(name)

    # ä»·æ ¼ï¼šDOM ä¼˜å…ˆï¼ˆåŸä»·/æŠ˜åä»·ï¼‰
    original_price, current_price = _extract_price_pair_from_dom_cho(soup)

    info = {
        "Product Code": product_code or "No Data",
        "Product Name": name,
        "Product Description": description or "No Data",
        "Product Gender": gender_guess,
        "Product Color": color or "No Data",
        "Product Price": original_price,
        "Adjusted Price": current_price,
        "Product Material": "No Data",
        "Feature": "No Data",
        "SizeDetail": size_detail,
        "Source URL": url,
        "Site Name": CANON_SITE,
    }
    return info


# ========== æŠ“å– & å†™ TXT ==========

def fetch_one_product(url: str, idx: int, total: int):
    print(f"[{idx}/{total}] æŠ“å–: {url}")
    try:
        driver = get_driver()
        driver.get(url)
        time.sleep(2.5)
        html = driver.page_source
        driver.quit()

        info = parse_detail_page(html, url)

        # åŸºç¡€å­—æ®µè¡¥é½
        info.setdefault("Brand", "Barbour")
        info.setdefault("Site Name", CANON_SITE)
        info.setdefault("Source URL", url)

        # æ€§åˆ«ä¿®æ­£ï¼šä¼˜å…ˆæ ¹æ® Barbour ç¼–ç 
        if infer_gender_for_barbour:
            info["Product Gender"] = infer_gender_for_barbour(
                product_code=info.get("Product Code"),
                title=info.get("Product Name"),
                description=info.get("Product Description"),
                given_gender=info.get("Product Gender"),
            ) or info.get("Product Gender") or "ç”·æ¬¾"

        # SizeDetail â†’ Product Size / Product Size Detail
        if info.get("SizeDetail") and (not info.get("Product Size") or not info.get("Product Size Detail")):
            ps, psd = _build_size_lines_from_sizedetail(info["SizeDetail"], info.get("Product Gender", "ç”·æ¬¾"))
            info["Product Size"] = info.get("Product Size") or ps
            info["Product Size Detail"] = info.get("Product Size Detail") or psd

        # æ–‡ä»¶åï¼šä½¿ç”¨ Product Code
        code = info.get("Product Code") or "NoData"
        safe_code = re.sub(r"[^A-Za-z0-9_-]+", "_", code)
        txt_path = TXT_DIR / f"{safe_code}.txt"

        format_txt(info, txt_path, brand="Barbour")
        return (url, "âœ… æˆåŠŸ")
    except Exception as e:
        return (url, f"âŒ å¤±è´¥: {e}")


def cho_fetch_info(max_workers: int = MAX_WORKERS):
    print(f"ğŸš€ å¯åŠ¨ CHO å¤šçº¿ç¨‹å•†å“è¯¦æƒ…æŠ“å–ï¼ˆçº¿ç¨‹æ•°: {max_workers}ï¼‰")
    links = LINK_FILE.read_text(encoding="utf-8").splitlines()
    links = [u.strip() for u in links if u.strip()]
    total = len(links)
    if total == 0:
        print("âš  é“¾æ¥æ–‡ä»¶ä¸ºç©º")
        return

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = [
            executor.submit(fetch_one_product, url, idx + 1, total)
            for idx, url in enumerate(links)
        ]
        for future in as_completed(futures):
            url, status = future.result()
            print(f"{status} - {url}")

    print("\nâœ… CHO å•†å“æŠ“å–å®Œæˆ")


if __name__ == "__main__":
    cho_fetch_info(max_workers=10)
