# -*- coding: utf-8 -*-
"""
CHO (Country House Outdoor) é‡‡é›†å™¨ - é‡æ„ç‰ˆ

ä¿®å¤:
- JSON-LD: ç”¨ demjson3 è§£æ (å…¼å®¹ Shopify éæ ‡ JSON)
- å°ºç /é¢œè‰²: ä» hasVariant name è§£æ (æ ¼å¼: "Name - Color / Size")
- ä»·æ ¼: DOM .price__sale / .price__regular æå–
- Driver: æ¯çº¿ç¨‹ç‹¬ç«‹ (çº¿ç¨‹å®‰å…¨)
- å­—æ®µå: ä¸ format_txt å¯¹é½ (Product Price / Adjusted Price)
- æ€§åˆ«: ä¸­æ–‡è¾“å‡º (ç”·æ¬¾/å¥³æ¬¾)

ä½¿ç”¨æ–¹å¼:
    python -m brands.barbour.supplier.cho_fetch_info_v2
"""

from __future__ import annotations

import re
import time
import threading
from typing import Dict, Any, Optional, Tuple
from bs4 import BeautifulSoup
import psycopg2
import demjson3

from brands.barbour.core.hybrid_barbour_matcher import resolve_product_code

# å¯¼å…¥åŸºç±»å’Œå·¥å…·
from brands.barbour.core.base_fetcher import BaseFetcher, setup_logging

# å¯¼å…¥é€šç”¨æ¨¡å—
from common.browser.selenium_utils import get_driver, quit_driver

# é…ç½®
from config import BARBOUR, SETTINGS, PGSQL_CONFIG

SITE_NAME = "cho"
LINKS_FILE = BARBOUR["LINKS_FILES"].get("cho", "")
OUTPUT_DIR = BARBOUR["TXT_DIRS"].get("cho", "")
DEFAULT_STOCK_COUNT = SETTINGS.get("DEFAULT_STOCK_COUNT", 3)

# åˆ¤æ–­ç¼–ç æ˜¯å¦ä¸ºå®Œæ•´ 11 ä½æ ¼å¼ (å¦‚ LQU0475OL71)
_FULL_CODE_RE = re.compile(r"^[A-Z]{2,3}\d{4}[A-Z]{2}\d{2}$")


def _is_partial_code(code: str) -> bool:
    """åˆ¤æ–­ç¼–ç æ˜¯å¦ä¸ºæˆªæ–­æ ¼å¼ (7ä½, å¦‚ LQU0475, æ— é¢œè‰²åç¼€)"""
    if not code or code == "No Data":
        return False
    return len(code) <= 8 and not _FULL_CODE_RE.match(code)


# ================== è¾…åŠ©å‡½æ•° ==================

def _clean_text(s: str) -> str:
    return re.sub(r"\s+", " ", (s or "").strip())


def _to_float(x: str) -> Optional[float]:
    if not x:
        return None
    try:
        m = re.search(r"([0-9]+(?:\.[0-9]+)?)", x.replace(",", ""))
        return float(m.group(1)) if m else None
    except Exception:
        return None


def _extract_price_pair_from_dom_cho(soup: BeautifulSoup) -> Tuple[Optional[float], Optional[float]]:
    """
    ä» CHO DOM ä¸­æŠ“å– (original_price, current_price)
    - æ‰“æŠ˜:
        .price__sale .price-item--sale        => ç°ä»·
        .savings-price .price-item--regular   => åŸä»·
    - æ— æ‰“æŠ˜:
        .price__regular .price-item--regular  => åŸä»· == ç°ä»·
    """
    sale_span = soup.select_one(".price__sale .price-item--sale")
    was_span = soup.select_one(".price__sale .savings-price .price-item--regular")
    sale_price = _to_float(sale_span.get_text(" ", strip=True)) if sale_span else None
    was_price = _to_float(was_span.get_text(" ", strip=True)) if was_span else None

    if sale_price is not None and was_price is not None:
        return was_price, sale_price  # (åŸä»·, æŠ˜åä»·)

    reg_span = soup.select_one(".price__regular .price-item--regular")
    reg_price = _to_float(reg_span.get_text(" ", strip=True)) if reg_span else None
    if reg_price is not None:
        return reg_price, reg_price

    return None, None


def _load_product_jsonld(soup: BeautifulSoup) -> dict:
    """è¿”å› JSON-LD ä¸­çš„ ProductGroup / Product èŠ‚ç‚¹ (ç”¨ demjson3 å…¼å®¹éæ ‡ JSON)"""
    for tag in soup.find_all("script", {"type": "application/ld+json"}):
        txt = (tag.string or tag.text or "").strip()
        if not txt:
            continue
        try:
            j = demjson3.decode(txt)
        except Exception:
            continue
        if isinstance(j, dict) and j.get("@type") in ("ProductGroup", "Product"):
            return j
    raise ValueError("æœªæ‰¾åˆ° ProductGroup/Product JSON-LD æ•°æ®")


def _extract_code_from_description(desc: str) -> str:
    """
    ä» description æœ«å°¾æå– Barbour ç¼–ç .
    å®Œæ•´æ ¼å¼: MQU0281NY71 (11å­—ç¬¦: 3å­—æ¯+4æ•°å­—+2å­—æ¯+2æ•°å­—)
    æˆªæ–­æ ¼å¼: LCA0362     (7å­—ç¬¦: 3å­—æ¯+4æ•°å­—, CHO å¸¸è§)
    ä¼˜å…ˆåŒ¹é…å®Œæ•´æ ¼å¼, å…¶æ¬¡åŒ¹é…æˆªæ–­æ ¼å¼.
    """
    if not desc:
        return "No Data"

    # æ­£åˆ™: å®Œæ•´ 11 å­—ç¬¦æ ¼å¼
    FULL_PAT = r"\b[A-Z]{2,3}\d{4}[A-Z]{2}\d{2}\b"
    # æ­£åˆ™: æˆªæ–­ 7 å­—ç¬¦æ ¼å¼ (CHO å¸¸ç”¨, æ— é¢œè‰²åç¼€)
    SHORT_PAT = r"\b[A-Z]{2,3}\d{4}\b"

    lines = [l.strip() for l in desc.splitlines() if l.strip()]

    # 1) å…ˆåœ¨æœ€åä¸€è¡Œæ‰¾å®Œæ•´æ ¼å¼
    if lines:
        last = lines[-1]
        m = re.search(FULL_PAT, last)
        if m:
            return m.group(0)

    # 2) å…¨æ–‡æ‰¾å®Œæ•´æ ¼å¼ (å–æœ€åä¸€ä¸ª)
    m_all = list(re.finditer(FULL_PAT, desc))
    if m_all:
        return m_all[-1].group(0)

    # 3) æœ€åä¸€è¡Œæ‰¾æˆªæ–­æ ¼å¼
    if lines:
        last = lines[-1]
        m = re.search(SHORT_PAT, last)
        if m:
            return m.group(0)

    # 4) å…¨æ–‡æ‰¾æˆªæ–­æ ¼å¼ (å–æœ€åä¸€ä¸ª)
    m_all = list(re.finditer(SHORT_PAT, desc))
    if m_all:
        return m_all[-1].group(0)

    return "No Data"


def _strip_code_from_description(desc: str, code: str) -> str:
    if not desc:
        return "No Data"
    if not code or code == "No Data":
        return _clean_text(desc)
    return _clean_text(desc.replace(code, "")).strip(" -â€“|,")


# ================== é‡‡é›†å™¨å®ç° ==================

class CHOFetcher(BaseFetcher):
    """
    CHO é‡‡é›†å™¨ - ä¸ v1 é€»è¾‘å®Œå…¨å¯¹é½

    é‡å†™:
    - parse_detail_page: ä» hasVariant è§£æå°ºç /é¢œè‰², DOM è§£æä»·æ ¼
    - _fetch_html: æ¯çº¿ç¨‹ç‹¬ç«‹ driver
    - æˆªæ–­ç¼–ç è‡ªåŠ¨é€šè¿‡ DB åŒ¹é…è¡¥å…¨
    """

    

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self._db_conn = None

    def _get_db_conn(self):
        """æ‡’åŠ è½½ DB è¿æ¥ (ç”¨äº partial_code æŸ¥è¯¢)"""
        if self._db_conn is None or self._db_conn.closed:
            try:
                self._db_conn = psycopg2.connect(**PGSQL_CONFIG)
                self.logger.info("ğŸ”— DB è¿æ¥å·²å»ºç«‹ (ç”¨äºç¼–ç è¡¥å…¨)")
            except Exception as e:
                self.logger.warning(f"DB è¿æ¥å¤±è´¥, è·³è¿‡ç¼–ç è¡¥å…¨: {e}")
                return None
        return self._db_conn

    def _fetch_html(self, url: str) -> str:
        """è¦†ç›–åŸºç±»: æ¯çº¿ç¨‹ç‹¬ç«‹ driver"""
        tid = threading.current_thread().ident
        driver_name = f"{self.site_name}_{tid}"
        driver = get_driver(
            name=driver_name,
            headless=self.headless,
            window_size="1920,1080",
        )
        try:
            driver.get(url)
            time.sleep(self.wait_seconds)
            return driver.page_source
        finally:
            quit_driver(driver_name)

    def parse_detail_page(self, html: str, url: str) -> Dict[str, Any]:
        """è§£æ CHO å•†å“è¯¦æƒ…é¡µ - ä¸ v1 é€»è¾‘å®Œå…¨å¯¹é½"""
        soup = BeautifulSoup(html, "html.parser")

        # 1. JSON-LD (ProductGroup)
        data = _load_product_jsonld(soup)
        name = data.get("name") or (soup.title.get_text(strip=True) if soup.title else "No Data")
        desc = data.get("description") or ""
        desc = desc.replace("\\n", "\n")
        desc = desc.replace("<br>", "\n").replace("<br/>", "\n").replace("<br />", "\n")

        # 2. Product Code (ä» description æœ«å°¾æå–)
        product_code = _extract_code_from_description(desc)
        description = _strip_code_from_description(desc, product_code)

        # 3. ä» hasVariant æå–å°ºç /é¢œè‰²/åº“å­˜
        variants = data.get("hasVariant", [])
        if isinstance(variants, dict):
            variants = [variants]
        if not variants:
            raise ValueError("æœªæ‰¾åˆ° hasVariant å˜ä½“æ•°æ®")

        size_detail = {}
        color = "No Data"

        for v in variants:
            v_name = v.get("name") or ""
            # name å½¢å¦‚: Barbour Powell Mens Quilted Jacket - Navy - Navy / L
            tail = v_name.split(" - ")[-1] if " - " in v_name else v_name
            if " / " in tail:
                c_txt, sz_txt = [p.strip() for p in tail.split(" / ", 1)]
            else:
                c_txt, sz_txt = (tail.strip() or "No Data"), "Unknown"
            if color == "No Data":
                color = c_txt or "No Data"

            offers = v.get("offers") or {}
            avail = (offers.get("availability") or "").lower()
            in_stock = "instock" in avail

            size_detail[sz_txt] = {
                "stock_count": DEFAULT_STOCK_COUNT if in_stock else 0,
                "ean": v.get("gtin") or v.get("sku") or "0000000000000",
            }

        # 3.5 æˆªæ–­ç¼–ç è¡¥å…¨: å¦‚ LQU0475 â†’ æŸ¥ DB åŒ¹é…é¢œè‰² â†’ LQU0475OL71
        if _is_partial_code(product_code):
            conn = self._get_db_conn()
            if conn:
                try:
                    full_code, trace = resolve_product_code(
                        conn,
                        site_name=SITE_NAME,
                        url=url,
                        scraped_title=name,
                        scraped_color=color,
                        sku_guess=product_code,
                        partial_code=product_code,
                    )
                    if full_code and full_code != "No Data":
                        self.logger.info(
                            f"ğŸ”— ç¼–ç è¡¥å…¨: {product_code} â†’ {full_code} "
                            f"(by={trace.get('final', {}).get('by', '?')})"
                        )
                        product_code = full_code
                except Exception as e:
                    self.logger.warning(f"ç¼–ç è¡¥å…¨å¤±è´¥ ({product_code}): {e}")

        # 4. æ€§åˆ« (ä¸­æ–‡, ä¸ size_normalizer / format_txt ä¸€è‡´)
        gender = self.infer_gender(
            text=name,
            url=url,
            product_code=product_code,
            output_format="cn",
        )

        # 5. ä»·æ ¼: DOM ä¼˜å…ˆ
        original_price, current_price = _extract_price_pair_from_dom_cho(soup)

        # 6. å°ºç è¡Œ
        ps, psd = self.build_size_lines(size_detail, gender)

        # 7. è¿”å› - å­—æ®µåä¸ format_txt å¯¹é½
        return {
            "Product Code": product_code or "No Data",
            "Product Name": name,
            "Product Description": description or "No Data",
            "Product Gender": gender,
            "Product Color": color or "No Data",
            "Product Price": original_price,
            "Adjusted Price": current_price,
            "Product Material": "No Data",
            "Feature": "No Data",
            "Product Size": ps,
            "Product Size Detail": psd,
        }

    def _validate_info(self, info: Dict[str, Any], url: str) -> None:
        """è¦†ç›–åŸºç±»: ä½¿ç”¨ä¸ v1 ä¸€è‡´çš„å­—æ®µåéªŒè¯"""
        required_fields = [
            "Product Code",
            "Product Name",
            "Product Gender",
            "Product Description",
            "Product Size",
            "Product Size Detail",
        ]
        for field in required_fields:
            if field not in info:
                raise ValueError(f"ç¼ºå¤±å¿…å¡«å­—æ®µ: {field} (URL: {url})")


# ================== ä¸»å…¥å£ ==================

def cho_fetch_info(
    max_workers: int = 4,
    headless: bool = False,
):
    """ä¸»å‡½æ•° - å…¼å®¹æ—§ç‰ˆæ¥å£"""
    setup_logging()

    fetcher = CHOFetcher(
        site_name=SITE_NAME,
        links_file=LINKS_FILE,
        output_dir=OUTPUT_DIR,
        max_workers=max_workers,
        max_retries=3,
        wait_seconds=2.5,
        headless=headless,
    )

    success, fail = fetcher.run_batch()
    print(f"\nâœ… CHO æŠ“å–å®Œæˆ: æˆåŠŸ {success}, å¤±è´¥ {fail}")


if __name__ == "__main__":
    cho_fetch_info(max_workers=4, headless=False)
