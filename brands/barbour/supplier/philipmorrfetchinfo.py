
# -*- coding: utf-8 -*-
"""
Philip Morris Direct | Barbour å•†å“æŠ“å–ï¼ˆæœ€ç»ˆæ•´åˆç‰ˆï¼‰

åŠŸèƒ½ï¼š
1. å¤šçº¿ç¨‹ç¨³å®šæŠ“å–
2. è‡ªåŠ¨é‡å»º driverï¼ˆInvalidSessionId è‡ªåŠ¨ä¿®å¤ï¼‰
3. ä¸» TXT / TXT.problem åˆ†æµ
4. è‡ªåŠ¨è®°å½•æœªçŸ¥é¢œè‰² unknown_colors.csv
5. è‡ªåŠ¨è®°å½•æ‰€æœ‰é—®é¢˜ problem_summary.csv
6. è‡ªåŠ¨æ”¯æŒé¢œè‰²å‰ç¼€å»é™¤ï¼ˆSoft Mint â†’ Mintï¼‰
7. å®Œæ•´ç¼–ç æ‰å†™å…¥ TXTï¼Œä¸å®Œæ•´å†™ TXT.problem
8. æä¾› generate_color_map_suggestions.py ç”Ÿæˆé¢œè‰²å»ºè®®
"""

import re
import time
import threading
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed

from bs4 import BeautifulSoup
import psycopg2

from config import BARBOUR
from common_taobao.ingest.txt_writer import format_txt

# selenium imports
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import (
    InvalidSessionIdException,
    WebDriverException,
)

try:
    from selenium_stealth import stealth
except ImportError:
    def stealth(*args, **kwargs):
        return


#########################################
# é…ç½®ä¸è·¯å¾„
#########################################

LINKS_FILE: Path = BARBOUR["LINKS_FILES"]["philipmorris"]
TXT_DIR: Path = BARBOUR["TXT_DIRS"]["philipmorris"]
SITE_NAME = "Philip Morris"
PGSQL_CONFIG = BARBOUR["PGSQL_CONFIG"]
COLOR_CODE_MAP = BARBOUR["BARBOUR_COLOR_CODE_MAP"]

TXT_DIR.mkdir(parents=True, exist_ok=True)

TXT_PROBLEM_DIR: Path = TXT_DIR.parent / "TXT.problem"
TXT_PROBLEM_DIR.mkdir(parents=True, exist_ok=True)

UNKNOWN_COLOR_FILE = TXT_DIR.parent / "unknown_colors.csv"
PROBLEM_SUMMARY_FILE = TXT_DIR.parent / "problem_summary.csv"

#########################################
# æµè§ˆå™¨ç®¡ç†ï¼šçº¿ç¨‹å±€éƒ¨ driver
#########################################

drivers_lock = threading.Lock()
_all_drivers = set()
thread_local = threading.local()


def create_driver(headless=True):
    """
    åˆ›å»ºä¸€ä¸ªç‹¬ç«‹ Chrome driverï¼ˆPhilip Morris ä¸“ç”¨ï¼‰
    """
    chrome_options = Options()
    if headless:
        chrome_options.add_argument("--headless=new")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--window-size=1920,1080")
    chrome_options.add_argument("user-agent=Mozilla/5.0")
    chrome_options.add_argument("--blink-settings=imagesEnabled=false")

    print("ğŸš— [get_driver] åˆ›å»ºæ–°çš„ Chrome driver (PhilipMorris)")
    driver = webdriver.Chrome(options=chrome_options)

    try:
        stealth(
            driver,
            languages=["en-GB", "en-US", "en"],
            vendor="Google Inc.",
            platform="Win32",
            webgl_vendor="Intel Inc.",
            renderer="Intel Iris OpenGL Engine",
            fix_hairline=True,
        )
    except Exception:
        pass

    with drivers_lock:
        _all_drivers.add(driver)

    return driver


def get_driver(headless=True):
    if not hasattr(thread_local, "driver") or thread_local.driver is None:
        thread_local.driver = create_driver(headless=headless)
    return thread_local.driver


def invalidate_current_driver():
    """
    å½“å‰çº¿ç¨‹ driver å´©äº† â†’ ç§»é™¤ + quit + é‡å»º
    """
    d = getattr(thread_local, "driver", None)
    if d:
        with drivers_lock:
            if d in _all_drivers:
                _all_drivers.remove(d)
        try:
            d.quit()
        except Exception:
            pass
    thread_local.driver = None


def shutdown_all_drivers():
    """
    æ‰€æœ‰çº¿ç¨‹ç»“æŸåç»Ÿä¸€å…³é—­ driver
    """
    with drivers_lock:
        for d in list(_all_drivers):
            try:
                d.quit()
            except:
                pass
        _all_drivers.clear()


#########################################
# å·¥å…·å‡½æ•°
#########################################

def accept_cookies(driver, timeout=5):
    try:
        WebDriverWait(driver, timeout).until(
            EC.element_to_be_clickable((By.CSS_SELECTOR, "button#onetrust-accept-btn-handler"))
        ).click()
        time.sleep(1)
    except:
        pass


def sanitize_filename(name: str) -> str:
    return re.sub(r"[\\/:*?\"<>|'\\s]+", "_", (name or "")).strip("_")


#########################################
# é¢œè‰²å¤„ç†ï¼ˆå«è‡ªåŠ¨è¯†åˆ«å‰ç¼€ï¼‰
#########################################

def record_unknown_color(style: str, color: str, url: str):
    from datetime import datetime
    with open(UNKNOWN_COLOR_FILE, "a", encoding="utf-8") as f:
        f.write(f"{style},{color},{url},{datetime.now().isoformat(timespec='seconds')}\n")


def record_problem_item(style, color, product_code, reason, url):
    from datetime import datetime
    with open(PROBLEM_SUMMARY_FILE, "a", encoding="utf-8") as f:
        f.write(f"{style},{color},{product_code},{reason},{url},{datetime.now().isoformat(timespec='seconds')}\n")


def map_color_to_code(color: str) -> str | None:
    """
    å°è¯• 3 æ­¥ï¼š
    1ï¼‰ç»„åˆè‰²å–ç¬¬ä¸€ä¸ª
    2ï¼‰ç›´æ¥åŒ¹é…é…ç½®
    3ï¼‰å»æ‰ Soft/Ancient/Muted ç­‰å‰ç¼€åå†æ¬¡åŒ¹é…
    """
    if not color:
        return None

    s = color.strip().lower()

    if "/" in s:
        s = s.split("/")[0].strip()

    def try_map(text: str):
        for code, names in COLOR_CODE_MAP.items():
            en = (names.get("en") or "").lower()
            if text == en or text in en or en in text:
                return code
        return None

    code = try_map(s)
    if code:
        return code

    prefixes = ["soft ", "muted ", "ancient ", "classic ", "dark ", "light ", "mid ", "deep "]
    for p in prefixes:
        if s.startswith(p):
            base = s[len(p):].strip()
            code = try_map(base)
            if code:
                return code

    return None


#########################################
# æ¬¾å¼ç¼–ç æå–
#########################################

def extract_style_code(html: str) -> str | None:
    text = html or ""

    mpn = re.search(r"MPN:\s*([A-Z0-9,\s]+)", text)
    if mpn:
        raw = mpn.group(1)
        for token in re.split(r"[,\s]+", raw):
            token = token.strip()
            if re.match(r"^[A-Z]{3}\d{4}[A-Z0-9]{0,6}$", token):
                return token[:7]

    m = re.search(r"\b([A-Z]{3}\d{4}[A-Z]{2}\d{2,4})\b", text)
    if m:
        return m.group(1)[:7]

    m = re.search(r"\b([A-Z]{3}\d{4})\b", text)
    if m:
        return m.group(1)

    return None


#########################################
# ä»·æ ¼ & å°ºç 
#########################################

def _clean_price(t: str) -> str:
    if not t:
        return ""
    m = re.search(r"([0-9]+(?:\.[0-9]{1,2})?)", t.replace(",", ""))
    return m.group(1) if m else ""


def extract_prices(soup):
    sale = ""
    orig = ""

    for span in soup.select("span.price.price--withTax"):
        sale = _clean_price(span.text)
        break

    for span in soup.select("span.price.price--rrp"):
        orig = _clean_price(span.text)
        break

    if not sale:
        meta = soup.find("meta", {"property": "product:price:amount"})
        if meta:
            sale = meta.get("content") or ""

    if not orig:
        orig = sale

    return orig, sale


def extract_sizes(html):
    soup = BeautifulSoup(html, "html.parser")
    labels = soup.select("label.form-option")
    out = []

    for lb in labels:
        classes = lb.get("class", [])
        if "label-img" in classes:
            continue

        span = lb.find("span", class_="form-option-variant")
        if not span:
            continue

        size = span.text.strip()
        stock = "æ— è´§" if "unavailable" in classes else "æœ‰è´§"
        out.append((size, stock))

    return out


def build_size_str(sizes):
    order = []
    agg = {}
    for size, st in sizes:
        if size not in agg:
            agg[size] = st
            order.append(size)
        else:
            if st == "æœ‰è´§":
                agg[size] = "æœ‰è´§"
    return ";".join([f"{s}:{agg[s]}" for s in order])


#########################################
# æ•°æ®åº“åŒ¹é…
#########################################

def find_product_code_in_db(style: str, color: str, conn, url: str):
    if not style or not color or not conn:
        return None

    color_abbr = map_color_to_code(color)
    if not color_abbr:
        print(f"âš ï¸ æœªæ‰¾åˆ°é¢œè‰²ç®€å†™æ˜ å°„ï¼š{style} / {color}")
        record_unknown_color(style, color, url)
        return None

    sql = """
        SELECT product_code FROM barbour_products
        WHERE product_code ILIKE %s
        LIMIT 1
    """

    prefix = f"{style}{color_abbr}"
    with conn.cursor() as cur:
        cur.execute(sql, (prefix + "%",))
        row = cur.fetchone()
        if row:
            return row[0]

    # ç‰¹ä¾‹ï¼šSage SG â†’ GN
    if color.lower() == "sage" and color_abbr == "SG":
        alt = f"{style}GN"
        with conn.cursor() as cur:
            cur.execute(sql, (alt + "%",))
            row = cur.fetchone()
            if row:
                return row[0]

    print(f"âš ï¸ æ•°æ®åº“æœªåŒ¹é…åˆ°ï¼š{style} / {color}")
    return None


#########################################
# ä¸»æµç¨‹ï¼šå¤„ç†å• URL
#########################################

def process_url(url: str, output_dir: Path):
    """
    å¤„ç†å•ä¸ª URLï¼ˆå«è‡ªåŠ¨é‡è¯• 2 æ¬¡ï¼‰
    """

    for attempt in range(2):
        driver = get_driver(headless=True)

        try:
            print(f"\nğŸŒ æŠ“å–({attempt+1}/2): {url}")
            driver.get(url)
            accept_cookies(driver)
            time.sleep(2)

            html = driver.page_source
            soup = BeautifulSoup(html, "html.parser")

            style = extract_style_code(html) or ""
            name = soup.find("h1", class_="productView-title")
            product_name = name.text.strip() if name else "No Data"

            desc = soup.find("div", id="tab-description")
            product_desc = " ".join(desc.stripped_strings) if desc else "No Data"

            base_orig, base_sale = extract_prices(soup)

            color_elems = driver.find_elements(By.CSS_SELECTOR, "label.form-option.label-img")
            variants = []

            if color_elems:
                for idx in range(len(color_elems)):
                    color_elems = driver.find_elements(By.CSS_SELECTOR, "label.form-option.label-img")
                    if idx >= len(color_elems):
                        break

                    elem = color_elems[idx]
                    color = elem.text.strip() or (elem.get_attribute("title") or "No Data")

                    print(f"  ğŸ¨ {idx+1}/{len(color_elems)}: {color}")

                    if color == "No Data":
                        continue

                    driver.execute_script("arguments[0].click();", elem)
                    time.sleep(1.3)

                    html_c = driver.page_source
                    soup_c = BeautifulSoup(html_c, "html.parser")

                    orig, sale = extract_prices(soup_c)
                    if not sale:
                        sale = base_sale
                    if not orig:
                        orig = base_orig or sale

                    sizes = extract_sizes(html_c)
                    size_str = build_size_str(sizes)

                    adjusted = sale if sale != orig else ""

                    variants.append({
                        "_style": style,
                        "Product Name": product_name,
                        "Product Description": product_desc,
                        "Product Color": color,
                        "Product Price": orig or sale or "0",
                        "Adjusted Price": adjusted,
                        "Product Size": size_str,
                        "Site Name": SITE_NAME,
                        "Source URL": url,
                    })

            else:
                print("âš ï¸ æ— é¢œè‰²é€‰é¡¹ â†’ è§†ä¸ºå•è‰²")
                color = "No Data"
                sizes = extract_sizes(html)
                size_str = build_size_str(sizes)
                adjusted = base_sale if base_sale != base_orig else ""

                variants.append({
                    "_style": style,
                    "Product Name": product_name,
                    "Product Description": product_desc,
                    "Product Color": color,
                    "Product Price": base_orig or base_sale or "0",
                    "Adjusted Price": adjusted,
                    "Product Size": size_str,
                    "Site Name": SITE_NAME,
                    "Source URL": url,
                })

            #########################
            # å†™å…¥ TXT æˆ– TXT.problem
            #########################

            if not variants:
                print("âŒ æ— å˜ä½“ â†’ è·³è¿‡")
                return

            # DB connection
            conn = None
            try:
                conn = psycopg2.connect(**PGSQL_CONFIG)
                print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
            except:
                print("âš ï¸ æ•°æ®åº“è¿æ¥å¤±è´¥ â†’ å…¨éƒ¨ç®—é—®é¢˜æ–‡ä»¶")

            for info in variants:
                style = info.pop("_style") or ""
                color = info["Product Color"]

                product_code = None
                reason = ""

                if style and conn:
                    product_code = find_product_code_in_db(style, color, conn, url)

                if product_code:
                    target_dir = TXT_DIR
                    info["Product Code"] = product_code
                else:
                    # é—®é¢˜æ–‡ä»¶
                    target_dir = TXT_PROBLEM_DIR
                    info["Product Code"] = style or "UNKNOWN"
                    reason = "unknown_color" if map_color_to_code(color) is None else "no_db_match"
                    record_problem_item(style, color, info["Product Code"], reason, url)

                fname = sanitize_filename(info["Product Code"]) + ".txt"
                fpath = target_dir / fname
                format_txt(info, fpath, brand="Barbour")

                if target_dir == TXT_DIR:
                    print(f"  âœ… å†™å…¥ TXT: {fname}")
                else:
                    print(f"  âš ï¸ å†™å…¥ TXT.problem: {fname}  ({reason})")

            return  # æœ¬é“¾æ¥æˆåŠŸå®Œæˆ

        except InvalidSessionIdException as e:
            print(f"âš ï¸ driver ä¼šè¯å¤±æ•ˆ â†’ é‡å»º: {e}")
            invalidate_current_driver()
            time.sleep(1)
            continue

        except WebDriverException as e:
            print(f"âŒ WebDriver å¼‚å¸¸ â†’ æ”¾å¼ƒ: {e}")
            return

        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {url}\n    {e}")
            return

    return


#########################################
# æ‰¹é‡å…¥å£
#########################################

def philipmorris_fetch_info(max_workers=3):
    print(f"LINKS_FILE = {LINKS_FILE}")
    print(f"TXT_DIR    = {TXT_DIR}")

    urls = []
    with open(LINKS_FILE, "r", encoding="utf-8") as f:
        for line in f:
            u = line.strip()
            if u:
                urls.append(u)

    print(f"ğŸš€ å¯åŠ¨ Philip Morris æŠ“å–ï¼Œæ€» {len(urls)} æ¡ï¼Œçº¿ç¨‹æ•°={max_workers}")

    try:
        with ThreadPoolExecutor(max_workers=max_workers) as exe:
            futures = [exe.submit(process_url, u, TXT_DIR) for u in urls]
            for _ in as_completed(futures):
                pass
    finally:
        shutdown_all_drivers()
        print("ğŸ§¹ å·²å…³é—­æ‰€æœ‰ driver")


#########################################
# main
#########################################

if __name__ == "__main__":
    philipmorris_fetch_info(max_workers=10)
