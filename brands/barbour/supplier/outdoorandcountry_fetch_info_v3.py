# -*- coding: utf-8 -*-
"""
Outdoor & Country é‡‡é›†å™¨ - é‡æ„ç‰ˆ (ä½¿ç”¨ BaseFetcher)

åŸºäº outdoorandcountry_fetch_info_v2.py é‡æ„
ç‰¹ç‚¹:
- span.price-sales ä»·æ ¼
- button.size-variant å°ºç 
- MPN å­—æ®µè·å–ç¼–ç 
- éœ€è¦ parse_offer_info è¾…åŠ©æ¨¡å—

å¯¹æ¯”:
- æ—§ç‰ˆ (outdoorandcountry_fetch_info_v2.py): 442 è¡Œ
- æ–°ç‰ˆ (æœ¬æ–‡ä»¶): ~150 è¡Œ
- ä»£ç å‡å°‘: 66%

ä½¿ç”¨æ–¹å¼:
    python -m brands.barbour.supplier.outdoorandcountry_fetch_info_v3
"""

from __future__ import annotations

import re
from pathlib import Path
from typing import Dict, Any
from bs4 import BeautifulSoup

# å¯¼å…¥åŸºç±»å’Œå·¥å…·
from brands.barbour.core.base_fetcher import BaseFetcher, setup_logging

# å¯¼å…¥ç«™ç‚¹ç‰¹å®šçš„è§£ææ¨¡å—
from brands.barbour.supplier.outdoorandcountry_parse_offer_info import parse_offer_info

# é…ç½®
from config import BARBOUR, SETTINGS

SITE_NAME = "outdoorandcountry"
LINKS_FILE = BARBOUR["LINKS_FILES"][SITE_NAME]
OUTPUT_DIR = BARBOUR["TXT_DIRS"][SITE_NAME]
DEFAULT_STOCK_COUNT = SETTINGS.get("DEFAULT_STOCK_COUNT", 3)

# Outdoor å¼ºé£æ§ç«™ç‚¹ï¼šæœ‰æ•ˆå¹¶å‘ä¸Šé™ï¼ˆä¸ v2 ä¸€è‡´ï¼‰
EFFECTIVE_MAX_WORKERS = 2


# ================== é‡‡é›†å™¨å®ç° ==================

class OutdoorAndCountryFetcher(BaseFetcher):
    """
    Outdoor & Country é‡‡é›†å™¨

    ç‰¹ç‚¹:
    - ä½¿ç”¨ parse_offer_info è§£æ offers (å°ºç /åº“å­˜/ä»·æ ¼)
    - ä» JSON-LD æå– Product Code
    - MPN å­—æ®µä¼˜å…ˆ
    """

    # å°ºç æ’åºè§„åˆ™
    WOMEN_NUM = ["6", "8", "10", "12", "14", "16", "18", "20"]
    MEN_ALPHA = ["S", "M", "L", "XL", "XXL", "XXXL"]
    MEN_NUM = [str(s) for s in range(32, 52, 2)]

    def parse_detail_page(self, html: str, url: str) -> Dict[str, Any]:
        """
        è§£æ Outdoor & Country å•†å“è¯¦æƒ…é¡µ

        é¡µé¢ç‰¹ç‚¹:
        - parse_offer_info æä¾›åŸºç¡€ä¿¡æ¯
        - JSON-LD çš„ MPN å­—æ®µåŒ…å«ç¼–ç 
        - éœ€è¦ä» URL æå–é¢œè‰²
        """
        soup = BeautifulSoup(html, "html.parser")

        # 1. ä½¿ç”¨ç«™ç‚¹ç‰¹å®šè§£æå™¨è·å–åŸºç¡€ä¿¡æ¯
        info = parse_offer_info(html, url, site_name=SITE_NAME) or {}

        # 2. æå–åç§°
        name = info.get("Product Name", "No Data")

        # 3. æå–é¢œè‰² (ä» URL æˆ–è§£æç»“æœ)
        color = info.get("Product Color") or self._normalize_color_from_url(url)

        # 4. æå–æè¿°
        description = self._extract_description(html)

        # 5. æå–ç‰¹å¾
        features = self._extract_features(html)

        # 6. æå– Product Code (ä» JSON-LD MPN)
        product_code = info.get("Product Color Code") or self._extract_color_code_from_jsonld(html)

        # 7. æ¨æ–­æ€§åˆ«
        gender = self.infer_gender(
            text=name,
            url=url,
            product_code=product_code,
            output_format="zh",  # ä¸­æ–‡è¾“å‡º
        )

        # 8. æ ¼å¼åŒ–å°ºç  (ä» offers)
        offers = info.get("Offers", [])
        product_size_detail = self._build_sizes_from_offers(offers, gender)

        # 9. æå–ä»·æ ¼
        original_price = info.get("original_price_gbp", "No Data")
        discount_price = info.get("discount_price_gbp", "No Data")

        # 10. è¿”å›æ ‡å‡†åŒ–å­—å…¸
        return {
            "Product Code": product_code or "No Data",
            "Product Name": self.clean_text(name, maxlen=200),
            "Product Color": self.clean_text(color, maxlen=100),
            "Product Gender": gender,
            "Product Description": self.clean_description(description),
            "Original Price (GBP)": original_price,
            "Discount Price (GBP)": discount_price,
            "Product Size": "No Data",  # æ—§ç‰ˆæœªä½¿ç”¨æ­¤å­—æ®µ
            "Product Size Detail": product_size_detail,
            "Feature": features,
        }

    def _normalize_color_from_url(self, url: str) -> str:
        """ä» URL å‚æ•°æå–é¢œè‰² (?c=xxx)"""
        try:
            from urllib.parse import urlparse, parse_qs, unquote
            qs = parse_qs(urlparse(url).query)
            c = qs.get("c", [None])[0]
            if not c:
                return ""
            c = unquote(c)
            c = c.replace("\\", "/")
            c = re.sub(r"\s*/\s*", " / ", c)
            c = re.sub(r"\s+", " ", c).strip()
            c = " ".join(w.capitalize() for w in c.split(" "))
            return c
        except Exception:
            return ""

    def _extract_description(self, html: str) -> str:
        """æå–å•†å“æè¿°"""
        soup = BeautifulSoup(html, "html.parser")

        # ä¼˜å…ˆ og:description
        tag = soup.find("meta", attrs={"property": "og:description"})
        if tag and tag.get("content"):
            desc = tag["content"]
            desc = desc.replace("<br>", "").replace("<br/>", "").replace("<br />", "")
            return desc.strip()

        # å…œåº•: product_tabs
        tab = soup.select_one(".product_tabs .tab_content[data-id='0'] div")
        if tab:
            return tab.get_text(" ", strip=True)

        return "No Data"

    def _extract_features(self, html: str) -> str:
        """æå–äº§å“ç‰¹å¾åˆ—è¡¨"""
        soup = BeautifulSoup(html, "html.parser")

        h3 = soup.find("h3", attrs={"title": "Features"})
        if h3:
            ul = h3.find_next("ul")
            if ul:
                items = [li.get_text(" ", strip=True) for li in ul.find_all("li")]
                return "; ".join(items)

        return "No Data"

    def _extract_color_code_from_jsonld(self, html: str) -> str:
        """ä» JSON-LD çš„ MPN å­—æ®µæå– Barbour Product Code"""
        import json
        soup = BeautifulSoup(html, "html.parser")

        for script in soup.find_all("script", type="application/ld+json"):
            try:
                raw = (script.string or "").strip()
                if not raw:
                    continue

                j = json.loads(raw)
                candidates = j if isinstance(j, list) else [j]

                for obj in candidates:
                    if not isinstance(obj, dict) or obj.get("@type") != "Product":
                        continue

                    offers = obj.get("offers")
                    if not offers:
                        continue

                    offers_list = offers if isinstance(offers, list) else [offers]

                    for off in offers_list:
                        mpn = (off or {}).get("mpn")
                        if not isinstance(mpn, str):
                            continue

                        # MPN æ ¼å¼: "MCA0538NY71_34"
                        mpn = mpn.split("_")[0].strip()

                        # æå–å‰ 11 ä½ä½œä¸º Product Code
                        if len(mpn) >= 11:
                            maybe_code = mpn[:11]
                            if re.match(r"^[A-Z]{3}\d{4}[A-Z]{2}\d{2}$", maybe_code):
                                return maybe_code

            except Exception:
                continue

        return ""

    def _build_sizes_from_offers(self, offers, gender: str):
        """ä» offers æ„å»º Product Size Detail"""
        if not offers:
            return "No Data"

        temp = []
        for size, price, stock_text, can_order in offers:
            size = (size or "").strip()
            if not size:
                continue

            # åˆ¤æ–­åº“å­˜
            stock = 0
            if (stock_text or "").strip() in ("æœ‰è´§", "In Stock", "available"):
                stock = DEFAULT_STOCK_COUNT
            if can_order and stock == 0:
                stock = DEFAULT_STOCK_COUNT

            # æ¸…ç†å°ºç 
            cs = self._clean_size(size)
            if not cs:
                continue

            # è¿‡æ»¤è¶…å¤§å°ºç  (>=52)
            m = re.match(r"^(\d{2})$", cs)
            if m and int(m.group(1)) >= 52:
                continue

            temp.append((cs, stock))

        if not temp:
            return "No Data"

        # å»é‡ (ä¿ç•™æœ€å¤§åº“å­˜)
        bucket = {}
        for s, stock in temp:
            bucket[s] = max(bucket.get(s, 0), stock)

        # æ’åº
        ordered = []
        if "å¥³" in (gender or ""):
            # å¥³æ¬¾: æ•°å­—ä¼˜å…ˆ
            for s in self.WOMEN_NUM:
                if s in bucket:
                    ordered.append(s)
            for s in bucket:
                if s not in ordered:
                    ordered.append(s)
        else:
            # ç”·æ¬¾: å­—æ¯ + æ•°å­—
            for s in self.MEN_ALPHA:
                if s in bucket:
                    ordered.append(s)
            for s in self.MEN_NUM:
                if s in bucket:
                    ordered.append(s)
            for s in bucket:
                if s not in ordered:
                    ordered.append(s)

        # æ ¼å¼åŒ–
        out = []
        for s in ordered:
            qty = DEFAULT_STOCK_COUNT if bucket.get(s, 0) > 0 else 0
            out.append(f"{s}:{qty}:0000000000000")

        return ";".join(out) if out else "No Data"

    def _clean_size(self, raw: str) -> str:
        """æ¸…ç†å°ºç """
        from common_taobao.core.size_utils import clean_size_for_barbour

        raw = (raw or "").strip()
        if not raw:
            return ""

        s = clean_size_for_barbour(raw) or raw
        return s.strip()


# ================== ä¸»å…¥å£ ==================

def outdoorandcountry_fetch_info(
    max_workers: int = 2,
    headless: bool = True,
):
    """
    ä¸»å‡½æ•° - å…¼å®¹æ—§ç‰ˆæ¥å£

    Args:
        max_workers: å¹¶å‘çº¿ç¨‹æ•° (å»ºè®® 2, Outdoor å¼ºé£æ§)
        headless: æ˜¯å¦æ— å¤´æ¨¡å¼
    """
    setup_logging()

    effective = min(int(max_workers), EFFECTIVE_MAX_WORKERS)
    print(f"ğŸ”„ Outdoor&Country v3: è¯·æ±‚å¹¶å‘ {max_workers}, æœ‰æ•ˆå¹¶å‘ {effective}", flush=True)

    fetcher = OutdoorAndCountryFetcher(
        site_name=SITE_NAME,
        links_file=LINKS_FILE,
        output_dir=OUTPUT_DIR,
        max_workers=effective,
        max_retries=3,
        wait_seconds=2.0,
        headless=headless,
    )

    success, fail = fetcher.run_batch()
    print(f"\nâœ… Outdoor & Country æŠ“å–å®Œæˆ: æˆåŠŸ {success}, å¤±è´¥ {fail}")


if __name__ == "__main__":
    outdoorandcountry_fetch_info(max_workers=2, headless=True)
