# brands/barbour/supplier/cho_get_links.py
# -*- coding: utf-8 -*-

"""
CHO | Barbour å•†å“é“¾æ¥æŠ“å–è„šæœ¬ (V2 ç¨³å®šç‰ˆ)

ç‰¹æ€§ï¼š
- æ”¯æŒå¤šä¸ªç±»ç›®ï¼š
    https://www.cho.co.uk/collections/barbour
    https://www.cho.co.uk/collections/barbour-international
- ?page=1,2,3... ç¿»é¡µ
- ä»åˆ—è¡¨é¡µæå–æ‰€æœ‰ /products/ å•†å“é“¾æ¥
- é€šè¿‡â€œæ˜¯å¦å‡ºç°æ–°é“¾æ¥â€åˆ¤æ–­æ˜¯å¦å·²ç»åˆ°æœ€åä¸€é¡µ
- è¾“å‡ºåˆ° config.BARBOUR["LINKS_FILES"]["cho"]
"""

import time
from pathlib import Path

from bs4 import BeautifulSoup
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

from config import BARBOUR
from common_taobao.core.selenium_utils import get_driver, quit_driver

# ========= ç±»ç›®é…ç½®ï¼šåœ¨è¿™é‡Œå¢åˆ ç±»ç›®é“¾æ¥ =========
CATEGORY_URLS = [
    "https://www.cho.co.uk/collections/barbour",
    "https://www.cho.co.uk/collections/barbour-international",
]

# è¾“å‡ºè·¯å¾„ï¼šä½¿ç”¨ config ä¸­å®šä¹‰å¥½çš„ cho é“¾æ¥æ–‡ä»¶
OUTPUT_PATH: Path = BARBOUR["LINKS_FILES"]["cho"]
OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)


def get_cho_driver():
    """
    ç»Ÿä¸€ä» common_taobao.selenium_utils è·å– driverï¼Œ
    åå­—ç”¨ 'cho'ï¼Œæ–¹ä¾¿ä¹‹åå…³é—­æˆ–å¤ç”¨ã€‚
    """
    return get_driver(
        name="cho",
        headless=False,          # éœ€è¦æ— å¤´å¯ä»¥æ”¹æˆ True
        window_size="1200,2000",
    )


def extract_links_from_html(html: str) -> set[str]:
    """
    ä» CHO åˆ—è¡¨é¡µ HTML ä¸­æå–å•†å“è¯¦æƒ…é“¾æ¥ã€‚

    è§„åˆ™ï¼š
    - ä»»æ„ <a> æ ‡ç­¾ï¼Œåªè¦ href ä¸­åŒ…å« '/products/' å°±è®¤ä¸ºæ˜¯å•†å“é“¾æ¥
    - è‡ªåŠ¨è¡¥å…¨ç›¸å¯¹è·¯å¾„
    """
    soup = BeautifulSoup(html, "html.parser")
    links: set[str] = set()

    for a in soup.find_all("a", href=True):
        href = (a["href"] or "").strip()
        if "/products/" not in href.lower():
            continue

        if href.startswith("http"):
            full = href
        elif href.startswith("/"):
            full = "https://www.cho.co.uk" + href
        else:
            # æå°‘æ•°æƒ…å†µå‡ºç°ç›¸å¯¹é“¾æ¥
            full = "https://www.cho.co.uk/" + href.lstrip("/")

        links.add(full)

    return links


def build_page_url(base_url: str, page: int) -> str:
    """
    æ ¹æ® base_url æ„é€ åˆ†é¡µ URLï¼š
    - å·²åŒ…å« ? æ—¶ç”¨ &page=
    - å¦åˆ™ç”¨ ?page=
    """
    if "?" in base_url:
        return f"{base_url}&page={page}"
    else:
        return f"{base_url}?page={page}"


def cho_get_links():
    print("ğŸš€ å¼€å§‹æŠ“å– CHO | Barbour å•†å“é“¾æ¥ï¼ˆå¤šç±»ç›®ï¼‰")

    driver = get_cho_driver()
    all_links: set[str] = set()

    try:
        for idx, base_url in enumerate(CATEGORY_URLS, start=1):
            print("\n============================")
            print(f"ğŸ“‚ ç±»ç›® {idx}/{len(CATEGORY_URLS)}: {base_url}")

            page = 1
            while True:
                page_url = build_page_url(base_url, page)
                print(f"ğŸŒ æŠ“å–ç¬¬ {page} é¡µ: {page_url}")
                driver.get(page_url)

                # ç­‰å¾…é¡µé¢å‡ºç°è‡³å°‘ä¸€ä¸ªå•†å“é“¾æ¥ï¼ˆ/products/ï¼‰
                try:
                    WebDriverWait(driver, 10).until(
                        EC.presence_of_element_located(
                            (By.CSS_SELECTOR, "a[href*='/products/']")
                        )
                    )
                except Exception:
                    print(f"âš ï¸ ç¬¬ {page} é¡µåŠ è½½å¤±è´¥æˆ–æ— æœ‰æ•ˆå•†å“é“¾æ¥ï¼Œç»“æŸè¯¥ç±»ç›®")
                    break

                html = driver.page_source
                page_links = extract_links_from_html(html)

                if not page_links:
                    # ç†è®ºä¸Šä¸ä¼šå‡ºç°ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»ç­‰åˆ° a[href*='/products/']
                    print(f"âš ï¸ ç¬¬ {page} é¡µæœªæå–åˆ°ä»»ä½•å•†å“é“¾æ¥ï¼Œç»“æŸè¯¥ç±»ç›®")
                    break

                # ç»Ÿè®¡â€œæ–°å‡ºç°â€çš„é“¾æ¥æ•°é‡
                before_count = len(all_links)
                new_links = [u for u in page_links if u not in all_links]
                all_links.update(new_links)
                after_count = len(all_links)

                print(
                    f"âœ… ç¬¬ {page} é¡µæå– {len(page_links)} ä¸ªé“¾æ¥ï¼Œ"
                    f"å…¶ä¸­æ–°é“¾æ¥ {len(new_links)} ä¸ªï¼Œ"
                    f"ç´¯è®¡æ€»æ•° {after_count}"
                )

                # ğŸ’¡ å…³é”®ç»ˆæ­¢æ¡ä»¶ï¼š
                # å¦‚æœè¿™ä¸€é¡µæ²¡æœ‰äº§ç”Ÿä»»ä½•â€œæ–°é“¾æ¥â€ï¼Œè¯´æ˜å·²ç»è¿›å…¥å¹¿å‘Šå¾ªç¯é¡µ â†’ åœæ­¢ç¿»é¡µ
                if after_count == before_count:
                    print(
                        f"â›” æœ¬é¡µæœªäº§ç”Ÿæ–°çš„å•†å“é“¾æ¥ï¼Œæ¨æ–­å·²ç»åˆ°æœ€åä¸€é¡µï¼Œ"
                        f"ç»“æŸè¯¥ç±»ç›®ç¿»é¡µï¼ˆpage={page}ï¼‰ã€‚"
                    )
                    break

                page += 1
                time.sleep(1)  # å‹å¥½ä¸€ç‚¹ï¼Œåˆ«åˆ·å¤ªçŒ›

    finally:
        # å…³é—­ driver
        quit_driver("cho")

    # å†™å…¥æ–‡ä»¶ï¼ˆå»é‡åçš„æ€»é›†åˆï¼‰
    sorted_links = sorted(all_links)
    OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)
    OUTPUT_PATH.write_text("\n".join(sorted_links), encoding="utf-8")

    print("\nğŸ¯ æŠ“å–å®Œæˆ")
    print(f"ğŸ“¦ å…±æå– {len(sorted_links)} æ¡å•†å“é“¾æ¥ï¼ˆå¤šç±»ç›®å»é‡åæ€»æ•°ï¼‰")
    print(f"ğŸ’¾ å·²ä¿å­˜è‡³ï¼š{OUTPUT_PATH}")


if __name__ == "__main__":
    cho_get_links()
