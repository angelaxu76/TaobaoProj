
import os
import requests
import json
from bs4 import BeautifulSoup
from urllib.parse import urlparse
from config import BARBOUR

headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36"
}

def extract_code_and_name(url: str):
    # ä¾‹å¦‚ï¼šhttps://www.barbour.com/gb/zola-quilted-jacket-LQU1822CR11.html
    filename = os.path.basename(urlparse(url).path)  # zola-quilted-jacket-LQU1822CR11.html
    if filename.endswith(".html"):
        filename = filename[:-5]
    parts = filename.split("-")
    code = parts[-1]
    name = "-".join(parts[:-1])
    return code, name

def extract_image_urls(page_content: str):
    soup = BeautifulSoup(page_content, "html.parser")
    script_tag = soup.find("script", type="application/ld+json")
    if not script_tag:
        return []

    try:
        data = json.loads(script_tag.string.strip())
        images = data.get("image", [])
        if isinstance(images, list):
            return images
    except Exception as e:
        print(f"[è§£æå¤±è´¥] JSON é”™è¯¯: {e}")
    return []

def download_barbour_images():
    links_file = BARBOUR["LINKS_FILE"]
    image_folder = BARBOUR["IMAGE_DOWNLOAD"]
    os.makedirs(image_folder, exist_ok=True)

    with open(links_file, "r", encoding="utf-8") as f:
        urls = [line.strip() for line in f if line.strip()]

    print(f"ğŸ“¦ å…± {len(urls)} ä¸ªå•†å“é“¾æ¥ï¼Œå¼€å§‹ä¾æ¬¡ä¸‹è½½...")

    for idx, url in enumerate(urls, 1):
        try:
            code, name = extract_code_and_name(url)
            resp = requests.get(url, headers=headers, timeout=15)
            resp.raise_for_status()
            image_urls = extract_image_urls(resp.text)

            for i, img_url in enumerate(image_urls, 1):
                img_name = f"{code}-{name}_{i}.jpg"
                save_path = os.path.join(image_folder, img_name)
                img_data = requests.get(img_url, headers=headers, timeout=15).content
                with open(save_path, "wb") as f:
                    f.write(img_data)
                print(f"âœ… [{idx}/{len(urls)}] å·²ä¿å­˜: {img_name}")
        except Exception as e:
            print(f"âŒ [{idx}/{len(urls)}] å¤±è´¥: {url}ï¼Œé”™è¯¯: {e}")

    print("ğŸ¯ æ‰€æœ‰å›¾ç‰‡å¤„ç†å®Œæ¯•ã€‚")

if __name__ == "__main__":
    download_barbour_images()
