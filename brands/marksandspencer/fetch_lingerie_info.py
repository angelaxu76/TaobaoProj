# brands/ms/core/ms_fetch_product_info.py
# -*- coding: utf-8 -*-
"""
M&S å•†å“æŠ“å– â†’ ç”Ÿæˆâ€œé²¸èŠ½æ¨¡å¼â€æ ¼å¼åŒ– TXTï¼ˆCamper å¯¹é½ï¼‰
- æ— éœ€å‘½ä»¤è¡Œå‚æ•°ï¼Œä¾› pipeline ç›´æ¥è°ƒç”¨ï¼šms_fetch_product_info()
- ä»å¤§ JSON(__INITIAL_STATE__/__NEXT_DATA__/__NUXT__)æå–æ¯ä¸ª SKU å°ºç ä¸åº“å­˜
- ç”Ÿæˆ SizeMap / SizeDetailï¼ˆdictï¼‰ï¼Œç”± format_txt æ¸²æŸ“å‡ºï¼š
    Product Size: <å°ºç :æœ‰è´§/æ— è´§;...>
    Product Size Detail: <å°ºç :åº“å­˜:EAN;...>
- å…œåº•ï¼šè‹¥æ²¡æœ‰å¤§ JSONï¼Œåˆ™ä» DOM/æ–‡æœ¬æå–æ•´ç ï¼Œåº“å­˜ç½® 0
"""

import re
import json
import time
import threading
from pathlib import Path
from typing import Dict, List, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed

from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

from config import BRAND_CONFIG
from common_taobao.ingest.txt_writer import format_txt

# ============= å¸¸é‡&å“ç‰Œé…ç½® =============
CFG = BRAND_CONFIG["marksandspencer"]
SAVE_PATH: Path = CFG["TXT_DIR"]
PRODUCT_URLS_FILE: Path = CFG["LINKS_FILE_LINGERIE"]
CHROMEDRIVER_PATH: str = CFG.get("CHROMEDRIVER_PATH", "")
MAX_WORKERS = 6

# æ¯å‹æ’åºï¼ˆç”¨äºè¾“å‡ºæ’åºï¼‰
CUP_ORDER = ["AA", "A", "B", "C", "D", "DD", "E", "F", "G", "H", "J", "K"]

# ============= Driver ç®¡ç†ï¼ˆä¸ camper é£æ ¼ä¸€è‡´ï¼‰ =============
drivers_lock = threading.Lock()
_all_drivers: set = set()
thread_local = threading.local()

def create_driver() -> webdriver.Chrome:
    chrome_options = Options()
    chrome_options.add_argument("--headless=new")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--window-size=1920x1080")
    chrome_options.add_argument("user-agent=Mozilla/5.0")
    chrome_options.add_argument("--log-level=3")
    chrome_options.add_argument("--disable-logging")
    chrome_options.add_argument("--disable-notifications")
    chrome_options.add_argument("--disable-background-networking")
    chrome_options.add_argument("--disable-default-apps")
    chrome_options.add_argument("--disable-sync")
    chrome_options.add_argument("--no-first-run")
    chrome_options.add_argument("--no-default-browser-check")
    chrome_options.add_argument("--disable-features=Translate,MediaRouter,AutofillServerCommunication")
    chrome_options.add_argument("--blink-settings=imagesEnabled=false")

    driver = webdriver.Chrome(options=chrome_options)
    try:
        caps = driver.capabilities
        print("Chrome:", caps.get("browserVersion"))
        print("ChromeDriver:", (caps.get("chrome") or {}).get("chromedriverVersion", ""))
    except Exception:
        pass
    return driver

def get_driver() -> webdriver.Chrome:
    if not hasattr(thread_local, "driver"):
        d = create_driver()
        thread_local.driver = d
        with drivers_lock:
            _all_drivers.add(d)
    return thread_local.driver

def shutdown_all_drivers():
    with drivers_lock:
        for d in list(_all_drivers):
            try:
                d.quit()
            except Exception:
                pass
        _all_drivers.clear()

# ============= å·¥å…·å‡½æ•° =============
def _clean_text(s: str) -> str:
    return re.sub(r"\s+", " ", s or "").strip()

def _to_num_str(price_text: str) -> str:
    if not price_text:
        return ""
    m = re.search(r"(\d+(?:\.\d{1,2})?)", price_text.replace(",", ""))
    return m.group(1) if m else ""

def _parse_json_ld(soup: BeautifulSoup) -> List[dict]:
    out = []
    for tag in soup.find_all("script", {"type": "application/ld+json"}):
        try:
            content = tag.string or tag.get_text() or ""
            if not content.strip():
                continue
            obj = json.loads(content)
            if isinstance(obj, dict):
                out.append(obj)
            elif isinstance(obj, list):
                out.extend([x for x in obj if isinstance(x, dict)])
        except Exception:
            continue
    return out

def _find_product_in_jsonld(jsonld_list: List[dict]) -> dict:
    product = {}
    for obj in reversed(jsonld_list):
        typ = obj.get("@type")
        if typ == "Product" or (isinstance(typ, list) and "Product" in typ):
            product["name"] = obj.get("name") or product.get("name")
            product["code"] = obj.get("sku") or obj.get("mpn") or product.get("code")
            product["color"] = obj.get("color") or product.get("color")
            product["description"] = obj.get("description") or product.get("description")
            offers = obj.get("offers", {})
            if isinstance(offers, list) and offers:
                offers = offers[0]
            if isinstance(offers, dict):
                product["price"] = offers.get("price") or product.get("price")
                ps = offers.get("priceSpecification") or {}
                if isinstance(ps, dict) and ps.get("price"):
                    product["discount_price"] = ps.get("price")
    return product

# ============= ä»å¤§ JSON ä¸­æå– SKU åº“å­˜ =============
def _norm_size_label(primary: str, secondary: str) -> str:
    p = (primary or "").strip().upper()
    s = (secondary or "").strip().upper()
    if not p or not s:
        return ""
    return f"{p}{s}"

def _walk_collect_skus(obj, out: List[Tuple[str, int]]):
    """
    åœ¨ä»»æ„åµŒå¥—çš„ dict/list ä¸­éå†ï¼Œæ•æ‰å½¢å¦‚ï¼š
      size: { primarySize: "34", secondarySize: "D" } + inventory: { quantity: 12 }
    ä»¥åŠ size: { name: "34D" } çš„å˜ä½“ã€‚
    """
    if isinstance(obj, dict):
        size = obj.get("size")
        inv = obj.get("inventory") or obj.get("stock") or {}
        qty = inv.get("quantity")

        if isinstance(size, dict) and (("primarySize" in size and "secondarySize" in size) or "name" in size):
            primary = size.get("primarySize")
            secondary = size.get("secondarySize")
            if (not primary or not secondary) and isinstance(size.get("name"), str):
                m = re.match(r"^\s*(\d{2})([A-Z]{1,3})\s*$", size["name"].upper())
                if m:
                    primary, secondary = m.group(1), m.group(2)
            label = _norm_size_label(primary, secondary)
            if label:
                try:
                    q = int(qty) if qty is not None else 0
                except Exception:
                    q = 0
                out.append((label, q))

        for v in obj.values():
            _walk_collect_skus(v, out)

    elif isinstance(obj, list):
        for x in obj:
            _walk_collect_skus(x, out)

def _extract_sizes_with_quantity_from_state(state_obj) -> Dict[str, int]:
    """ä» window.__INITIAL_STATE__/__NEXT_DATA__/__NUXT__ ç­‰å¯¹è±¡ä¸­æ”¶é›† { '34D': 12, ... }"""
    pairs: List[Tuple[str, int]] = []
    try:
        _walk_collect_skus(state_obj, pairs)
    except Exception:
        pass
    agg: Dict[str, int] = {}
    for label, q in pairs:
        if not label:
            continue
        agg[label] = max(int(q), agg.get(label, 0))
    return agg

from urllib.parse import urlparse, parse_qs, unquote

def _color_from_url(url: str) -> str:
    """
    å½“é¡µé¢/JSON æœªæä¾›é¢œè‰²æ—¶ï¼Œä» URL å…œåº•è§£æ:
      https://.../p/xxxx?color=WHITE      -> WHITE
      https://.../p/xxxx?colour=WHITE_MIX -> WHITE_MIX
    è§£æååšä¸€æ¬¡è§„èŒƒåŒ–ï¼šä¸‹åˆ’çº¿/è¿å­—ç¬¦ -> ç©ºæ ¼ï¼›å¤§å†™è½¬ Title Caseï¼ˆä¿ç•™ 'Mix' ç­‰è¯ï¼‰ã€‚
    """
    if not url:
        return ""
    try:
        q = parse_qs(urlparse(url).query)
        raw = q.get("color", q.get("colour", [""]))[0]
        if not raw:
            return ""
        s = unquote(raw).strip()
        # ç»Ÿä¸€æ¸…ç†ï¼šä¸‹åˆ’çº¿/è¿å­—ç¬¦ -> ç©ºæ ¼
        s = s.replace("_", " ").replace("-", " ")
        # æ ‡å‡†åŒ–å¤§å°å†™ï¼ˆWHITE MIX -> White Mixï¼›ivory -> Ivoryï¼‰
        s = s.upper()
        # ä¿ç•™ç‰¹æ®Šæ¯å‹è¯æ±‡çš„ Title Caseï¼šDD/EE ä¸æ¶‰åŠé¢œè‰²ï¼Œè¿™é‡Œåªå¤„ç†æ™®é€šè¯
        s = " ".join(w.capitalize() for w in s.split())
        return s
    except Exception:
        return ""

# ============= ä¸»è§£æï¼ˆå• URLï¼‰ =============
def process_product_url(url: str):
    try:
        driver = get_driver()
        print(f"\nğŸ” è®¿é—®: {url}")
        driver.get(url)
        WebDriverWait(driver, 12).until(EC.presence_of_element_located((By.CSS_SELECTOR, "body")))
        time.sleep(4)  # ç»™ JS æ¸²æŸ“æ—¶é—´

        soup = BeautifulSoup(driver.page_source, "html.parser")

        # ---------- åŸºç¡€å­—æ®µï¼šJSON-LD + å…œåº• ----------
        title_tag = soup.find("title")
        name_from_title = _clean_text(re.sub(r"\s*[-â€“â€”].*", "", title_tag.text)) if title_tag else ""

        jsonld_list = _parse_json_ld(soup)
        p_jsonld = _find_product_in_jsonld(jsonld_list)

        # åç§°
        product_name = _clean_text(p_jsonld.get("name") or name_from_title or "No Data")

        # ç¼–ç ï¼ˆM&S å¸¸è§ Txx/xxxxï¼‰
        product_code = p_jsonld.get("code") or ""
        if not product_code:
            body_txt = soup.get_text("\n")
            mcode = re.search(r"\bT\d{2}/[A-Z0-9]+", body_txt)
            if mcode:
                product_code = mcode.group(0)
        product_code = product_code or "No Data"

        # é¢œè‰²/æè¿°
        product_color = _clean_text(p_jsonld.get("color") or "")  # å…ˆç”¨ JSON/LD
        if not product_color:  # é¡µé¢ä¸ç»™ â†’ ç”¨ URL å…œåº•
            product_color = _color_from_url(url)
        product_color = product_color or "No Data"



        description = _clean_text(p_jsonld.get("description") or "") or "No Data"





        # ---------- ä»·æ ¼/æŠ˜æ‰£ä»· ----------
        raw_price = _to_num_str(p_jsonld.get("price") or "")
        raw_discount = _to_num_str(p_jsonld.get("discount_price") or "")

        if raw_discount and raw_price and raw_discount != raw_price:
            # æƒ…å†µ1ï¼šåŸä»· + æŠ˜æ‰£ä»·éƒ½æœ‰
            price = raw_price
            discount_price = raw_discount
        elif raw_price and not raw_discount:
            # æƒ…å†µ2ï¼šåªæœ‰ä¸€ä¸ªä»·æ ¼ï¼ˆæ­£å¸¸ä»·ï¼‰
            price = raw_price
            discount_price = ""  # âœ… ç©ºä½†å­˜åœ¨
        elif not raw_price and raw_discount:
            # æƒ…å†µ3ï¼šåªæœ‰æŠ˜æ‰£ä»·
            price = raw_discount
            discount_price = ""
        else:
            price = "No Data"
            discount_price = ""









        # ---------- å°ºç ä¸åº“å­˜ï¼šä¼˜å…ˆè¯»å–å¤§ JSON ----------
        size_qty_map: Dict[str, int] = {}

        # 1) window å…¨å±€å¯¹è±¡
        state_obj = None
        try:
            state_obj = driver.execute_script(
                "return (window.__INITIAL_STATE__ || window.__NEXT_DATA__ || window.__NUXT__ || window.initialState || null)"
            )
        except Exception:
            state_obj = None

        if state_obj:
            size_qty_map = _extract_sizes_with_quantity_from_state(state_obj)

        # 2) è‹¥è¿˜ä¸ºç©ºï¼Œéå† <script> é‡Œçš„ JSON æ–‡æœ¬å†å…œåº•ä¸€æ¬¡
        if not size_qty_map:
            for tag in soup.find_all("script"):
                txt = (tag.string or tag.get_text() or "").strip()
                if not txt or len(txt) < 50:
                    continue
                if not (txt.startswith("{") or txt.startswith("[")) and "primarySize" not in txt and "secondarySize" not in txt:
                    continue
                cleaned = txt.replace("undefined", "null")
                try:
                    obj = json.loads(cleaned)
                except Exception:
                    continue
                sub = _extract_sizes_with_quantity_from_state(obj)
                if sub:
                    for k, v in sub.items():
                        size_qty_map[k] = max(v, size_qty_map.get(k, 0))
                    break

        # 3) ä»ä¸ºç©º â†’ DOM/çº¯æ–‡æœ¬å…œåº•ï¼ˆæ•´ç ï¼Œåº“å­˜=0ï¼‰
        if not size_qty_map:
            rough_sizes = set()
            # select/æŒ‰é’®é‡Œçš„æ•´ç 
            for opt in soup.select('select[name*=size] option'):
                t = _clean_text(opt.get_text()).upper()
                if t and "SELECT" not in t and re.search(r"\b\d{2}[A-Z]{1,3}\b", t):
                    rough_sizes.add(t)
            for el in soup.select('[data-testid*=size], button, a'):
                lbl = (el.get("aria-label") or el.get("data-size") or el.get("data-value") or "").strip().upper()
                if lbl and re.search(r"\b\d{2}[A-Z]{1,3}\b", lbl):
                    rough_sizes.add(lbl)
            if not rough_sizes:
                text_all = soup.get_text(" ").upper()
                for m in re.finditer(r"\b\d{2}[A-Z]{1,3}\b", text_all):
                    rough_sizes.add(m.group(0))
            size_qty_map = {s: 0 for s in rough_sizes}

        # ---------- ç”Ÿæˆ SizeMap / SizeDetailï¼ˆdictï¼‰ ----------
        if size_qty_map:
            def _sort_key(sz: str):
                m = re.match(r"^(\d{2})([A-Z]{1,3})$", sz)
                band = int(m.group(1)) if m else 0
                cup = (m.group(2) if m else "").upper()
                cup_idx = CUP_ORDER.index(cup) if cup in CUP_ORDER else 999
                return (band, cup_idx, cup)

            ordered = sorted(size_qty_map.items(), key=lambda kv: _sort_key(kv[0]))
            size_map = {sz: ("æœ‰è´§" if qty > 0 else "æ— è´§") for sz, qty in ordered}
            # EAN æš‚æ— ï¼šå¯ç”¨ "" æˆ– "0000000000000"
            size_detail = {sz: {"stock_count": int(qty), "ean": "0000000000000"} for sz, qty in ordered}
        else:
            size_map = {}
            size_detail = {}

        # ---------- å…¶å®ƒå­—æ®µ ----------
        gender = "å¥³æ¬¾"  # èƒ¸ç½©é»˜è®¤å¥³æ¬¾
        style_category = "å†…è¡£/æ–‡èƒ¸"

        # ---------- å†™å‡º TXT ----------
        info = {
            "Product Code": product_code,
            "Product Name": product_name,
            "Product Description": description,
            "Product Gender": gender,
            "Product Color": product_color,
            "Product Price": price,
            "Adjusted Price": discount_price if discount_price else 0,
            "Product Material": "No Data",
            "Style Category": style_category,
            "Feature": "No Data",

            # âœ… äº¤ç”± format_txt æ¸²æŸ“æˆä¸¤è¡Œ
            "SizeMap": size_map,
            "SizeDetail": size_detail,

            "Source URL": url
        }

        SAVE_PATH.mkdir(parents=True, exist_ok=True)
        filepath = SAVE_PATH / f"{product_code.replace('/', '_')}.txt"

        try:
            format_txt(info, filepath, brand="marksandspencer")
        except TypeError:
            format_txt(info, filepath)

        print(f"âœ… å®Œæˆ TXT: {filepath.name}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {url} - {e}")

# ============= æ— å‚å…¥å£ï¼ˆä¾› pipeline è°ƒç”¨ï¼‰ =============
def fetch_product_info(max_workers: int = MAX_WORKERS):
    SAVE_PATH.mkdir(parents=True, exist_ok=True)
    urls_path = Path(PRODUCT_URLS_FILE)
    if not urls_path.exists():
        print(f"âš ï¸ æœªæ‰¾åˆ° URL åˆ—è¡¨æ–‡ä»¶ï¼š{urls_path}")
        return

    with urls_path.open("r", encoding="utf-8", errors="ignore") as f:
        urls = [ln.strip() for ln in f if ln.strip() and not ln.strip().startswith("#")]

    try:
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = [executor.submit(process_product_url, u) for u in urls]
            for fut in as_completed(futures):
                fut.result()
    finally:
        shutdown_all_drivers()

# å¯ç‹¬ç«‹è¿è¡Œè°ƒè¯•ï¼ˆç”Ÿäº§ä¸­å»ºè®®ç”± pipeline è°ƒç”¨ï¼‰
if __name__ == "__main__":
    fetch_product_info()
