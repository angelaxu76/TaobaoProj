# -*- coding: utf-8 -*-
"""
MS æœè£…ï¼ˆå¤–å¥—/é’ˆç»‡/ä¸Šè¡£/è¿è¡£è£™ç­‰ï¼‰ç»Ÿä¸€è§£æè„šæœ¬
ä½¿ç”¨ Selenium + __NEXT_DATA__ è§£æå…¨é‡ä¿¡æ¯
ä½¿ç”¨ format_txt å†™å…¥â€œé²¸èŠ½æ ‡å‡†æ ¼å¼â€ TXT
"""

import json
import re
import time
from pathlib import Path

from attr import attrs
from bs4 import BeautifulSoup
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

from config import MARKSANDSPENCER
from common_taobao.core.selenium_utils import get_driver
from common_taobao.ingest.txt_writer import format_txt


CANON_SITE = "Marks & Spencer"


# ===================== å·¥å…·å‡½æ•° =====================
def _apply_size_range_completion(size_map: dict, detail: dict, gender: str | None):
    """
    æ ¹æ®æ€§åˆ«å’Œç°æœ‰å°ºç æ¨¡å¼ï¼Œè¡¥å…¨å°ºç èŒƒå›´å¹¶è‡ªåŠ¨è¡¥ 0 åº“å­˜ï¼š
    - å¥³æ¬¾ï¼š
        * è‹¥å°ºç ä¸å«æ•°å­—ï¼ˆXS/S/M/L/XLï¼‰ â†’ èŒƒå›´: XS-XL
        * è‹¥å°ºç å«æ•°å­—ï¼ˆ6/8/10/12 ç­‰ï¼‰ â†’ èŒƒå›´: 6-24ï¼ˆæ­¥é•¿ 2ï¼‰
    - ç”·æ¬¾ï¼š
        * èŒƒå›´: XS, S, M, L, XL, XXL, 3XL, 4XL
    å…¶å®ƒï¼ˆç«¥æ¬¾/æœªçŸ¥ï¼‰æš‚ä¸å¤„ç†ï¼Œä¿æŒåŸæ ·ã€‚
    """
    if size_map is None:
        return size_map, detail

    if not size_map:
        # æ²¡æœ‰ä»»ä½•å°ºç ï¼šåªæœ‰åœ¨å¥³æ¬¾/ç”·æ¬¾æ‰è€ƒè™‘è¡¥ä¸€æ•´å¥—
        g = gender or ""
        if "å¥³" not in g and "ç”·" not in g:
            return size_map, detail
    else:
        g = gender or ""
        # æœ‰å°ºç ä¹Ÿè¦ç…§æ ·è¡¥èŒƒå›´
        # g å–è‡ªä¸Šå±‚ _infer_genderï¼Œé€šå¸¸ä¸º "å¥³æ¬¾"/"ç”·æ¬¾"/"ç«¥æ¬¾"/"æœªçŸ¥"
    
    g = gender or ""
    g_is_female = "å¥³" in g
    g_is_male = "ç”·" in g

    import re

    base_sizes: list[str] = []

    if g_is_female:
        # åˆ¤æ–­ç°æœ‰å°ºç æ˜¯å¦æ˜¯â€œæ•°å­—ç³»â€
        has_digit = any(re.search(r"\d", s) for s in size_map.keys())

        if has_digit:
            # å¥³æ¬¾æ•°å­—å°ºç ï¼š6 - 24ï¼Œæ­¥é•¿ 2
            base_sizes = [str(x) for x in range(6, 26, 2)]
        else:
            # å¥³æ¬¾å­—æ¯å°ºç ï¼šXS - XL
            base_sizes = ["XS", "S", "M", "L", "XL"]

    elif g_is_male:
        # ç”·æ¬¾ï¼šXS - 4XL
        base_sizes = ["XS", "S", "M", "L", "XL", "XXL", "3XL", "4XL"]

    else:
        # ç«¥æ¬¾ / æœªçŸ¥æ€§åˆ«ï¼šä¸åšè¡¥ç 
        return size_map, detail

    # å¯¹äºèŒƒå›´å†…æ¯ä¸ªå°ºç ï¼Œè‹¥ä¸å­˜åœ¨åˆ™è¡¥ä¸€æ¡â€œæ— è´§ï¼Œåº“å­˜ 0â€
    for sz in base_sizes:
        if sz in size_map:
            continue
        size_map[sz] = "æ— è´§"
        detail[sz] = {
            "stock_count": 0,
            "ean": "0000000000000",
        }

    return size_map, detail


def _normalize_size_label(label: str) -> str:
    """
    æ¸…æ´— M&S æœè£…å°ºç ï¼š
    - Extra Small -> XS, Medium -> M ç­‰
    - å¦‚æœåŒ…å«æ•°å­—ï¼ˆ8, 10, 12, 8-10 ä¹‹ç±»ï¼‰ï¼Œè§†ä¸º UK æ•°å­—å°ºç ï¼ŒåŸæ ·ä¿ç•™
    """
    label = _clean(label)
    if not label:
        return label

    # å«æ•°å­—çš„å°ºç ï¼ˆ8 / 10 / 12 / 8-10 / 5yrs ç­‰ï¼‰ç›´æ¥ä¿ç•™
    import re
    if re.search(r"\d", label):
        return label

    lower = label.lower().strip()
    # å»æ‰å‰ç¼€ "size "
    if lower.startswith("size "):
        lower = lower[5:].strip()

    mapping = {
        "extra small": "XS",
        "x-small": "XS",
        "xs": "XS",

        "small": "S",
        "s": "S",

        "medium": "M",
        "m": "M",

        "large": "L",
        "l": "L",

        "extra large": "XL",
        "x-large": "XL",
        "xl": "XL",

        "extra extra large": "XXL",
        "xx-large": "XXL",
        "xxl": "XXL",

        "extra extra extra large": "3XL",
        "xxx-large": "3XL",
        "3xl": "3XL",
    }

    if lower in mapping:
        return mapping[lower]

    # é»˜è®¤ä¿æŒåŸæ ·ï¼ˆæ¯”å¦‚ ONE SIZE, REGULAR ç­‰ï¼‰
    return label


def _clean(s: str) -> str:
    if not s:
        return ""
    return re.sub(r"\s+", " ", s).strip()


def _load_json_safe(text: str):
    if not text:
        return None
    text = text.replace("undefined", "null")
    try:
        return json.loads(text)
    except Exception:
        return None

def _get_color_from_url(url: str) -> str:
    from urllib.parse import urlparse, parse_qs
    qs = parse_qs(urlparse(url).query)
    if "color" in qs and qs["color"]:
        return qs["color"][0]
    return ""

def _normalize_color_code(color: str) -> str:
    """
    color: CHARTREUSE, FadedBlue, Navy/White ç­‰
    è§„èŒƒåŒ–ä¸ºå¤§å†™ã€æ— ç©ºæ ¼æ— ç¬¦å·ï¼š
    CHARTREUSE â†’ CHARTREUSE
    Faded Blue â†’ FADEDBLUE
    Navy/White â†’ NAVYWHITE
    """
    if not color:
        return ""
    s = re.sub(r"[^A-Za-z0-9]+", "", color)
    return s.upper()



def _extract_product_sheet(soup: BeautifulSoup):
    """
    ä» <script id="__NEXT_DATA__"> ä¸­å–å•†å“æ ¸å¿ƒä¿¡æ¯

    ä¼˜å…ˆä½¿ç”¨æ—§ç»“æ„çš„ pageProps.productSheetï¼›
    è‹¥ä¸å­˜åœ¨ï¼Œåˆ™é€‚é…æ–°ç»“æ„çš„ pageProps.productDetailsï¼Œ
    æ„é€ ä¸€ä¸ªâ€œä»¿ productSheetâ€çš„ dictï¼Œè®©åç»­è§£æé€»è¾‘å¤ç”¨ã€‚
    """
    tag = soup.find("script", {"id": "__NEXT_DATA__", "type": "application/json"})
    if not tag:
        return None

    data = _load_json_safe(tag.string)
    if not isinstance(data, dict):
        return None

    page_props = (data.get("props") or {}).get("pageProps") or {}

    # 1ï¸âƒ£ æ—§ç»“æ„ï¼šç›´æ¥å­˜åœ¨ productSheet
    sheet = page_props.get("productSheet")
    if sheet:
        return sheet

    # 2ï¸âƒ£ æ–°ç»“æ„ï¼šåªæœ‰ productDetailsï¼Œéœ€è¦è‡ªå·±é€‚é…
    pd = page_props.get("productDetails")
    if not isinstance(pd, dict):
        return None

    attrs = pd.get("attributes") or {}
    variants = pd.get("variants") or []
    first_variant = variants[0] if variants else {}
    skus = first_variant.get("skus") or []

    # âœ… å•†å“åç§°ï¼šä¼˜å…ˆç”¨é¡µé¢å±•ç¤ºçš„ masterProductDescription
    marketing_name = attrs.get("masterProductDescription")
    sheet_name = marketing_name or pd.get("name") or ""

    # ---------- prices: æ„é€ æˆæ—§çš„ prices.current / prices.previous ----------
    prices = {}
    if skus:
        sku_price = (skus[0].get("price") or {})
        cur = sku_price.get("currentPrice")
        prev = sku_price.get("previousPrice")
        prices = {
            "current": cur,
            "previous": prev,
        }

    # ---------- features: ç”¨æè¿° + æˆåˆ† + Inline bullets ----------
    features = []

    # å•†å“æ–‡æ¡ˆæè¿°
    desc_html = attrs.get("masterAspirationalText") or attrs.get("furtherDescription") or ""
    if desc_html:
        features.append({"name": "Description", "value": desc_html})

    # æˆåˆ†ä¿¡æ¯
    comp = attrs.get("compositionList")
    if comp:
        features.append({"name": "Composition", "value": comp})

    # Inline bulletsï¼ˆä¾‹å¦‚ Fit and style / Care and compositionï¼‰
    for key in ("inlineReferenceBullet1", "inlineReferenceBullet2", "inlineReferenceBullet3"):
        val = attrs.get(key)
        if val:
            # M&S è¿™é‡Œé€šå¸¸æ˜¯ "Fit and style#Regular fit;Button fastening" è¿™ç§å½¢å¼
            features.append({"name": key, "value": val})

    # ---------- sizes: é€‚é…æˆåŸå…ˆ sheet['sizes'] çš„ç»“æ„ ----------
    sizes = []
    for sku in skus:
        size_obj = sku.get("size") or {}
        size_label = (
            size_obj.get("primarySize")
            or size_obj.get("secondarySize")
            or ""
        )
        if not size_label:
            continue

        inv = sku.get("inventory") or {}
        qty = inv.get("quantity") or 0

        # M&S è¿™é‡Œæš‚æ—¶æ²¡æœ‰ EANï¼Œå°±ç”¨å ä½ç¬¦ï¼Œåé¢ _extract_sizes ä¼šç…§å¸¸ä½¿ç”¨
        ean = "0000000000000"

        sizes.append({
            "value": str(size_label),
            "stock": qty,
            "ean": ean,
        })

    # ---------- color: é€‚é…æˆåŸå…ˆ sheet['color'] çš„ç»“æ„ ----------
    colour_name = first_variant.get("colour") if isinstance(first_variant, dict) else None
    color = {"name": colour_name} if colour_name else None

    # ---------- æ‹¼æˆâ€œä»¿ productSheetâ€çš„ dict ----------
    sheet_new = {
        "name": sheet_name,
        "code": attrs.get("strokeId") or pd.get("productExternalId") or pd.get("id"),
        "description": desc_html or "",
        "features": features,
        "prices": prices,
        "sizes": sizes,
        "color": color,
    }

    return sheet_new



# ===================== ä»·æ ¼è§£æ =====================

def _parse_price(sheet: dict):
    """
    è¿”å›ï¼šProduct Priceï¼ˆåŸä»·ï¼‰ å’Œ Adjusted Priceï¼ˆæŠ˜åä»·ï¼‰
    """
    prices = sheet.get("prices") or {}
    cur = prices.get("current")
    prev = prices.get("previous")

    # è½¬ float
    def _to_float(x):
        try:
            return float(x)
        except:
            return None

    cur_f = _to_float(cur)
    prev_f = _to_float(prev)

    # previous > current â†’ æœ‰æŠ˜æ‰£
    if prev_f and cur_f and prev_f > cur_f:
        return prev_f, cur_f

    # æ— æŠ˜æ‰£ï¼Œåªæœ‰ current
    if cur_f:
        return cur_f, 0

    return "No Data", 0


# ===================== æè´¨ä¸ Feature =====================

def _extract_features(sheet: dict):
    """
    è¿”å›ï¼šfeatures_textã€material
    """
    features = sheet.get("features") or []
    feat_list = []
    material = "No Data"

    for f in features:
        name = f.get("name") or ""
        val_html = f.get("value") or ""
        txt = _clean(BeautifulSoup(val_html, "html.parser").get_text(" ", strip=True))
        if txt:
            feat_list.append(txt)

        # æ‰¾æè´¨å…³é”®è¯
        low = name.lower()
        if material == "No Data" and any(k in low for k in
            ["fabric", "material", "composition", "shell", "outer", "lining"]):
            material = txt

    features_text = " | ".join(feat_list) if feat_list else "No Data"

    # è‹¥æ²¡æ‰¾åˆ°æè´¨ï¼Œå°è¯•ä» features_text æŠ“ 65% polyester ç±»ä¼¼å­—æ®µ
    if material == "No Data":
        m = re.search(r"\d+%[^|]+", features_text)
        if m:
            material = m.group(0).strip()

    return features_text, material


# ===================== å°ºç è§£æ =====================

def _extract_sizes(sheet: dict, gender: str | None = None):
    """
    è¿”å› SizeMap, SizeDetailï¼ˆdictï¼‰
    äº¤ç»™ common_taobao.txt_writer.format_txt å»æ¸²æŸ“ï¼š
      Product Size:        "XS:æœ‰è´§;S:æ— è´§;..."
      Product Size Detail: "XS:3:EAN;S:0:EAN;..."
    """
    sizes = sheet.get("sizes") or []
    size_map: dict[str, str] = {}
    detail: dict[str, dict] = {}

    for s in sizes:
        raw_label = s.get("value") or s.get("name")
        size_label = _normalize_size_label(raw_label)
        if not size_label:
            continue

        # quantity / stock / availableï¼šå­—æ®µåå…¼å®¹
        qty_raw = s.get("quantity", s.get("stock"))
        try:
            qty = int(qty_raw) if qty_raw is not None else 0
        except Exception:
            qty = 0

        available = s.get("available")
        if available is None:
            available = qty > 0
        else:
            available = bool(available)

        stock_flag = "æœ‰è´§" if available and qty > 0 else "æ— è´§"
        stock_count = qty if stock_flag == "æœ‰è´§" else 0

        ean = (s.get("ean") or "").strip() or "0000000000000"

        if size_label in size_map:
            # åŒä¸€å°ºç å¤šæ¡è®°å½•ï¼šåˆå¹¶åº“å­˜ / çŠ¶æ€ / EAN
            prev_flag = size_map[size_label]
            prev_detail = detail[size_label]

            prev_detail["stock_count"] += stock_count

            if prev_flag == "æœ‰è´§" or stock_flag == "æœ‰è´§":
                size_map[size_label] = "æœ‰è´§"

            if prev_detail.get("ean") in ("", "0000000000000") and ean not in ("", "0000000000000"):
                prev_detail["ean"] = ean
        else:
            size_map[size_label] = stock_flag
            detail[size_label] = {
                "stock_count": stock_count,
                "ean": ean,
            }

    # âš ï¸ åœ¨è¿™é‡Œè¿›è¡Œâ€œè¡¥ç è¡¥ 0â€é€»è¾‘
    size_map, detail = _apply_size_range_completion(size_map, detail, gender)

    return size_map, detail




# ===================== é¢œè‰²ï¼Œæ€§åˆ«ï¼Œç±»ç›® =====================

def _extract_color(sheet: dict, url: str):
    color_data = sheet.get("color")
    if isinstance(color_data, dict):
        c = color_data.get("name")
        if c:
            return _clean(c)

    m = re.search(r"[?&]color=([^&#]+)", url, re.I)
    if m:
        return _clean(m.group(1))

    return "No Data"


def _infer_gender(name: str, sheet: dict, url: str):
    l = name.lower()
    if "men" in l or "/men/" in url:
        return "ç”·æ¬¾"
    if any(k in l for k in ["girl", "boys", "kids"]) or "/kids/" in url:
        return "ç«¥æ¬¾"
    return "å¥³æ¬¾"


def _infer_category(name: str):
    l = name.lower()
    if any(k in l for k in ["coat", "jacket", "parka", "blazer", "gilet"]):
        return "ä¸Šè¡£/å¤–å¥—"
    if any(k in l for k in ["cardigan", "jumper", "knit", "sweater"]):
        return "ä¸Šè¡£/é’ˆç»‡"
    if "dress" in l:
        return "è¿è¡£è£™"
    return "ä¸Šè¡£/å…¶ä»–"


# ===================== å•é¡µé¢è§£æ =====================

def extract_page(url: str) -> dict:
    """ä½¿ç”¨ Selenium åŠ è½½é¡µé¢å¹¶è§£æ"""
    driver = get_driver("marksandspencer", headless=True)
    driver.get(url)

    try:
        WebDriverWait(driver, 12).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "body"))
        )
    except:
        time.sleep(5)

    html = driver.page_source
    soup = BeautifulSoup(html, "html.parser")

    title_tag = soup.find("title")
    title = _clean(title_tag.text) if title_tag else "No Data"

    # --- è§£ææ ¸å¿ƒ JSON ---
    sheet = _extract_product_sheet(soup)
    if not sheet:
        raise Exception("æ²¡æœ‰æ‰¾åˆ° productSheet")

    name = _clean(sheet.get("name") or title)



    base_code = sheet.get("code") or "NoCode"

    # ä» URL æå–é¢œè‰²
    url_color = _get_color_from_url(url)
    color_suffix = _normalize_color_code(url_color)

    # å¦‚æœ URL ç»™äº†é¢œè‰²ï¼Œå°±æŠŠé¢œè‰²åŠ å…¥ç¼–ç 
    if color_suffix:
        code = f"{base_code}_{color_suffix}"
    else:
        # å•è‰²å•†å“ï¼šä¿æŒåŸå§‹æ¬¾å¼ç¼–ç 
        code = base_code








    desc = _clean(sheet.get("description") or "")

    # ä»·æ ¼
    price, discount = _parse_price(sheet)

    # ç‰¹å¾ / æè´¨
    feature, material = _extract_features(sheet)

    # é¢œè‰²
    color = _extract_color(sheet, url)

    # æ€§åˆ« / ç±»ç›®ï¼ˆå¿…é¡»æ”¾åœ¨å°ºç è§£æä¹‹å‰ï¼‰
    gender = _infer_gender(name, sheet, url)
    category = _infer_category(name)

    # å°ºç ï¼ˆè¿”å› SizeMap/SizeDetailï¼Œç¬¦åˆé²¸èŠ½æ ¼å¼ï¼‰
    size_map, size_detail = _extract_sizes(sheet, gender)

    # ç›´æ¥äº¤ç»™ txt_writer ç”Ÿæˆé²¸èŠ½æ ¼å¼ Product Size / Product Size Detail
    info = {
        "Product Code": code,
        "Product Name": name,
        "Product Description": desc or "No Data",
        "Product Gender": gender,
        "Product Color": color,
        "Product Price": price,
        "Adjusted Price": discount,
        "Product Material": material,
        "Style Category": category,
        "Feature": feature,

        # â¬‡â¬‡â¬‡ æ–°å­—æ®µï¼Œé²¸èŠ½æ¨¡å¼å¿…é¡»æœ‰
        "SizeMap": size_map,
        "SizeDetail": size_detail,

        "Site Name": CANON_SITE,
        "Source URL": url,
    }
    return info



# ===================== Pipeline ä¸»å…¥å£ =====================

def ms_fetch_jackcet_info():
    """M&S å…¨å“ç±»ï¼ˆæœè£…ï¼‰æŠ“å–å…¥å£"""
    links_file: Path = MARKSANDSPENCER["LINKS_FILE_JACKET"]
    txt_dir: Path = MARKSANDSPENCER["TXT_DIR"]
    txt_dir.mkdir(parents=True, exist_ok=True)

    if not links_file.exists():
        print(f"âŒ æœªæ‰¾åˆ°é“¾æ¥æ–‡ä»¶: {links_file}")
        return

    urls = [
        ln.strip()
        for ln in links_file.read_text(encoding="utf-8").splitlines()
        if ln.strip()
    ]

    print(f"ğŸ“„ å…± {len(urls)} ä¸ª M&S å•†å“å¾…æŠ“å–")

    for idx, url in enumerate(urls, 1):
        print(f"\nâ€”â€” [{idx}/{len(urls)}] â€”â€”")
        try:
            info = extract_page(url)

            fname = info["Product Code"].replace("/", "_")
            txt_path = txt_dir / f"{fname}.txt"

            format_txt(info, txt_path, brand="marksandspencer")

            print(f"âœ… æˆåŠŸå†™å…¥ TXT: {txt_path.name}")

        except Exception as e:
            print(f"âŒ è§£æå¤±è´¥: {url}\n   é”™è¯¯: {e}")


if __name__ == "__main__":
    ms_fetch_jackcet_info()
