# -*- coding: utf-8 -*-
"""
ECCO UK (Next.js) å…¨æ–°æŠ“å– â†’ Clarks Jingya æ ¼å¼
- è¾“å…¥: product_links.txtï¼ˆæ¯è¡Œä¸€ä¸ª URLï¼›ä¹Ÿæ”¯æŒæœ¬åœ° .html ä¾¿äºè°ƒè¯•ï¼‰
- è¾“å‡º: /TXT/{product_code}.txt  å’Œ  å¯é€‰ /debug_pages/*.html
- å­—æ®µ: Code / Name / Description / Gender / Color / Price / Adjusted Price / Material / Size / Feature / Source URL
"""
import time
import hashlib
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from html import unescape
from config import ECCO, SIZE_RANGE_CONFIG
import requests
from bs4 import BeautifulSoup
import json

# ===== ä½ æœ¬åœ°å·²æœ‰çš„å†™å…¥å™¨ï¼šä¿æŒä¸ç°æœ‰å·¥ç¨‹å…¼å®¹ =====
from common_taobao.ingest.txt_writer import format_txt  # format_txt(info, filepath, brand="clarks_jingya")

# ===== è·¯å¾„é…ç½®ï¼ˆæŒ‰éœ€æ”¹ï¼‰=====
LINKS_FILE = ECCO["LINKS_FILE"]
TXT_DIR    = ECCO["TXT_DIR"]
DEBUG_DIR  = ECCO["BASE"] / "publication" / "debug_pages"


# æ˜¯å¦ä¿å­˜ HTML è°ƒè¯•é¡µ
DEBUG_SAVE_HTML = True

# requests
REQUEST_TIMEOUT = 20
HDRS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                  "AppleWebKit/537.36 (KHTML, like Gecko) "
                  "Chrome/123.0.0.0 Safari/537.36",
    "Accept-Language": "en-GB,en;q=0.9"
}

# å¯é€‰ï¼šSelenium å›é€€ï¼ˆåŠ¨æ€åº“å­˜/å˜ä½“æ›´ç¨³ï¼‰
ENABLE_SELENIUM = True
CHROMEDRIVER_PATH = r"D:/Software/chromedriver-win64/chromedriver.exe"

# çº¿ç¨‹
MAX_WORKERS = 1

# ============ å°å·¥å…· ============


import re
import demjson3  # ç¡®ä¿å·²å®‰è£…: pip install demjson3


def supplement_ecco_sizes(size_map: dict, size_detail: dict, gender: str):
    """
    æ ¹æ®æ€§åˆ«ï¼Œç”¨ SIZE_RANGE_CONFIG['ecco'] è¡¥é½ç¼ºå¤±å°ºç ï¼š
    - ç”·æ¬¾: 39â€“46
    - å¥³æ¬¾: 35â€“42
    - ç«¥æ¬¾: 27â€“40
    TXT ä¸­æœªå‡ºç°çš„ EU ç ç»Ÿç»Ÿè¡¥æˆæ— è´§:
        SizeMap[eu] = "æ— è´§"
        SizeDetail[eu] = {"stock_count": 0, "ean": "0000000000000"}
    """
    brand_cfg = SIZE_RANGE_CONFIG.get("ecco", {})
    key = None
    # ECCO é‡Œ gender æ˜¯è‹±æ–‡: "men" / "women" / "kids" / "unisex"
    if gender == "men":
        key = "ç”·æ¬¾"
    elif gender == "women":
        key = "å¥³æ¬¾"
    elif gender == "kids":
        key = "ç«¥æ¬¾"
    else:
        # "unisex" æˆ–æœªçŸ¥ï¼Œä¸è¡¥ç ï¼Œé¿å…è¯¯åˆ¤
        return size_map, size_detail

    standard_sizes = brand_cfg.get(key, [])
    if not standard_sizes:
        return size_map, size_detail

    for eu in standard_sizes:
        if eu not in size_detail:
            size_map[eu] = "æ— è´§"
            size_detail[eu] = {"stock_count": 0, "ean": "0000000000000"}

    return size_map, size_detail


def parse_ecco_sizes_and_stock(html: str):
    """
    ä» ECCO é¡µé¢è„šæœ¬ä¸­è§£æå°ºç +åº“å­˜ã€‚
    - å…ˆè§£æ variants[*].availability.channels.results é‡Œ key=="GB-web" çš„ availableQuantity
    - å†ç”¨ relatedProduct.variants[*] å›å¡«ç¼ºå¤±çš„ EU/UK/qty
    - å…¼å®¹ \\" è½¬ä¹‰ å’Œ æœªè½¬ä¹‰ ä¸¤ç§å½¢æ€
    è¿”å›: [{sku,size_eu,size_uk,available_qty,has_stock}, ...]ï¼ˆå»é‡ã€æŒ‰ EU å‡åºï¼‰
    """

    def _unescape(s: str) -> str:
        # å±€éƒ¨åè½¬ä¹‰ï¼Œä¾¿äº demjson3 è§£æ
        return s.replace('\\"', '"').replace('\\\\', '\\')

    rows = []

    # ---- A) variants ä¸»æ¸ é“ï¼ˆæœ‰ GB-web æ•°é‡ï¼‰----
    m_variants_plain = re.search(r'"variants"\s*:\s*(\[[\s\S]*?\])', html)
    m_variants_esc   = re.search(r'\\"variants\\":\s*(\[[\s\S]*?\])', html)
    block_variants = None
    if m_variants_plain:
        block_variants = m_variants_plain.group(1)
    elif m_variants_esc:
        block_variants = _unescape(m_variants_esc.group(1))

    if block_variants:
        try:
            variants = demjson3.decode(_unescape(block_variants))
            for v in variants if isinstance(variants, list) else []:
                sku = str(v.get("sku") or "")
                size_eu = size_uk = None
                for a in v.get("attributesRaw", []) or []:
                    if a.get("name") == "Size":    size_eu = a.get("value")
                    if a.get("name") == "Size_UK": size_uk = a.get("value")
                qty, on = 0, False
                for c in (v.get("availability", {}) or {}).get("channels", {}).get("results", []) or []:
                    if (c.get("channel", {}) or {}).get("key") == "GB-web":
                        av = c.get("availability", {}) or {}
                        try:
                            qty = int(av.get("availableQuantity") or 0)
                        except Exception:
                            qty = 0
                        on = bool(av.get("isOnStock"))
                        break
                if size_eu:
                    rows.append({
                        "sku": sku,
                        "size_eu": str(size_eu),
                        "size_uk": str(size_uk) if size_uk is not None else "",
                        "available_qty": qty,
                        "has_stock": on
                    })
        except Exception:
            pass  # ä¸å½±å“åç»­å›å¡«

    # ---- B) relatedProduct.variants å…œåº•å›å¡« ----
    m_rel_plain = re.search(r'"relatedProduct"\s*:\s*\{\s*"variants"\s*:\s*(\[[\s\S]*?\])', html)
    m_rel_esc   = re.search(r'\\"relatedProduct\\":\s*\{\s*\\"variants\\":\s*(\[[\s\S]*?\])', html)
    block_rel = None
    if m_rel_plain:
        block_rel = m_rel_plain.group(1)
    elif m_rel_esc:
        block_rel = _unescape(m_rel_esc.group(1))

    if block_rel:
        try:
            rel = demjson3.decode(_unescape(block_rel))
            # ç”¨ (sku, eu) å»ºç´¢å¼•ä¾¿äºåˆå¹¶
            by_key = {(r["sku"], r["size_eu"]): r for r in rows if r.get("sku") and r.get("size_eu")}
            for v in rel if isinstance(rel, list) else []:
                sku = str(v.get("sku") or "")
                eu  = str(v.get("size") or v.get("eu") or v.get("label") or "")

                if not sku or not eu:
                    continue

                uk  = str(v.get("sizeUK") or v.get("uk") or "")
                try:
                    qty = int(v.get("availableQuantity") or 0)
                except Exception:
                    qty = 0
                has = v.get("hasStock")
                key = (sku, eu)

                if key in by_key:
                    r = by_key[key]
                    if not r.get("size_uk") and uk: r["size_uk"] = uk
                    # åªæœ‰åœ¨ A ä¸­æ²¡æ‹¿åˆ° qty æ—¶æ‰ç”¨å›å¡«
                    if (r.get("available_qty") is None) or (r.get("available_qty") == 0):
                        r["available_qty"] = qty
                        r["has_stock"] = bool(has) if has is not None else (qty > 0)
                else:
                    rows.append({
                        "sku": sku,
                        "size_eu": eu,
                        "size_uk": uk,
                        "available_qty": qty,
                        "has_stock": bool(has) if has is not None else (qty > 0)
                    })
        except Exception:
            pass

    # ---- C) æ¸…æ´— & æ’åº ----
    cleaned, seen = [], set()
    for r in rows:
        eu, sku = r.get("size_eu"), r.get("sku")
        if not eu or not sku:
            continue
        key = (sku, eu)
        if key in seen:
            continue
        seen.add(key)
        cleaned.append(r)

    def _eu_key(s: str):
        try:
            return int(str(s).split("-")[0])
        except Exception:
            return 999

    cleaned.sort(key=lambda x: _eu_key(x.get("size_eu", "")))
    return cleaned


def extract_price_info(html):
    """
    è¿”å› (Price, AdjustedPrice)
    1) å…ˆèµ°æ—§çš„ onProductPageInit()
    2) å›é€€ JSON-LD offers.priceï¼ˆAdjustedPrice æ— åˆ™ä¸º 0ï¼‰
    """
    # æ—§é€»è¾‘
    try:
        m = re.search(r'productdetailctrl\.onProductPageInit\((\{.*?\})\)', html, re.DOTALL)
        if m:
            data = json.loads(m.group(1).replace("&quot;", '"'))
            return float(data.get("Price", 0.0) or 0.0), float(data.get("AdjustedPrice", 0.0) or 0.0)
    except Exception:
        pass

    # JSON-LD å›é€€
    try:
        for s in re.findall(r'<script[^>]+type="application/ld\+json"[^>]*>(.*?)</script>', html, re.DOTALL):
            j = json.loads(s.strip())
            if isinstance(j, dict) and j.get("@type") == "Product" and "offers" in j:
                offers = j["offers"]
                if isinstance(offers, dict) and "price" in offers:
                    price = float(str(offers.get("price", "0")).replace(",", "") or 0)
                    return price, 0.0
    except Exception:
        pass
    return 0.0, 0.0


def build_size_fields(rows):
    """
    rows -> 
      Product Size: "39,40,41,..."
      Product Size Detail: "39|uk:6|stock:64|sku:0194....;..."
    - å»é‡ã€æ’åºï¼›ç¼ºå¤±å­—æ®µç”¨å ä½ï¼ˆuk:"", stock:0, sku:""ï¼‰
    """
    eu_seen = set()
    eu_list, detail = [], []

    for r in rows:
        eu = str(r.get("size_eu") or "").strip()
        if not eu or eu in eu_seen:
            continue
        eu_seen.add(eu)
        eu_list.append(eu)

        uk  = str(r.get("size_uk") or "").strip()
        sku = str(r.get("sku") or "").strip()
        # åº“å­˜å¼ºåˆ¶ intï¼Œé¿å… "92" è¢«å½“æˆéæ•°å­—
        try:
            qty = int(r.get("available_qty") or 0)
        except Exception:
            qty = 0

        detail.append(f"{eu}|uk:{uk}|stock:{qty}|sku:{sku}")

    # æ’åº & åŒæ­¥æ’åº detail
    def _eu_key(s: str):
        try:
            return int(s.split("-")[0])
        except Exception:
            return 999

    eu_list.sort(key=_eu_key)
    order = {eu: i for i, eu in enumerate(eu_list)}
    detail.sort(key=lambda seg: order.get(seg.split("|", 1)[0], 999))

    return ",".join(eu_list), ";".join(detail)



def ensure_dirs(*paths: Path):
    for p in paths:
        p.mkdir(parents=True, exist_ok=True)

def is_url(s: str) -> bool:
    return str(s).startswith("http://") or str(s).startswith("https://")

def clean(s: str) -> str:
    return re.sub(r"\s+", " ", (s or "")).strip()

def get_meta(soup, name=None, prop=None):
    if name:
        m = soup.find("meta", attrs={"name": name})
        if m and m.get("content"):
            return clean(m["content"])
    if prop:
        m = soup.find("meta", attrs={"property": prop})
        if m and m.get("content"):
            return clean(m["content"])
    return ""

MATERIAL_WORDS = [
    "Leather", "Nubuck", "Suede", "Textile", "Mesh", "Canvas",
    "Rubber", "GORE-TEX", "Gore-Tex", "GORETEX", "Synthetic", "PU", "TPU", "EVA", "Wool", "Neoprene"
]

def guess_code_from_url(url: str) -> str:
    m = re.search(r"/(\d{6})/(\d{5})(?:[/?#]|$)", url or "")
    if m:
        return f"{m.group(1)}{m.group(2)}"
    m2 = re.search(r"/product/(\d{10,12})(?:[/?#]|$)", url or "")
    if m2:
        return m2.group(1)
    return hashlib.md5((url or "").encode("utf-8")).hexdigest()[:10]

def save_debug_html(url: str, html: str, tag: str = "loaded"):
    if not DEBUG_SAVE_HTML:
        return
    ensure_dirs(DEBUG_DIR)
    code_hint = guess_code_from_url(url)
    ts = time.strftime("%Y%m%d-%H%M%S")
    name = f"{ts}_{tag}_{code_hint}.html"
    (DEBUG_DIR / name).write_text(html or "", encoding="utf-8", errors="ignore")

def fetch_html(url_or_file: str) -> str:
    if not is_url(url_or_file):
        return Path(url_or_file).read_text(encoding="utf-8", errors="ignore")
    r = requests.get(url_or_file, headers=HDRS, timeout=REQUEST_TIMEOUT)
    r.raise_for_status()
    return r.text

# ============ å¯é€‰ï¼šSelenium ============
_selenium_driver = None
def get_driver():
    global _selenium_driver
    if _selenium_driver is not None:
        return _selenium_driver
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.chrome.service import Service
    opts = Options()
    opts.add_argument("--headless=new")
    opts.add_argument("--disable-gpu")
    opts.add_argument("--no-sandbox")
    opts.add_argument("--disable-dev-shm-usage")
    opts.add_argument("--window-size=1920,1080")
    _selenium_driver = webdriver.Chrome(service=Service(CHROMEDRIVER_PATH), options=opts)
    return _selenium_driver

def fetch_html_selenium(url: str) -> str:
    d = get_driver()
    d.get(url)
    # è½»ç­‰å¾…ï¼šæ–°ç«™é¦–å±ç›´å‡º + å°‘é‡åŠ¨æ€
    time.sleep(1.2)
    return d.page_source

# ============ è§£æï¼šç¼–ç  / åç§° / æè¿° / é¢œè‰² / æ€§åˆ« / æè´¨ ============
def extract_code(soup, url="") -> str:
    # A. JSON-LDï¼ˆæ–°ç‰ˆæœ€ç¨³ï¼‰
    for s in soup.find_all("script", {"type": "application/ld+json"}):
        try:
            data = json.loads(s.string or "{}")
            items = data if isinstance(data, list) else [data]
            for item in items:
                for k in ("sku", "mpn", "productID", "productId"):
                    v = str(item.get(k, "")).strip()
                    if v:
                        m = re.search(r"(\d{6})\D*(\d{5})", v)
                        if m:
                            return f"{m.group(1)}{m.group(2)}"
                        m2 = re.search(r"\b(\d{10,12})\b", v)
                        if m2:
                            return m2.group(1)
        except Exception:
            pass
    # B. å¯è§â€œProduct number:â€è€æ¨¡æ¿
    node = soup.find("div", class_="product_info__product-number")
    if node:
        t = clean(node.get_text(" ", strip=True))
        m = re.search(r"(\d{6})\D+(\d{5})", t)
        if m:
            return f"{m.group(1)}{m.group(2)}"
        m2 = re.search(r"\b(\d{10,12})\b", t)
        if m2:
            return m2.group(1)
    # C. URL å…œåº•
    href = get_meta(soup, prop="og:url") or get_meta(soup, name="twitter:url")
    if not href:
        href = url or ""
    m = re.search(r"/(\d{6})/(\d{5})(?:[/?#]|$)", href)
    if m:
        return f"{m.group(1)}{m.group(2)}"
    m2 = re.search(r"/product/(\d{10,12})(?:[/?#]|$)", href)
    if m2:
        return m2.group(1)
    # D. æ•´é¡µå…œåº•
    text = soup.get_text(" ", strip=True)
    m3 = re.search(r"\b(\d{6})\D{0,3}(\d{5})\b", text)
    if m3:
        return f"{m3.group(1)}{m3.group(2)}"
    m4 = re.search(r"\b(\d{10,12})\b", text)
    if m4:
        return m4.group(1)
    raise RuntimeError("Product Code not found")

def extract_names(soup):
    # æ–°æ¨¡æ¿ï¼šåŒæ ‡é¢˜
    h1 = soup.select_one('[data-testid="product-card-titleandprice"] h1')
    marketing = ""
    model = ""
    if h1:
        p = h1.find("p")
        marketing = clean(p.get_text(" ", strip=True)) if p else ""
        tails = [t for t in (h1.find_all(string=True, recursive=False) or [])]
        model = clean(tails[0]) if tails and clean(tails[0]) else ""
    # og:title å…œåº•ï¼ˆå¸¸è§å½¢å¦‚ "... | Black"ï¼‰
    og_title = get_meta(soup, prop="og:title")
    if not (marketing or model) and og_title:
        # å»å“ç‰Œ ECCO æ–‡æ¡ˆç²˜è¿ï¼Œä¿ç•™ Men's/Women's
        left = og_title.split(" | ", 1)[0]
        left = re.sub(r"\bECCO\b|\bECCOÂ®\b", "", left, flags=re.I)
        left = clean(left)
        marketing = left
    merged = " | ".join([x for x in [marketing, model] if x]) or (og_title or "")
    return marketing, model, merged

def extract_description(soup):
    # JSON-LD description æœ€å¹²å‡€
    for s in soup.find_all("script", {"type": "application/ld+json"}):
        try:
            data = json.loads(s.string or "{}")
            items = data if isinstance(data, list) else [data]
            for item in items:
                desc = item.get("description", "")
                if desc:
                    text = re.sub(r"<[^>]+>", " ", desc)
                    return clean(unescape(text))
        except Exception:
            pass
    # meta æè¿°å…œåº•
    desc = get_meta(soup, name="description")
    if desc:
        text = re.sub(r"<[^>]+>", " ", desc)
        return clean(unescape(text))
    # å¯è§å®¹å™¨å…œåº•
    node = soup.select_one("div.product-description")
    return clean(node.get_text(" ", strip=True)) if node else ""

def extract_color(soup):
    node = soup.select_one("span.product_info__color--selected")
    if node:
        return clean(node.get_text(" ", strip=True))
    og_title = get_meta(soup, prop="og:title")
    if " | " in og_title:
        return clean(og_title.split(" | ", 1)[1])
    return "No Data"

def parse_gender(*texts):
    t = " ".join([x or "" for x in texts]).lower()
    if "women" in t or "womenâ€™s" in t or "women's" in t or "ladies" in t:
        return "women"
    if "men" in t or "menâ€™s" in t or "men's" in t:
        return "men"
    if "kid" in t or "junior" in t or "youth" in t:
        return "kids"
    return ""

def parse_materials(*texts):
    joined = " | ".join([x or "" for x in texts])
    hits = []
    for w in MATERIAL_WORDS:
        if re.search(rf"(?<!\w){re.escape(w)}(?!\w)", joined, re.I):
            hits.append(w if w.isupper() else w.title())
    # å»é‡ä¿åº
    seen, out = set(), []
    for x in hits:
        xl = x.lower()
        if xl in seen: 
            continue
        seen.add(xl); out.append(x)
    return ", ".join(out) if out else "No Data"

# ============ ä»·æ ¼ / åº“å­˜ ============
def extract_prices(html, soup):
    """
    è¿”å› (Price, AdjustedPrice)

    çº¦å®šï¼š
      - Price         = åŸä»·ï¼ˆRRPï¼‰ï¼Œå¦‚æœèƒ½æ‹¿åˆ°ï¼›
      - AdjustedPrice = æŠ˜åä»·ï¼ˆæ‰“æŠ˜ä»·ï¼‰ï¼Œå¦‚æœæœ‰æ‰“æŠ˜ï¼Œå¦åˆ™ä¸º 0ã€‚
    """

    def _parse_money(text: str) -> float:
        if not text:
            return 0.0
        m = re.search(r'(\d+(?:\.\d+)?)', text.replace(",", ""))
        return float(m.group(1)) if m else 0.0

    # 1) æ—§é€»è¾‘ï¼šè€ç«™çš„ onProductPageInit
    try:
        m = re.search(r'productdetailctrl\.onProductPageInit\((\{.*?\})\)', html, re.DOTALL)
        if m:
            js = m.group(1).replace("&quot;", '"')
            data = json.loads(js)
            p = float(data.get("Price", 0) or 0)
            ap = float(data.get("AdjustedPrice", 0) or 0)
            return p, ap
    except Exception:
        pass

    # 2) JSON-LD ä¸­çš„å½“å‰ä»·æ ¼ï¼ˆä¸€èˆ¬æ˜¯æŠ˜åä»·ï¼‰
    current_price = 0.0
    try:
        for s in soup.find_all("script", {"type": "application/ld+json"}):
            data = json.loads(s.string or "{}")
            items = data if isinstance(data, list) else [data]
            for item in items:
                offers = item.get("offers")
                if isinstance(offers, dict) and "price" in offers:
                    current_price = float(str(offers.get("price", "0")).replace(",", "") or 0)
                    break
            if current_price:
                break
    except Exception:
        pass

    # 3) DOM é‡Œçš„åŸä»·ï¼š<p data-testid="RecommendedPrice">Â£170.00</p>
    orig_price = 0.0
    try:
        p_orig = soup.find("p", attrs={"data-testid": "RecommendedPrice"})
        if p_orig:
            orig_price = _parse_money(p_orig.get_text(" ", strip=True))
    except Exception:
        pass

    # 3.1 ä¼˜å…ˆç”¨ã€ŒåŸä»· + æŠ˜åä»·ã€ç»„åˆ
    if orig_price > 0 and current_price > 0 and orig_price > current_price:
        return orig_price, current_price

    # 3.2 åªæœ‰ä¸€ä¸ªä»·æ ¼ï¼šå½“æˆåŸä»·
    if current_price > 0:
        return current_price, 0.0

    # 4) å…œåº•ï¼šåªä» DOM æ‹¿æŠ˜åä»·ï¼ˆæå°‘æ•°æ²¡æœ‰ JSON-LD çš„é¡µé¢ï¼‰
    try:
        p_disc = soup.select_one("p.product-price")
        disc_val = _parse_money(p_disc.get_text(" ", strip=True)) if p_disc else 0.0
        if orig_price > 0 and disc_val > 0 and orig_price > disc_val:
            return orig_price, disc_val
        if disc_val > 0:
            return disc_val, 0.0
    except Exception:
        pass

    # 5) å…¨éƒ¨å¤±è´¥
    return 0.0, 0.0



def build_size_fields_jingya(rows):
    """
    å°† parse_ecco_sizes_and_stock(rows) çš„ç»“æœï¼Œè½¬æˆé²¸èŠ½éœ€è¦çš„ä¸¤åˆ—ï¼š
      - Product Size:  EU:æœ‰è´§/æ— è´§;...
      - Product Size Detail: EU:3/0:EAN;...    (3=æœ‰è´§, 0=æ— è´§)
    è§„åˆ™ï¼š
      - åªçœ‹åœ¨çº¿åº“å­˜ï¼šqty>0 æˆ– has_stock=True è§†ä¸ºæœ‰è´§ -> çŠ¶æ€ç =3ï¼›å¦åˆ™=0
      - EAN/sku ä¸æ˜¯ 13 ä½æ—¶ï¼Œç”¨ '0000000000000' å ä½
      - EU å°ºç æŒ‰æ•°å€¼å‡åºï¼›åŒºé—´å¦‚ '3538' å¯é€‰è½¬æˆ '35-38'ï¼ˆé»˜è®¤ä¸æ”¹ï¼‰
    """
    def eu_key(s):
        try:
            return int(str(s).split("-")[0])
        except Exception:
            return 999

    # æ’åºå»é‡
    seen = set()
    sorted_rows = sorted(rows, key=lambda r: eu_key(r.get("size_eu", "")))

    size_parts = []
    detail_parts = []
    for r in sorted_rows:
        eu = str(r.get("size_eu") or "").strip()
        if not eu or eu in seen:
            continue
        seen.add(eu)

        qty = r.get("available_qty")
        has = r.get("has_stock")
        in_stock = (has is True) or (isinstance(qty, (int, float)) and qty > 0) or (isinstance(qty, str) and qty.isdigit() and int(qty) > 0)
        status_word = "æœ‰è´§" if in_stock else "æ— è´§"
        status_code = 3 if in_stock else 0

        sku = str(r.get("sku") or "").strip()
        ean = sku if len(sku) == 13 and sku.isdigit() else "0000000000000"

        size_parts.append(f"{eu}:{status_word}")
        detail_parts.append(f"{eu}:{status_code}:{ean}")

    return ";".join(size_parts), ";".join(detail_parts)

def build_size_maps_jingya(rows):
    """
    rows -> (size_map, size_detail)
    - size_map:   {EU: "æœ‰è´§"/"æ— è´§", ...}
    - size_detail:{EU: {"stock_count": 3/0, "ean": "13ä½"}, ...}  # 3=æœ‰è´§,0=æ— è´§
    EAN ç”¨ skuï¼Œé13ä½æ•°å­—åˆ™ç»™ "0000000000000"
    """
    def in_stock(r):
        q = r.get("available_qty")
        has = r.get("has_stock")
        if has is True:
            return True
        try:
            return int(q) > 0
        except Exception:
            return False

    size_map = {}
    size_detail = {}

    # æ’åºåå»é‡
    def eu_key(s):
        try:
            return int(str(s).split("-")[0])
        except Exception:
            return 999

    seen = set()
    for r in sorted(rows, key=lambda x: eu_key(x.get("size_eu", ""))):
        eu = str(r.get("size_eu") or "").strip()
        if not eu or eu in seen:
            continue
        seen.add(eu)

        ok = in_stock(r)
        status_word = "æœ‰è´§" if ok else "æ— è´§"
        status_code = 3 if ok else 0

        sku = str(r.get("sku") or "").strip()
        ean = sku if (len(sku) == 13 and sku.isdigit()) else "0000000000000"

        size_map[eu] = status_word
        size_detail[eu] = {"stock_count": status_code, "ean": ean}

    return size_map, size_detail

def extract_sizes(html, soup):
    """
    è¿”å› ["41:æœ‰è´§","42:æ— è´§", ...]
    - DOM: div.size-picker__rows button
    - è„šæœ¬ JSON å…œåº•: æŸ¥æ‰¾åŒ…å« size / stock çš„ç»“æ„
    """
    results = []

    # DOM
    size_div = soup.find("div", class_="size-picker__rows")
    if size_div:
        for btn in size_div.find_all("button"):
            label = clean(btn.get_text(" ", strip=True))
            if not label:
                continue
            # ECCO UK çš„å°ºç æŒ‰é’®å¤šæ•°ç›´æ¥æ˜¾ç¤º EU ç ï¼›è‹¥æ˜¾ç¤º UKï¼Œå¯åœ¨æ­¤åŠ æ˜ å°„
            eu_m = re.search(r"\b(\d{2})\b", label)
            eu_size = eu_m.group(1) if eu_m else label
            classes = " ".join(btn.get("class", []))
            soldout = ("soldout" in classes.lower()) or ("disabled" in classes.lower()) or ("unavailable" in classes.lower())
            status = "æ— è´§" if soldout else "æœ‰è´§"
            results.append(f"{eu_size}:{status}")
        if results:
            return results

    # è„šæœ¬ JSON å…œåº•ï¼ˆå°½é‡è¯†åˆ«ï¼‰
    for s in soup.find_all("script"):
        txt = s.string or ""
        if not txt:
            continue
        if ("size" in txt.lower() or "variant" in txt.lower()) and ("stock" in txt.lower() or "availability" in txt.lower()):
            # æå– "EUxx" + availability
            # å¸¸è§å­—æ®µï¼šsize, eu, available, inStock
            pairs = re.findall(r'("?(?:eu|size|label)"?\s*:\s*"?(\d{2})"?).*?("?(?:inStock|available|availability)"?\s*:\s*(?:true|false|"?(?:InStock|OutOfStock)"?))', txt, flags=re.I|re.S)
            added = set()
            for p in pairs:
                eu = p[1]
                avail_part = p[2].lower()
                soldout = ("false" in avail_part) or ("outofstock" in avail_part)
                status = "æ— è´§" if soldout else "æœ‰è´§"
                key = f"{eu}:{status}"
                if key not in added:
                    results.append(key)
                    added.add(key)
            if results:
                return results

    return results  # å¯èƒ½ä¸ºç©ºï¼ˆé…ä»¶ç±»æ— å°ºç ï¼‰

# ============ ä¸»æµç¨‹ ============
def process_one(url: str, idx: int, total: int):
    try:
        print(f"ğŸ” ({idx}/{total}) {url}")
        # 1) æŠ“ HTMLï¼šrequests ä¼˜å…ˆ
        html = fetch_html(url)
        if DEBUG_SAVE_HTML:
            save_debug_html(url, html, "loaded_req")
        soup = BeautifulSoup(html, "html.parser")

        # 2) æå°‘æ•°é¡µå›é€€ Seleniumï¼ˆè‹¥è¿ JSON-LD / og:title éƒ½æ²¡æœ‰ï¼‰
        need_fallback = False
        if not soup.find("script", {"type": "application/ld+json"}) and not get_meta(soup, prop="og:title"):
            need_fallback = True
        if ENABLE_SELENIUM and need_fallback and is_url(url):
            html = fetch_html_selenium(url)
            if DEBUG_SAVE_HTML:
                save_debug_html(url, html, "loaded_sel")
            soup = BeautifulSoup(html, "html.parser")

        # ===== ç¼–ç  / åç§° / æè¿° / é¢œè‰² =====
        product_code = extract_code(soup, url=url)
        marketing, model, merged_name = extract_names(soup)
        product_name = merged_name if merged_name else "No Data"
        description = extract_description(soup)
        color_name = extract_color(soup)

        # ===== æ€§åˆ« / æè´¨ï¼ˆæ ¹æ®æ–‡æœ¬ & å°ºç ï¼‰=====
        gender_from_title = parse_gender(marketing, model, product_name)
        material_from_text = parse_materials(marketing, model, product_name, description)

        # ===== æ–°å¢ï¼šå°ºç  + åº“å­˜ï¼ˆä¼˜å…ˆ GB-web æ•°é‡ï¼›å¤±è´¥å† DOM å…œåº•ï¼‰=====
        rows = parse_ecco_sizes_and_stock(html)  # â† ä½ å·²å®šä¹‰çš„å‡½æ•°
        
        size_map, size_detail = build_size_maps_jingya(rows)
        if not size_map:
            only_flags = extract_sizes(html, soup)  # ["41:æœ‰è´§","42:æ— è´§",...]
            for token in only_flags:
                if ":" not in token:
                    continue
                eu, flag = token.split(":", 1)
                eu = eu.strip()
                has = ("æ— è´§" not in flag)
                size_map[eu] = "æœ‰è´§" if has else "æ— è´§"
                size_detail[eu] = {"stock_count": 3 if has else 0, "ean": "0000000000000"}

# ç”¨å°ºç è¾…åŠ©åˆ¤æ–­æ€§åˆ«ï¼ˆä» SizeMap çš„å°ºç é”®æ¨æ–­ï¼‰
        eu_sizes_arr     = [k for k in size_map.keys() if k.isdigit()]
        gender_by_size = ""
        if any(int(x) < 35 for x in eu_sizes_arr):
            gender_by_size = "kids"
        elif any(x in ("45", "46") for x in eu_sizes_arr):
            gender_by_size = "men"
        elif any(x in ("35", "36") for x in eu_sizes_arr):
            gender_by_size = "women"




        gender_by_size = ""
        if any(x.isdigit() and int(x) < 35 for x in eu_sizes_arr):
            gender_by_size = "kids"
        elif any(x in ("45", "46") for x in eu_sizes_arr):
            gender_by_size = "men"
        elif any(x in ("35", "36") for x in eu_sizes_arr):
            gender_by_size = "women"

        gender = gender_from_title or gender_by_size or "unisex"
        material = material_from_text or "No Data"

        # âœ… åœ¨è¿™é‡ŒæŒ‰ ECCO æ ‡å‡†å°ºç è¡¥ç 
        size_map, size_detail = supplement_ecco_sizes(size_map, size_detail, gender)

        # ===== ä»·æ ¼ =====
        price, adjusted = extract_prices(html, soup)

        # ===== è¦ç‚¹ï¼ˆFeaturesï¼‰=====
        feature = ""
        li_texts = []
        for li in soup.select("div.about-this-product__container div.product-description-list ul li"):
            t = clean(li.get_text(" ", strip=True))
            if t:
                li_texts.append(t)
        if li_texts:
            feature = " | ".join(li_texts)

        # ===== å†™æ–‡ä»¶ï¼ˆæ–°å¢ Product Size Detailï¼‰=====
        ensure_dirs(TXT_DIR)
        out_path = TXT_DIR / f"{product_code}.txt"
        info = {
            "Product Code": product_code,
            "Product Name": product_name,
            "Product Description": description,
            "Product Gender": gender,
            "Product Color": color_name,
            "Product Price": price,
            "Adjusted Price": adjusted,
            "Product Material": material,
            "SizeMap": size_map,
            "SizeDetail": size_detail,
            "Feature": feature,
            "Source URL": url
        }
        format_txt(info, out_path, brand="clarks_jingya")
        print(f"âœ… å†™å…¥: {out_path.name}")

    except Exception as e:
        print(f"âŒ å¤±è´¥: {url} -> {e}")
        try:
            err_html = html if 'html' in locals() else ""
        except Exception:
            err_html = ""
        if DEBUG_SAVE_HTML and err_html:
            save_debug_html(url, err_html, "error")
        try:
            ensure_dirs(TXT_DIR)
            code_hint = guess_code_from_url(url)
            out_path = TXT_DIR / f"{code_hint}.txt"
            info = {
                "Product Code": code_hint,
                "Product Name": "No Data",
                "Product Description": "",
                "Product Gender": "unisex",
                "Product Color": "No Data",
                "Product Price": 0.0,
                "Adjusted Price": 0.0,
                "Product Material": "No Data",
                "SizeMap": {},        # â† å¿…é¡»æ˜¯ dict
                "SizeDetail": {},     # â† å¿…é¡»æ˜¯ dict
                "Feature": "",
                "Source URL": url
            }
            format_txt(info, out_path, brand="clarks_jingya")
            print(f"âš ï¸ å·²å†™å ä½: {out_path.name}")
        except Exception:
            pass


def ecco_fetch_info(links_file=None, max_workers: int = MAX_WORKERS):
    """
    ECCO å•†å“æŠ“å–å…¥å£ã€‚

    :param links_file: å¯é€‰ï¼Œè‡ªå®šä¹‰ product_links.txt è·¯å¾„ã€‚
                       ä¸º None æ—¶ï¼Œä½¿ç”¨ config ä¸­çš„é»˜è®¤ LINKS_FILEã€‚
    :param max_workers: çº¿ç¨‹æ•°ï¼Œä¸ä¼ åˆ™ä½¿ç”¨é»˜è®¤ MAX_WORKERSã€‚
    """
    # 1) è§£æ links æ–‡ä»¶è·¯å¾„
    if links_file is None:
        links_path = LINKS_FILE            # config é‡Œçš„ Path
    else:
        links_path = Path(links_file)      # å…è®¸ä¼  str/path

    ensure_dirs(TXT_DIR, DEBUG_DIR)

    if not links_path.exists():
        raise FileNotFoundError(f"é“¾æ¥æ–‡ä»¶ä¸å­˜åœ¨: {links_path}")

    # 2) è¯»å– URL åˆ—è¡¨
    urls = [u.strip() for u in links_path.read_text(encoding="utf-8").splitlines() if u.strip()]
    total = len(urls)
    print(f"ğŸ“¦ å…± {total} æ¡ï¼Œçº¿ç¨‹ {max_workers}ï¼ŒSelenium å›é€€: {ENABLE_SELENIUM}")
    if total == 0:
        print("âš ï¸ é“¾æ¥æ–‡ä»¶ä¸ºç©ºï¼Œç›´æ¥é€€å‡ºã€‚")
        return

    # 3) å¤šçº¿ç¨‹æŠ“å–
    with ThreadPoolExecutor(max_workers=max_workers) as ex:
        futures = [ex.submit(process_one, url, i + 1, total) for i, url in enumerate(urls)]
        for _ in as_completed(futures):
            pass

    # 4) å…³é—­ selenium
    if ENABLE_SELENIUM:
        try:
            d = get_driver()
            d.quit()
        except Exception:
            pass

    print("âœ… å®Œæˆ")


if __name__ == "__main__":
    ecco_fetch_info()

