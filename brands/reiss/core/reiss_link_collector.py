# -*- coding: utf-8 -*-
"""
REISS å•†å“é“¾æ¥æŠ“å–ï¼ˆå¥å£®ç‰ˆï¼Œå¼‚å¸¸ä¹Ÿä¼šä¿å­˜ç»“æœï¼‰
- é¦–é¡µæ—  pï¼›ç¬¬äºŒé¡µèµ· ?p=1,2,3...
- å¤šç±»ç›®å…¥å£ï¼›pipeline å¯è°ƒç”¨
- æ¯é¡µå¢é‡å†™å…¥ï¼›å¼‚å¸¸/é€€å‡ºæ—¶æœ€ç»ˆå†™å…¥
"""

from __future__ import annotations
import time
import random
import re
from typing import Iterable, List, Set
from pathlib import Path
import os, time, datetime, errno

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

from webdriver_manager.chrome import ChromeDriverManager

# ==== å¯ä» config è¯»å–ï¼Œæ²¡é…ä¹Ÿèƒ½è·‘ ====
try:
    from config import REISS
    DEFAULT_OUTPUT = Path(REISS["LINKS_FILE"])
    DEFAULT_CATEGORIES = REISS.get("CATEGORY_BASE_URLS", [])
except Exception:
    DEFAULT_OUTPUT = Path(r"D:/TB/Products/REISS/publication/product_links.txt")
    DEFAULT_CATEGORIES = []

# ==== å‚æ•° ====
WAIT_FIRST = 12       # é¦–é¡µç­‰å¾…
WAIT_EACH = 6         # ç¿»é¡µç­‰å¾…
MAX_EMPTY_PAGES = 2   # è¿ç»­ç©ºé¡µé˜ˆå€¼ï¼ˆæˆ–æ— æ–°å¢ï¼‰
HEADLESS_DEFAULT = True

def _new_driver(headless: bool = HEADLESS_DEFAULT) -> webdriver.Chrome:
    options = webdriver.ChromeOptions()
    if headless:
        options.add_argument("--headless=new")
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--window-size=1920,1080")
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option("useAutomationExtension", False)
    # å¦‚æœä½ æƒ³å½»åº•æ¶ˆé™¤ WebGL/ANGLE çš„æŠ¥é”™ï¼Œå¯æŒ‰éœ€æ‰“å¼€ä¸‹é¢ä¸¤è¡Œï¼ˆç‰ºç‰²éƒ¨åˆ†å®‰å…¨/æ¸²æŸ“èƒ½åŠ›ï¼‰
    # options.add_argument("--enable-unsafe-swiftshader")
    # options.add_argument("--use-angle=swiftshader")

    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    driver.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
        "source": "Object.defineProperty(navigator,'webdriver',{get:()=>undefined});"
    })
    return driver

def _build_page_url(base_url: str, page: int) -> str:
    if page <= 1:
        return base_url
    sep = '&' if '?' in base_url else '?'
    return f"{base_url}{sep}p={page-1}"

def _wait_list_loaded(driver: webdriver.Chrome, first: bool = False) -> None:
    timeout = WAIT_FIRST if first else WAIT_EACH
    wait = WebDriverWait(driver, timeout)
    try:
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "a.MuiCardMedia-root")))
    except Exception:
        wait.until(EC.presence_of_element_located(
            (By.CSS_SELECTOR, 'a[href^="/style/"], a[href^="https://www.reiss.com/style/"]')
        ))

def _extract_links(driver: webdriver.Chrome) -> Set[str]:
    links: Set[str] = set()
    for a in driver.find_elements(By.CSS_SELECTOR, "a.MuiCardMedia-root"):
        href = (a.get_attribute("href") or "").strip()
        if href.startswith("https://www.reiss.com/style/"):
            links.add(href.split("#")[0].rstrip("/"))
    for a in driver.find_elements(By.CSS_SELECTOR, 'a[href^="/style/"], a[href^="https://www.reiss.com/style/"]'):
        href = (a.get_attribute("href") or "").strip()
        if "/style/" in href:
            if href.startswith("/"):
                href = "https://www.reiss.com" + href
            links.add(href.split("#")[0].rstrip("/"))
    return links


# æ›¿æ¢åŸæ¥çš„ _atomic_write ä¸ºè¿™ä¸ªâ€œWindows å®‰å…¨â€çš„ç‰ˆæœ¬


def _safe_write(out_path: Path, lines: List[str], max_retries: int = 6, backoff: float = 0.4) -> None:
    """
    Windows å‹å¥½çš„å®‰å…¨å†™å…¥ï¼š
    1) å†™åˆ°å”¯ä¸€ä¸´æ—¶æ–‡ä»¶
    2) å¤šæ¬¡é‡è¯• os.replace() è¦†ç›–ç›®æ ‡
    3) è‹¥ä»ç„¶ PermissionError(WinError 5)ï¼Œå†™åˆ° fallback æ–‡ä»¶ï¼Œä¿è¯è¿™æ¬¡æŠ“åˆ°çš„æ•°æ®å¯ç”¨
    """
    out_path.parent.mkdir(parents=True, exist_ok=True)

    # 1) å†™å”¯ä¸€ä¸´æ—¶æ–‡ä»¶
    tmp = out_path.with_suffix(out_path.suffix + f".tmp.{os.getpid()}.{int(time.time()*1000)}")
    with tmp.open("w", encoding="utf-8", newline="\n") as f:
        for line in lines:
            f.write(line + "\n")

    # 2) å¤šæ¬¡é‡è¯• replace
    for attempt in range(1, max_retries + 1):
        try:
            os.replace(tmp, out_path)  # åŸå­æ›¿æ¢
            return
        except PermissionError as e:
            # å¸¸è§ï¼šç›®æ ‡æ–‡ä»¶è¢«ç¼–è¾‘å™¨/æ€æ¯’å ç”¨ï¼›ç¨ç­‰é‡è¯•
            if attempt == max_retries:
                break
            time.sleep(backoff * attempt)
        except OSError as e:
            # å…¶å®ƒå¶å‘é”™è¯¯ä¹Ÿé‡è¯•å‡ æ¬¡
            if attempt == max_retries:
                break
            time.sleep(backoff * attempt)

    # 3) ä»å¤±è´¥ï¼šè½ç›˜åˆ° fallbackï¼Œç¡®ä¿æœ‰ç»“æœ
    ts = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
    fb = out_path.with_name(f"{out_path.stem}.fallback-{ts}.txt")
    try:
        with fb.open("w", encoding="utf-8", newline="\n") as f:
            for line in lines:
                f.write(line + "\n")
        print(f"âš ï¸ æ— æ³•è¦†ç›– {out_path.name}ï¼ˆå¯èƒ½è¢«å ç”¨ï¼‰ï¼Œå·²å†™å…¥å¤‡ä»½æ–‡ä»¶ï¼š{fb}")
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        try:
            if tmp.exists():
                tmp.unlink(missing_ok=True)
        except Exception:
            pass


def _slug(url: str) -> str:
    return re.sub(r'[^a-z0-9]+', '-', url.lower()).strip('-')[:80]

def _maybe_restart_and_retry(driver, headless, page_url, first_wait) -> tuple[webdriver.Chrome, set]:
    """é‡å¯æµè§ˆå™¨å¹¶é‡è¯•å½“å‰é¡µä¸€æ¬¡ï¼›è¿”å›(æ–°driver, links)ã€‚å¤±è´¥åˆ™æŠ›å¼‚å¸¸"""
    try:
        driver.quit()
    except Exception:
        pass
    driver = _new_driver(headless=headless)
    driver.get(page_url)
    _wait_list_loaded(driver, first=first_wait)
    links = _extract_links(driver)
    return driver, links

def reiss_get_links(
    category_base_urls: Iterable[str] | None = None,
    output_file: str | Path | None = None,
    headless: bool = HEADLESS_DEFAULT,
    max_pages_per_cat: int = 500,
    use_swiftshader: bool = False,   # âœ… å¯é€‰ï¼šå‹åˆ¶ GPU æŠ¥é”™
) -> Path:
    cats: List[str] = [u.strip() for u in (category_base_urls or DEFAULT_CATEGORIES) if u and u.strip()]
    if not cats:
        raise ValueError("è¯·ä¼ å…¥ category_base_urlsï¼Œæˆ–åœ¨ REISS['CATEGORY_BASE_URLS'] é…ç½®ç±»ç›®é¦–é¡µ URLï¼ˆæ—  pï¼‰ã€‚")

    out_path = Path(output_file) if output_file else DEFAULT_OUTPUT
    out_path.parent.mkdir(parents=True, exist_ok=True)

    # å¯é€‰å¼€å¯ SwiftShader
    if use_swiftshader:
        orig_new = _new_driver
        def _new_driver_swiftshader(headless: bool = HEADLESS_DEFAULT):
            options = webdriver.ChromeOptions()
            if headless:
                options.add_argument("--headless=new")
            options.add_argument("--disable-gpu")
            options.add_argument("--no-sandbox")
            options.add_argument("--disable-dev-shm-usage")
            options.add_argument("--window-size=1920,1080")
            options.add_experimental_option("excludeSwitches", ["enable-automation"])
            options.add_experimental_option("useAutomationExtension", False)
            options.add_argument("--enable-unsafe-swiftshader")
            options.add_argument("--use-angle=swiftshader")
            drv = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
            drv.execute_cdp_cmd("Page.addScriptToEvaluateOnNewDocument", {
                "source": "Object.defineProperty(navigator,'webdriver',{get:()=>undefined});"
            })
            return drv
        globals()["_new_driver"] = _new_driver_swiftshader  # åŠ¨æ€æ›¿æ¢

    all_links: Set[str] = set()
    driver: webdriver.Chrome | None = None

    try:
        driver = _new_driver(headless=headless)

        for idx, base in enumerate(cats, 1):
            print(f"\nâ–¶ ç±»ç›® [{idx}/{len(cats)}]: {base}")
            cat_links: Set[str] = set()
            cat_file = out_path.with_name(f"links_{_slug(base)}.txt")
            empty_streak = 0

            try:
                for page in range(1, max_pages_per_cat + 1):
                    page_url = _build_page_url(base, page)
                    print(f"ğŸŒ ç¬¬ {page} é¡µï¼š{page_url}")

                    try:
                        driver.get(page_url)
                        _wait_list_loaded(driver, first=(page == 1))
                        links = _extract_links(driver)
                    except Exception as e:
                        print(f"ğŸ’¥ æœ¬é¡µå¼‚å¸¸ï¼š{e} â†’ å°è¯•é‡å¯æµè§ˆå™¨å¹¶é‡è¯•ä¸€æ¬¡â€¦")
                        try:
                            driver, links = _maybe_restart_and_retry(driver, headless, page_url, first_wait=(page == 1))
                            print("   ğŸ” é‡è¯•æˆåŠŸã€‚")
                        except Exception as e2:
                            print(f"   ğŸ’£ é‡è¯•ä»å¤±è´¥ï¼š{e2} â†’ ç»“æŸæœ¬ç±»ç›®ï¼Œç»§ç»­ä¸‹ä¸€ä¸ªã€‚")
                            # å†™å…¥ç±»ç›®çº§ä¸æ€»çº§æ–‡ä»¶çš„å½“å‰ç´¯è®¡
                            _safe_write(cat_file, sorted(cat_links))
                            _safe_write(out_path, sorted(all_links))
                            break  # ç»“æŸæœ¬ç±»ç›®

                    before_all = len(all_links)
                    before_cat = len(cat_links)
                    all_links.update(links)
                    cat_links.update(links)
                    added_all = len(all_links) - before_all
                    added_cat = len(cat_links) - before_cat

                    print(f"   âœ… æŠ“åˆ° {len(links)} æ¡ï¼Œæœ¬é¡µæ–°å¢(ç±»ç›®) {added_cat} æ¡ï¼Œç´¯è®¡(æ€») {len(all_links)}")

                    # æ¯é¡µå¢é‡å†™ç›˜ï¼šç±»ç›®çº§ + æ€»æ±‡æ€»
                    _safe_write(cat_file, sorted(cat_links))
                    _safe_write(out_path, sorted(all_links))

                    # è¿ç»­ä¸¤é¡µæ— æ–°å¢ï¼Œç»“æŸæœ¬ç±»ç›®
                    if added_cat == 0:
                        empty_streak += 1
                    else:
                        empty_streak = 0
                    if empty_streak >= MAX_EMPTY_PAGES:
                        print(f"   â¹ï¸ è¿ç»­ {MAX_EMPTY_PAGES} é¡µæ— æ–°å¢ï¼Œç»“æŸæœ¬ç±»ç›®")
                        break

                    time.sleep(random.uniform(0.6, 1.2))

            except Exception as e_cat:
                # ç±»ç›®çº§å…œåº•ï¼šæ— è®ºå‘ç”Ÿä»€ä¹ˆï¼Œç»§ç»­ä¸‹ä¸€ä¸ªç±»ç›®
                print(f"ğŸš§ ç±»ç›®çº§å¼‚å¸¸ï¼š{e_cat} â†’ è·³è¿‡è¯¥ç±»ç›®ä½™ä¸‹é¡µé¢ã€‚")
                _safe_write(cat_file, sorted(cat_links))
                _safe_write(out_path, sorted(all_links))
                continue

    except Exception as e:
        print(f"ğŸ’£ å…¨å±€å¼‚å¸¸ï¼š{e}")
    finally:
        try:
            _safe_write(out_path, sorted(all_links))
            print(f"ğŸ“ å·²æœ€ç»ˆä¿å­˜ {len(all_links)} æ¡ â†’ {out_path}")
        except Exception as _e:
            print(f"âš ï¸ å†™æ–‡ä»¶å¤±è´¥ï¼š{_e}")
        try:
            if driver:
                driver.quit()
        except Exception:
            pass

    return out_path

# ç›´æ¥è¿è¡Œç¤ºä¾‹
if __name__ == "__main__":
    cats = DEFAULT_CATEGORIES or [
        "https://www.reiss.com/shop/feat-sale-gender-women-0",
        "https://www.reiss.com/shop/feat-sale-gender-men-0",
    ]
    reiss_get_links(cats, headless=True)
