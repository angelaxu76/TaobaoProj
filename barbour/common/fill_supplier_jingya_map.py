# -*- coding: utf-8 -*-
from __future__ import annotations
import csv
from pathlib import Path
from typing import Dict, List, Optional, Set

import openpyxl
from sqlalchemy import create_engine, text
from sqlalchemy.engine import Connection

from config import BRAND_CONFIG, BARBOUR
from barbour.core.site_utils import canonical_site

PUBLICATION_DIR = Path(BARBOUR["PUBLICATION_DIR"])
PATTERN = "barbour_publication_*.xlsx"
TABLE = "barbour_supplier_map"

SQL_CREATE = text(f"""
CREATE TABLE IF NOT EXISTS {TABLE} (
  product_code VARCHAR(50) PRIMARY KEY,
  site_name    VARCHAR(100) NOT NULL
);
""")

SQL_PUBLISHED_CODES = text("""
SELECT DISTINCT product_code
FROM barbour_inventory
WHERE is_published = TRUE
  AND product_code IS NOT NULL
""")  # is_published/product_code æ¥è‡ª inventoryã€‚:contentReference[oaicite:0]{index=0}

SQL_EXISTING_MAP = text(f"SELECT product_code FROM {TABLE}")

SQL_UPSERT = text(f"""
INSERT INTO {TABLE} (product_code, site_name)
VALUES (:code, :site)
ON CONFLICT (product_code) DO UPDATE SET site_name = EXCLUDED.site_name
""")

SQL_LOWEST_SITE = text("""
WITH agg AS (
  SELECT
    site_name,
    -- æœ‰è´§å°ºç æ•°
    SUM(CASE WHEN COALESCE(stock_count,0) > 0 THEN 1 ELSE 0 END) AS sizes_in_stock,
    -- ä»…åœ¨æœ‰è´§å°ºç ä¸­å–æœ€ä½ä»·
    MIN(COALESCE(NULLIF(price_gbp,0), original_price_gbp))
      FILTER (WHERE COALESCE(stock_count,0) > 0)                 AS min_price,
    MAX(last_checked)                                            AS latest
  FROM barbour_offers
  WHERE product_code = :code
    AND is_active = TRUE
  GROUP BY site_name
),
eligible AS (
  SELECT * FROM agg WHERE sizes_in_stock >= 3
)
SELECT site_name
FROM eligible
ORDER BY
  min_price ASC NULLS LAST,
  sizes_in_stock DESC,
  latest DESC
LIMIT 1
""")  # offers å­—æ®µå‚è€ƒï¼šsite_name/price_gbp/original_price_gbp/stock_count/last_checkedã€‚:contentReference[oaicite:1]{index=1}


def _load_publication_mappings(pub_dir: Path) -> Dict[str, str]:
    """
    è¯»å–ç›®å½•ä¸‹æ‰€æœ‰ barbour_publication_*.xlsxï¼Œè¿”å› {product_code -> canonical_site}
    åè¯»çš„æ–°æ–‡ä»¶è¦†ç›–æ—§æ–‡ä»¶ï¼ˆä»¥â€œæœ€æ–°å‘å¸ƒâ€ä¸ºå‡†ï¼‰ã€‚
    å…¼å®¹åˆ—åï¼š
      ç¼–ç ï¼šProduct Code / å•†å“ç¼–ç  / product_code / color_code / ç¼–ç 
      ç«™ç‚¹ï¼šSupplier / ä¾›åº”å•† / Site / site / ç«™ç‚¹
    """
    def _headers(ws) -> Dict[str, int]:
        h = {}
        for j, c in enumerate(ws[1], start=1):
            k = str(c.value or "").strip().lower().replace(" ", "")
            if k:
                h[k] = j
        return h

    mappings: Dict[str, str] = {}
    files = sorted(pub_dir.glob(PATTERN), key=lambda p: p.stat().st_mtime)
    for fp in files:
        try:
            wb = openpyxl.load_workbook(fp, data_only=True)
            ws = wb.active
            hdr = _headers(ws)
            col_code = next((hdr[k] for k in ("productcode","å•†å“ç¼–ç ","product_code","color_code","ç¼–ç ") if k in hdr), None)
            col_site = next((hdr[k] for k in ("supplier","ä¾›åº”å•†","site","ç«™ç‚¹") if k in hdr), None)
            if not col_code or not col_site:
                continue
            for i in range(2, ws.max_row + 1):
                code = str(ws.cell(i, col_code).value or "").strip()
                site_raw = str(ws.cell(i, col_site).value or "").strip()
                if not code or not site_raw:
                    continue
                site = canonical_site(site_raw)
                if site:
                    mappings[code] = site
        except Exception as e:
            print(f"âš ï¸ è§£æå¤±è´¥ {fp.name}: {e}")
    return mappings


def _pick_lowest_site(conn: Connection, code: str) -> Optional[str]:
    row = conn.execute(SQL_LOWEST_SITE, {"code": code}).fetchone()
    if not row:
        return None
    return canonical_site(row[0]) or row[0]


def fill_supplier_map(force_refresh: bool = False) -> None:
    cfg = BRAND_CONFIG["barbour"]["PGSQL_CONFIG"]
    engine = create_engine(
        f"postgresql+psycopg2://{cfg['user']}:{cfg['password']}@{cfg['host']}:{cfg['port']}/{cfg['dbname']}"
    )

    with engine.begin() as conn:
        # 0) ç¡®ä¿è¡¨å­˜åœ¨ï¼ˆNOT NULL çº¦æŸä¿æŒï¼‰
        conn.execute(SQL_CREATE)

        if force_refresh:
            conn.execute(text(f"TRUNCATE TABLE {TABLE};"))
            print(f"âš ï¸ å·²æ¸…ç©º {TABLE} è¡¨ã€‚")       

        # 1) å–â€œå·²å‘å¸ƒâ€çš„ç¼–ç é›†åˆï¼ˆä¸æ’å…¥ä»»ä½• NULLï¼‰
        published: Set[str] = {r[0] for r in conn.execute(SQL_PUBLISHED_CODES).fetchall()}
        print(f"ğŸ“¦ å·²å‘å¸ƒç¼–ç ï¼š{len(published)} ä¸ªã€‚")  # æ¥è‡ª inventoryã€‚:contentReference[oaicite:2]{index=2}

        # 2) å·²æœ‰æ˜ å°„ï¼ˆé¿å…é‡å¤å¤„ç†ï¼‰
        try:
            existing: Set[str] = {r[0] for r in conn.execute(SQL_EXISTING_MAP).fetchall()}
        except Exception:
            existing = set()

        # 3) ä»å‘å¸ƒæ¸…å•å†™å…¥æ˜ å°„ï¼ˆæœ€æ–°è¦†ç›–æ—§å€¼ï¼‰
        pub_map = _load_publication_mappings(PUBLICATION_DIR)
        pub_hit: List[str] = []
        for code, site in pub_map.items():
            if code in published:
                conn.execute(SQL_UPSERT, {"code": code, "site": site})
                pub_hit.append(code)
        print(f"âœ… æŒ‰å‘å¸ƒæ–‡ä»¶æ›´æ–°ï¼š{len(pub_hit)} æ¡ã€‚")
        # æ‰“å°å‘½ä¸­ç¼–ç ï¼ˆä¾¿äºä½ åŒºåˆ†æ¥æºï¼‰
        if pub_hit:
            print("â†’ æ¥è‡ª publication çš„ç¼–ç ï¼š", ", ".join(pub_hit))

        # 4) å…œåº•ï¼šå¯¹â€œå·²å‘å¸ƒä½†è¿˜æœªæ˜ å°„â€çš„ç¼–ç ï¼Œç”¨ offers é€‰æœ€ä½ä»·ç«™ç‚¹
        need = (published - set(pub_hit)) - existing
        offer_filled: List[str] = []
        for code in sorted(need):
            site = _pick_lowest_site(conn, code)
            if site:
                conn.execute(SQL_UPSERT, {"code": code, "site": site})
                offer_filled.append(code)
        print(f"âœ… æŒ‰ offers å…œåº•ï¼š{len(offer_filled)} æ¡ã€‚")
        if offer_filled:
            print("â†’ æ¥è‡ª offers å…œåº•çš„ç¼–ç ï¼š", ", ".join(offer_filled))

        # 5) ç»Ÿè®¡æ”¶å°¾
        total_now = conn.execute(text(f"SELECT COUNT(*) FROM {TABLE}")).scalar_one()
        print(f"ğŸ¯ å®Œæˆæ˜ å°„ï¼Œæ€»è®¡ {total_now} æ¡ã€‚")
