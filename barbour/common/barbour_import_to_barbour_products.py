# barbour_import_to_barbour_products.py
# -*- coding: utf-8 -*-
"""
å¯¼å…¥ç»Ÿä¸€æ¨¡æ¿ TXT åˆ° barbour_productsï¼ˆå…¼å®¹æ—§æ¨¡æ¿ï¼Œå·²å…¨é¢åˆ‡æ¢ä¸º product_codeï¼‰
- å¿…å¡«ï¼šproduct_code, style_name, color, size, match_keywords
- å¯é€‰ï¼štitle, product_description, gender, category
- æ•°æ®æ¥æºä¼˜å…ˆçº§ï¼šbarbourå®˜ç½‘(0) > æœ‰ç¼–ç ç«™ç‚¹(1) > äººå·¥è¡¥ç (2)
- è§£æé¡ºåºï¼š
  1) ç»Ÿä¸€æ¨¡æ¿å­—æ®µï¼ˆä¼˜å…ˆï¼‰ï¼š
     Product Code / Product Name / Product Color / Product Description /
     Product Gender / Style Category / Product Size / Site Name / Source URL
  2) å…¼å®¹æ—§æ¨¡æ¿ï¼š
     Offer List: è¡Œï¼ˆsize|price|stock|can_orderï¼‰
     (Product )?Sizes: è¡Œ
"""

from __future__ import annotations
from pathlib import Path
from typing import List, Dict, Tuple
import psycopg2
import re
import unicodedata
import sys

from config import PGSQL_CONFIG, BARBOUR

# â€”â€” å¯é€‰ï¼šæ ‡é¢˜ç”Ÿæˆï¼ˆå­˜åœ¨åˆ™ç”¨ï¼Œä¸å­˜åœ¨å¿½ç•¥ï¼‰â€”â€”
try:
    from generate_barbour_taobao_title import generate_barbour_taobao_title
except Exception:
    generate_barbour_taobao_title = None  # æ²¡æœ‰ä¹Ÿä¸å½±å“

# -------------------- åŸºç¡€å·¥å…· --------------------
COMMON_WORDS = {
    "jacket", "coat", "gilet", "vest", "shirt", "top",
    "t-shirt", "pants", "trousers", "shorts", "parka",
    "barbour", "mens", "women", "ladies", "kids"
}

# Barbour ç¼–ç è¯†åˆ«ï¼šå¦‚ MWX0339NY91 / LWX0339OL51 / LBA0400BK111 ç­‰
RE_CODE = re.compile(r'[A-Z]{3}\d{3,4}[A-Z]{2,3}\d{2,3}')

def normalize_text(text: str) -> str:
    return unicodedata.normalize("NFKD", text or "").encode("ascii", "ignore").decode("ascii")

def extract_match_keywords(style_name: str) -> List[str]:
    style_name = normalize_text(style_name or "")
    cleaned = re.sub(r"[^\w\s]", "", style_name)
    words = [w.lower() for w in cleaned.split() if len(w) >= 3]
    return [w for w in words if w not in COMMON_WORDS]

def guess_product_code_from_filename(fp: Path) -> str | None:
    """ä»æ–‡ä»¶åä¸­çŒœæµ‹ product_codeï¼ˆå¦‚ MWX0339NY91.txtï¼‰ã€‚"""
    m = RE_CODE.search(fp.stem.upper())
    return m.group(0) if m else None

def validate_minimal_fields(rec: Dict) -> Tuple[bool, List[str]]:
    required = ["product_code", "style_name", "color", "size", "match_keywords"]
    missing = [k for k in required if not rec.get(k)]
    return (len(missing) == 0, missing)

# -------------------- ç»Ÿä¸€æ¨¡æ¿è§£æ --------------------
def _extract_field(text: str, label_re: str) -> str | None:
    """æå–å•è¡Œå­—æ®µï¼šå¦‚ Product Name: ... / Product Color: ..."""
    m = re.search(rf'{label_re}\s*:\s*([^\n\r]+)', text, flags=re.S)
    return m.group(1).strip() if m else None

def _extract_multiline_field(text: str, label_re: str) -> str | None:
    """æå–å¤šè¡Œå­—æ®µï¼šå¦‚ Product Description: ...ï¼ˆç›´åˆ°ä¸‹ä¸€ä¸ªâ€œWord:â€å­—æ®µï¼‰"""
    m = re.search(rf'{label_re}\s*:\s*(.+)', text, flags=re.S)
    if not m:
        return None
    tail = m.group(1)
    parts = re.split(r'\n\s*[A-Z][A-Za-z ]+:\s*', tail, maxsplit=1)
    return parts[0].strip() if parts else None

def _parse_sizes_from_product_size_line(text: str) -> List[str]:
    """ç»Ÿä¸€æ¨¡æ¿ï¼šProduct Size: 34:æœ‰è´§;36:æ— è´§;M:æœ‰è´§ ..."""
    line = _extract_field(text, r'(?i)Product\s+Size')
    if not line:
        return []
    sizes = []
    for token in line.split(";"):
        token = token.strip()
        if not token:
            continue
        size = token.split(":", 1)[0].strip()
        if size and size not in sizes:
            sizes.append(size)
    return sizes

# -------------------- æ—§æ¨¡æ¿å…¼å®¹ --------------------
def _extract_sizes_from_offer_list_block(text: str) -> list[str]:
    """æ—§ï¼šOffer List: å—ä¸­è§£æç¬¬ä¸€åˆ—å°ºç ï¼ˆsize|price|stock|can_orderï¼‰"""
    sizes = []
    in_block = False
    for line in text.splitlines():
        if not in_block:
            if re.search(r'^\s*Offer\s+List\s*:\s*$', line, flags=re.I):
                in_block = True
            continue
        if not line.strip() or re.match(r'^\s*[A-Z][A-Za-z ]+:\s*', line):
            break
        m = re.match(r'^\s*([^|]+)\|', line)
        if m:
            size = m.group(1).strip()
            size = size.split(":")[0].strip()
            if size and size not in sizes:
                sizes.append(size)
    return sizes

def _extract_sizes_from_sizes_line(text: str) -> list[str]:
    """æ—§ï¼š(Product )?Sizes: è¡Œï¼›é€—å·/åˆ†å·/æ–œæ åˆ†éš”"""
    m = re.search(r'(?i)(?:Product\s+)?Sizes?\s*:\s*(.+)', text)
    if not m:
        return []
    raw = m.group(1)
    parts = re.split(r'[;,/|]', raw)
    sizes = []
    for p in parts:
        p = p.strip()
        if not p:
            continue
        sizes.append(p.split(":")[0].strip())
    return sizes

# -------------------- å¯é€‰å­—æ®µå¢å¼º --------------------
_GENDER_PAT = [
    (r'\b(women|ladies|woman)\b', 'å¥³æ¬¾'),
    (r'\b(men|mens|man)\b',       'ç”·æ¬¾'),
    (r'\b(girl|boy|kid|kids)\b',  'ç«¥æ¬¾'),
]
_CATEGORY_PAT = [
    (r'quilt',             'quilted jacket'),
    (r'\bwax',             'waxed jacket'),
    (r'\bgilet\b|vest',    'gilet'),
    (r'\bparka\b',         'parka'),
    (r'\bliner\b',         'liner'),
    (r'\bfleece\b',        'fleece'),
    (r'\bshirt\b',         'shirt'),
    (r'knit|sweater',      'knitwear'),
]

def infer_gender(text: str) -> str | None:
    t = (text or "").lower()
    for pat, val in _GENDER_PAT:
        if re.search(pat, t):
            return val
    return None

def infer_category(text: str) -> str | None:
    t = (text or "").lower()
    for pat, val in _CATEGORY_PAT:
        if re.search(pat, t):
            return val
    return None

def enrich_record_optional(rec: Dict) -> Dict:
    # ä»…åœ¨ç¼ºå¤±æ—¶è¡¥
    code  = rec.get("product_code") or ""
    name  = rec.get("style_name") or ""
    color = rec.get("color") or ""
    base_text = " ".join([name, rec.get("product_description") or ""])

    if not rec.get("title") and generate_barbour_taobao_title:
        try:
            info = generate_barbour_taobao_title(code, name, color) or {}
            title_cn = info.get("Title")
            if title_cn:
                rec["title"] = title_cn
        except Exception:
            pass

    if not rec.get("gender"):
        g = infer_gender(base_text)
        if g:
            rec["gender"] = g

    if not rec.get("category"):
        c = infer_category(base_text)
        if c:
            rec["category"] = c

    return rec

# -------------------- TXT è§£æï¼ˆç»Ÿä¸€ + å…¼å®¹ï¼‰ --------------------
def parse_txt_file(filepath: Path) -> List[Dict]:
    """
    è¾“å‡º recordsï¼ˆæ¯å°ºç ä¸€æ¡ï¼‰ï¼š
      product_code, style_name, color, size, match_keywords,
      + å¯é€‰ï¼štitle, product_description, gender, category
      + æ¥æºï¼šsource_site, source_url, source_rank
    """
    text = filepath.read_text(encoding="utf-8", errors="ignore")
    info: Dict = {"sizes": []}

    # Product Code
    m = re.search(r'(?i)Product\s+(?:Color\s+)?Code:\s*([A-Z0-9]+|No\s+Data|null)', text)
    code = (m.group(1).strip() if m else None)
    if code and code.lower() not in {"no data", "null"}:
        info["product_code"] = code
    else:
        info["product_code"] = guess_product_code_from_filename(filepath)

    # Product Name
    name = _extract_field(text, r'(?i)Product\s+Name')
    if name:
        info["style_name"] = name

    # Product Color
    color = _extract_field(text, r'(?i)Product\s+Colou?r')
    if color:
        val = re.sub(r'^\-+\s*', '', color).strip()
        info["color"] = val

    # Product Descriptionï¼ˆå¤šè¡Œï¼‰
    desc = _extract_multiline_field(text, r'(?i)Product\s+Description')
    if desc:
        info["product_description"] = desc

    # Product Genderï¼ˆå¯é€‰ï¼‰
    g = _extract_field(text, r'(?i)Product\s+Gender')
    if g:
        gl = g.lower()
        if any(k in gl for k in ["å¥³", "women", "ladies", "woman"]):
            info["gender"] = "å¥³æ¬¾"
        elif any(k in gl for k in ["ç”·", "men", "mens", "man"]):
            info["gender"] = "ç”·æ¬¾"
        elif any(k in gl for k in ["ç«¥", "kid", "kids", "boy", "girl"]):
            info["gender"] = "ç«¥æ¬¾"

    # Style Categoryï¼ˆå¯é€‰ï¼‰
    cat = _extract_field(text, r'(?i)Style\s+Category')
    if cat:
        info["category"] = cat

    # Product Sizeï¼ˆç»Ÿä¸€æ¨¡æ¿ï¼‰
    sizes = _parse_sizes_from_product_size_line(text)
    if not sizes:
        sizes = _extract_sizes_from_offer_list_block(text)
    if not sizes:
        sizes = _extract_sizes_from_sizes_line(text)
    info["sizes"] = sizes

    # æ¥æºï¼ˆç”¨äºå†™å…¥ source_* ä¸ rankï¼‰
    source_site = _extract_field(text, r'(?i)Site\s+Name') or ""
    source_url  = _extract_field(text, r'(?i)Source\s+URL') or ""
    info["source_site"] = source_site.strip()
    info["source_url"]  = source_url.strip()
    # rankï¼šbarbourå®˜ç½‘=0ï¼›æœ‰ç¼–ç ç«™ç‚¹=1ï¼›æ— ç¼–ç ï¼ˆé äººå·¥ï¼‰=2
    if (info["source_site"] or "").lower() == "barbour":
        info["source_rank"] = 0
    elif info.get("product_code"):
        info["source_rank"] = 1
    else:
        info["source_rank"] = 2

    # â€”â€” å…¥åº“å¿…è¦å­—æ®µæ ¡éªŒ â€”â€”ï¼ˆç¼ºå¤±åˆ™è·³è¿‡ï¼‰
    if not info.get("product_code") or not info.get("style_name") or not info.get("color") or not info["sizes"]:
        miss = [k for k in ("product_code", "style_name", "color", "sizes")
                if not info.get(k) or (k == "sizes" and not info["sizes"])]
        print(f"âš ï¸ è·³è¿‡ï¼ˆä¿¡æ¯ä¸å®Œæ•´ï¼‰: {filepath.name} | ç¼ºå¤±: {', '.join(miss)}")
        return []

    keywords = extract_match_keywords(info["style_name"])

    # â€”â€” ç”Ÿæˆ recordsï¼ˆæ¯å°ºç ä¸€æ¡ï¼‰â€”â€”
    records: List[Dict] = []
    for size in info["sizes"]:
        r = {
            "product_code": info["product_code"],
            "style_name": info["style_name"],
            "color": info["color"],
            "size": size,
            "match_keywords": keywords,
            "source_site": info.get("source_site", ""),
            "source_url": info.get("source_url", ""),
            "source_rank": info.get("source_rank", 999)
        }
        if info.get("product_description"):
            r["product_description"] = info["product_description"]
        if info.get("gender"):
            r["gender"] = info["gender"]
        if info.get("category"):
            r["category"] = info["category"]

        # è½»é‡ enrichï¼ˆä¸è¦†ç›–å·²æœ‰å€¼ï¼‰
        r = enrich_record_optional(r)

        ok, missing = validate_minimal_fields(r)
        if not ok:
            print(f"âš ï¸ è·³è¿‡ï¼ˆè¡Œä¸å®Œæ•´ï¼‰: {filepath.name} {size} | ç¼ºå¤±: {', '.join(missing)}")
            continue
        records.append(r)

    return records

# -------------------- DB å…¥åº“ï¼ˆæŒ‰æ¥æºä¼˜å…ˆçº§ä¿æŠ¤è¦†ç›–ï¼‰ --------------------
def insert_into_products(records: List[Dict], conn):
    """
    UPSERT è§„åˆ™ï¼š
    - å†²çªé”®ï¼š(product_code, size)
    - ä»…å½“ EXCLUDED.source_rank <= ç°æœ‰ source_rank æ—¶ï¼Œå…è®¸è¦†ç›–åŸºç¡€å­—æ®µ
    - titleï¼šè‹¥åº“é‡Œä¸ºç©ºåˆ™å¡«
    - description/gender/categoryï¼šä¼˜å…ˆæ–°å€¼ï¼Œå¦åˆ™ä¿ç•™æ—§å€¼ï¼ˆä¹Ÿå— rank ä¿æŠ¤ï¼‰
    """
    sql = """
    INSERT INTO barbour_products
      (product_code, style_name, color, size, match_keywords,
       title, product_description, gender, category,
       source_site, source_url, source_rank)
    VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)
    ON CONFLICT (product_code, size) DO UPDATE SET
       style_name = CASE WHEN EXCLUDED.source_rank <= barbour_products.source_rank THEN EXCLUDED.style_name ELSE barbour_products.style_name END,
       color      = CASE WHEN EXCLUDED.source_rank <= barbour_products.source_rank THEN EXCLUDED.color      ELSE barbour_products.color      END,
       -- ä»…å½“åŸ title ä¸ºç©ºæ—¶å†™å…¥ï¼ˆé¿å…è¦†ç›–ä½ æ‰‹å·¥ä¼˜åŒ–è¿‡çš„ä¸­æ–‡æ ‡é¢˜ï¼‰
       title               = COALESCE(barbour_products.title, EXCLUDED.title),
       product_description = CASE WHEN EXCLUDED.source_rank <= barbour_products.source_rank THEN COALESCE(EXCLUDED.product_description, barbour_products.product_description) ELSE barbour_products.product_description END,
       gender              = CASE WHEN EXCLUDED.source_rank <= barbour_products.source_rank THEN COALESCE(EXCLUDED.gender, barbour_products.gender) ELSE barbour_products.gender END,
       category            = CASE WHEN EXCLUDED.source_rank <= barbour_products.source_rank THEN COALESCE(EXCLUDED.category, barbour_products.category) ELSE barbour_products.category END,
       source_site         = CASE WHEN EXCLUDED.source_rank <= barbour_products.source_rank THEN EXCLUDED.source_site ELSE barbour_products.source_site END,
       source_url          = CASE WHEN EXCLUDED.source_rank <= barbour_products.source_rank THEN EXCLUDED.source_url  ELSE barbour_products.source_url  END,
       source_rank         = LEAST(barbour_products.source_rank, EXCLUDED.source_rank);
    """
    with conn.cursor() as cur:
        for r in records:
            try:
                cur.execute(sql, (
                    r.get("product_code"),
                    r.get("style_name"),
                    r.get("color"),
                    r.get("size"),
                    r.get("match_keywords"),
                    r.get("title"),
                    r.get("product_description"),
                    r.get("gender"),
                    r.get("category"),
                    r.get("source_site"),
                    r.get("source_url"),
                    int(r.get("source_rank") or 999),
                ))
            except Exception as e:
                print(f"âŒ å…¥åº“å¤±è´¥ï¼ˆè®°å½•çº§ï¼‰: code={r.get('product_code')} size={r.get('size')} | é”™è¯¯: {e}")
                conn.rollback()
                continue
    conn.commit()

# -------------------- ç›®å½•å‘ç° & æ‰¹å¤„ç†å…¥å£ --------------------
_ALIAS = {
    "oac": "outdoorandcountry",
    "outdoor": "outdoorandcountry",
    "allweather": "allweathers",
    "hof": "houseoffraser",
    "pm": "philipmorris",
}

def _discover_txt_paths_by_supplier(supplier: str = "all") -> List[Path]:
    supplier = (supplier or "all").strip().lower()
    supplier = _ALIAS.get(supplier, supplier)

    txt_dirs: Dict[str, str] = BARBOUR.get("TXT_DIRS", {}) or {}
    paths: List[Path] = []

    if supplier == "all":
        for dirpath in txt_dirs.values():
            p = Path(dirpath)
            if p.exists():
                paths.extend(sorted(p.glob("*.txt")))
        if not paths and BARBOUR.get("TXT_DIR"):
            p = Path(BARBOUR["TXT_DIR"])
            if p.exists():
                paths = sorted(p.glob("*.txt"))
        return paths

    # æŒ‡å®šä¾›åº”å•†ç›®å½•
    dirpath = txt_dirs.get(supplier)
    if not dirpath:
        zh_map = {"å®˜ç½‘": "barbour", "barbourå®˜ç½‘": "barbour", "æˆ·å¤–": "outdoorandcountry"}
        supplier = zh_map.get(supplier, supplier)
        dirpath = txt_dirs.get(supplier)

    p = Path(dirpath) if dirpath else None
    if p and p.exists():
        return sorted(p.glob("*.txt"))
    return []

def batch_import_txt_to_barbour_product(supplier: str = "all"):
    files = _discover_txt_paths_by_supplier(supplier)
    if not files:
        print(f"âš ï¸ æœªæ‰¾åˆ°ä»»ä½• TXT æ–‡ä»¶ï¼ˆsupplier='{supplier}'ï¼‰ã€‚è¯·æ£€æŸ¥ BARBOUR['TXT_DIRS'] é…ç½®æˆ–ç›®å½•æ˜¯å¦å­˜åœ¨ã€‚")
        return

    conn = psycopg2.connect(**PGSQL_CONFIG)
    total_rows = 0
    parsed_files = 0

    for file in files:
        try:
            records = parse_txt_file(file)
            if not records:
                print(f"â“˜ è·³è¿‡ï¼ˆæ— è®°å½•ï¼‰: {file.name}")
                continue
            insert_into_products(records, conn)
            print(f"âœ… å¯¼å…¥ {file.name} â€” {len(records)} æ¡")
            total_rows += len(records)
            parsed_files += 1
        except Exception as e:
            conn.rollback()
            print(f"âŒ å¯¼å…¥å¤±è´¥ï¼ˆæ–‡ä»¶çº§ï¼‰: {file.name} | é”™è¯¯: {e}")
            continue

    conn.close()
    print(f"\nğŸ‰ å¯¼å…¥å®Œæˆï¼ˆsupplier='{supplier}'ï¼‰ï¼š{parsed_files} ä¸ªæ–‡ä»¶ï¼Œå…± {total_rows} æ¡è®°å½•")

if __name__ == "__main__":
    arg = sys.argv[1] if len(sys.argv) > 1 else "all"
    batch_import_txt_to_barbour_product(arg)
