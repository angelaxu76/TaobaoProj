# barbour_import_to_barbour_products.py
# -*- coding: utf-8 -*-
"""
å¯¼å…¥ç»Ÿä¸€æ¨¡æ¿ TXT åˆ° barbour_productsï¼ˆå…¼å®¹æ—§æ¨¡æ¿ï¼‰
- å¿…å¡«ï¼šcolor_code, style_name, color, size, match_keywords
- å¯é€‰ï¼štitle, product_description, gender, category
- è§£æžé¡ºåºï¼š
  1) ç»Ÿä¸€æ¨¡æ¿å­—æ®µï¼ˆä¼˜å…ˆï¼‰ï¼š
     Product Code / Product Name / Product Color / Product Description /
     Product Gender / Style Category / Product Size
  2) å…¼å®¹æ—§æ¨¡æ¿ï¼š
     Offer List: è¡Œï¼ˆsize|price|stock|can_orderï¼‰
     (Product )?Sizes: è¡Œ
- ç›®å½•å‘çŽ°ï¼š
  è‹¥ config.BARBOUR å­˜åœ¨ TXT_DIRSï¼Œåˆ™éåŽ†æ‰€æœ‰ç«™ç‚¹ç›®å½•ï¼›å¦åˆ™é€€å›ž TXT_DIR
"""

from __future__ import annotations
from pathlib import Path
from typing import List, Dict, Tuple
import psycopg2
import re
import unicodedata

from config import PGSQL_CONFIG, BARBOUR

# â€”â€” å¯é€‰ï¼šæ ‡é¢˜ç”Ÿæˆï¼ˆä½ é¡¹ç›®é‡Œæœ‰çš„è¯ä¼šè‡ªåŠ¨ç”¨ï¼Œæ²¡çš„è¯è·³è¿‡ï¼‰â€”â€”
try:
    from generate_barbour_taobao_title import generate_barbour_taobao_title
except Exception:
    generate_barbour_taobao_title = None  # æ²¡æœ‰ä¹Ÿä¸å½±å“

# -------------------- åŸºç¡€å·¥å…· --------------------
COMMON_WORDS = {
    "jacket", "coat", "gilet", "vest", "shirt", "top",
    "t-shirt", "pants", "trousers", "shorts", "parka",
    "barbour", "mens", "women", "ladies", "kids"
}

# é¢œè‰²ç¼–ç ï¼ˆcolor_codeï¼‰è¯†åˆ«ï¼šæ”¯æŒ MWX0339NY91 / LWX0339OL51 / LBA0400BK111 ç­‰
RE_CODE = re.compile(r'[A-Z]{3}\d{3,4}[A-Z]{2,3}\d{2,3}')

def normalize_text(text: str) -> str:
    return unicodedata.normalize("NFKD", text or "").encode("ascii", "ignore").decode("ascii")

def extract_match_keywords(style_name: str) -> List[str]:
    style_name = normalize_text(style_name or "")
    cleaned = re.sub(r"[^\w\s]", "", style_name)
    words = [w.lower() for w in cleaned.split() if len(w) >= 3]
    return [w for w in words if w not in COMMON_WORDS]

def guess_color_code_from_filename(fp: Path) -> str | None:
    """ä»Žæ–‡ä»¶åä¸­çŒœæµ‹ color_codeï¼ˆå¦‚ MWX0339NY91.txtï¼‰ã€‚"""
    m = RE_CODE.search(fp.stem.upper())
    return m.group(0) if m else None

def validate_minimal_fields(rec: Dict) -> Tuple[bool, List[str]]:
    required = ["color_code", "style_name", "color", "size", "match_keywords"]
    missing = [k for k in required if not rec.get(k)]
    return (len(missing) == 0, missing)

# -------------------- ç»Ÿä¸€æ¨¡æ¿è§£æž --------------------
def _extract_field(text: str, label_re: str) -> str | None:
    """
    æå–å•è¡Œå­—æ®µï¼šå¦‚ Product Name: ... / Product Color: ...
    label_re ä¾‹ï¼šr'(?i)Product\\s+Name'
    """
    m = re.search(rf'{label_re}\s*:\s*([^\n\r]+)', text, flags=re.S)
    return m.group(1).strip() if m else None

def _extract_multiline_field(text: str, label_re: str) -> str | None:
    """
    æå–å¤šè¡Œå­—æ®µï¼šå¦‚ Product Description: ...ï¼ˆç›´åˆ°ä¸‹ä¸€ä¸ªâ€œTitleCase:â€å­—æ®µï¼‰
    """
    m = re.search(rf'{label_re}\s*:\s*(.+)', text, flags=re.S)
    if not m:
        return None
    tail = m.group(1)
    # æˆªæ–­åˆ°ä¸‹ä¸€æ®µå½¢å¦‚ â€œWord Word:â€ çš„å­—æ®µæ ‡é¢˜å‰
    parts = re.split(r'\n\s*[A-Z][A-Za-z ]+:\s*', tail, maxsplit=1)
    return parts[0].strip() if parts else None

def _parse_sizes_from_product_size_line(text: str) -> List[str]:
    """
    ç»Ÿä¸€æ¨¡æ¿ï¼šProduct Size: 34:æœ‰è´§;36:æ— è´§;M:æœ‰è´§ ...
    å–åˆ†å·å‰æ¯æ®µçš„ç¬¬ä¸€ä¸ªâ€œå†’å·å·¦ä¾§â€ä¸ºå°ºç 
    """
    line = _extract_field(text, r'(?i)Product\s+Size')
    if not line:
        return []
    sizes = []
    for token in line.split(";"):
        token = token.strip()
        if not token:
            continue
        size = token.split(":", 1)[0].strip()
        if size and size not in sizes:
            sizes.append(size)
    return sizes

# -------------------- æ—§æ¨¡æ¿å…¼å®¹ï¼ˆä½ åŽŸæ¥çš„é€»è¾‘ï¼‰ --------------------
def _extract_sizes_from_offer_list_block(text: str) -> list[str]:
    """
    æ—§ï¼šOffer List: å—ä¸­è§£æžç¬¬ä¸€åˆ—å°ºç ï¼ˆsize|price|stock|can_orderï¼‰
    """
    sizes = []
    in_block = False
    for line in text.splitlines():
        if not in_block:
            if re.search(r'^\s*Offer\s+List\s*:\s*$', line, flags=re.I):
                in_block = True
            continue
        if not line.strip() or re.match(r'^\s*[A-Z][A-Za-z ]+:\s*', line):
            break
        m = re.match(r'^\s*([^|]+)\|', line)
        if m:
            size = m.group(1).strip()
            size = size.split(":")[0].strip()
            if size and size not in sizes:
                sizes.append(size)
    return sizes

def _extract_sizes_from_sizes_line(text: str) -> list[str]:
    """
    æ—§ï¼š(Product )?Sizes: è¡Œï¼›é€—å·/åˆ†å·/æ–œæ åˆ†éš”
    """
    m = re.search(r'(?i)(?:Product\s+)?Sizes?\s*:\s*(.+)', text)
    if not m:
        return []
    raw = m.group(1)
    parts = re.split(r'[;,/|]', raw)
    sizes = []
    for p in parts:
        p = p.strip()
        if not p:
            continue
        sizes.append(p.split(":")[0].strip())
    return sizes

# -------------------- å¯é€‰å­—æ®µå¢žå¼ºï¼ˆä¸Žæ—§ç‰ˆä¸€è‡´ï¼‰ --------------------
_GENDER_PAT = [
    (r'\b(women|ladies|woman)\b', 'å¥³æ¬¾'),
    (r'\b(men|mens|man)\b',       'ç”·æ¬¾'),
    (r'\b(girl|boy|kid|kids)\b',  'ç«¥æ¬¾'),
]
_CATEGORY_PAT = [
    (r'quilt',             'quilted jacket'),
    (r'\bwax',             'waxed jacket'),
    (r'\bgilet\b|vest',    'gilet'),
    (r'\bparka\b',         'parka'),
    (r'\bliner\b',         'liner'),
    (r'\bfleece\b',        'fleece'),
    (r'\bshirt\b',         'shirt'),
    (r'knit|sweater',      'knitwear'),
]

def infer_gender(text: str) -> str | None:
    t = (text or "").lower()
    for pat, val in _GENDER_PAT:
        if re.search(pat, t):
            return val
    return None

def infer_category(text: str) -> str | None:
    t = (text or "").lower()
    for pat, val in _CATEGORY_PAT:
        if re.search(pat, t):
            return val
    return None

def enrich_record_optional(rec: Dict) -> Dict:
    # ä»…åœ¨ç¼ºå¤±æ—¶è¡¥
    code  = rec.get("color_code") or ""
    name  = rec.get("style_name") or ""
    color = rec.get("color") or ""
    base_text = " ".join([name, rec.get("product_description") or ""])

    if not rec.get("title") and generate_barbour_taobao_title:
        try:
            info = generate_barbour_taobao_title(code, name, color) or {}
            title_cn = info.get("Title")
            if title_cn:
                rec["title"] = title_cn
        except Exception:
            pass

    if not rec.get("gender"):
        g = infer_gender(base_text)
        if g:
            rec["gender"] = g

    if not rec.get("category"):
        c = infer_category(base_text)
        if c:
            rec["category"] = c

    return rec

# -------------------- TXT è§£æžï¼ˆç»Ÿä¸€ + å…¼å®¹ï¼‰ --------------------
def parse_txt_file(filepath: Path) -> List[Dict]:
    """
    è¾“å‡º recordsï¼ˆæ¯å°ºç ä¸€æ¡ï¼‰ï¼š
      color_code, style_name, color, size, match_keywords,
      + å¯é€‰ï¼štitle, product_description, gender, category
    """
    text = filepath.read_text(encoding="utf-8", errors="ignore")
    info: Dict = {"sizes": []}

    # ---- ç»Ÿä¸€æ¨¡æ¿å­—æ®µä¼˜å…ˆ ----
    # Product Code / Product Color Code
    m = re.search(r'(?i)Product\s+(?:Color\s+)?Code:\s*([A-Z0-9]+|No\s+Data|null)', text)
    code = (m.group(1).strip() if m else None)
    if code and code.lower() not in {"no data", "null"}:
        info["color_code"] = code
    else:
        # å…œåº•ï¼šå°è¯•ä»Žæ–‡ä»¶åè¯†åˆ«ï¼ˆOutdoor/Allweathers/å®˜ç½‘é€šå¸¸OKï¼›HoFå¯èƒ½æ²¡æœ‰ï¼‰
        info["color_code"] = guess_color_code_from_filename(filepath)

    # Product Name
    name = _extract_field(text, r'(?i)Product\s+Name')
    if name:
        info["style_name"] = name

    # Product Color
    color = _extract_field(text, r'(?i)Product\s+Colou?r')
    if color:
        val = re.sub(r'^\-+\s*', '', color).strip()
        info["color"] = val

    # Product Descriptionï¼ˆå¤šè¡Œï¼‰
    desc = _extract_multiline_field(text, r'(?i)Product\s+Description')
    if desc:
        info["product_description"] = desc

    # Product Genderï¼ˆå¯é€‰ï¼‰
    g = _extract_field(text, r'(?i)Product\s+Gender')
    if g:
        gl = g.lower()
        if any(k in gl for k in ["å¥³", "women", "ladies", "woman"]):
            info["gender"] = "å¥³æ¬¾"
        elif any(k in gl for k in ["ç”·", "men", "mens", "man"]):
            info["gender"] = "ç”·æ¬¾"
        elif any(k in gl for k in ["ç«¥", "kid", "kids", "boy", "girl"]):
            info["gender"] = "ç«¥æ¬¾"

    # Style Categoryï¼ˆå¯é€‰ï¼‰
    cat = _extract_field(text, r'(?i)Style\s+Category')
    if cat:
        info["category"] = cat

    # Product Sizeï¼ˆç»Ÿä¸€æ¨¡æ¿ï¼‰
    sizes = _parse_sizes_from_product_size_line(text)

    # ---- è‹¥æ²¡æœ‰ï¼Œç”¨æ—§æ¨¡æ¿å…œåº• ----
    if not sizes:
        sizes = _extract_sizes_from_offer_list_block(text)
    if not sizes:
        sizes = _extract_sizes_from_sizes_line(text)
    info["sizes"] = sizes

    # â€”â€” å…¥åº“å¿…è¦å­—æ®µæ ¡éªŒ â€”â€”ï¼ˆç¼ºå¤±åˆ™è·³è¿‡ï¼‰
    if not info.get("color_code") or not info.get("style_name") or not info.get("color") or not info["sizes"]:
        miss = [k for k in ("color_code", "style_name", "color", "sizes")
                if not info.get(k) or (k == "sizes" and not info["sizes"])]
        print(f"âš ï¸ è·³è¿‡ï¼ˆä¿¡æ¯ä¸å®Œæ•´ï¼‰: {filepath.name} | ç¼ºå¤±: {', '.join(miss)}")
        return []

    keywords = extract_match_keywords(info["style_name"])

    # â€”â€” ç”Ÿæˆ recordsï¼ˆæ¯å°ºç ä¸€æ¡ï¼‰â€”â€”
    records: List[Dict] = []
    for size in info["sizes"]:
        r = {
            "color_code": info["color_code"],
            "style_name": info["style_name"],
            "color": info["color"],
            "size": size,
            "match_keywords": keywords,
        }
        # å¯é€‰
        if info.get("product_description"):
            r["product_description"] = info["product_description"]
        if info.get("gender"):
            r["gender"] = info["gender"]
        if info.get("category"):
            r["category"] = info["category"]

        # è½»é‡ enrichï¼ˆä¸è¦†ç›–å·²æœ‰å€¼ï¼‰
        r = enrich_record_optional(r)

        ok, missing = validate_minimal_fields(r)
        if not ok:
            print(f"âš ï¸ è·³è¿‡ï¼ˆè¡Œä¸å®Œæ•´ï¼‰: {filepath.name} {size} | ç¼ºå¤±: {', '.join(missing)}")
            continue
        records.append(r)

    return records

# -------------------- DB å…¥åº“ï¼ˆåªå¡«ç©ºä½ç­–ç•¥ï¼‰ --------------------
def insert_into_products(records: List[Dict], conn):
    """
    æ²¿ç”¨ä½ åŽŸæ¥çš„ UPSERT ç­–ç•¥ï¼š
    - å­˜åœ¨å†²çª(color_code,size)æ—¶ï¼Œä»…åœ¨åŽŸå€¼ä¸ºç©ºæ—¶æ›´æ–° titleï¼›
      product_description / gender / category ä¼˜å…ˆç”¨æ–°å€¼ï¼Œå¦åˆ™ä¿ç•™æ—§å€¼ã€‚
    """
    sql = """
    INSERT INTO barbour_products
      (color_code, style_name, color, size, match_keywords,
       title, product_description, gender, category)
    VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s)
    ON CONFLICT (color_code, size) DO UPDATE SET
       title               = COALESCE(barbour_products.title,               EXCLUDED.title),
       product_description = COALESCE(EXCLUDED.product_description,         barbour_products.product_description),
       gender              = COALESCE(EXCLUDED.gender,                      barbour_products.gender),
       category            = COALESCE(EXCLUDED.category,                    barbour_products.category);
    """
    with conn.cursor() as cur:
        for r in records:
            try:
                cur.execute(sql, (
                    r.get("color_code"),
                    r.get("style_name"),
                    r.get("color"),
                    r.get("size"),
                    r.get("match_keywords"),
                    r.get("title"),
                    r.get("product_description"),
                    r.get("gender"),
                    r.get("category"),
                ))
            except Exception as e:
                # å•æ¡å¤±è´¥ï¼šæ‰“å°å‡º code/sizeï¼Œä¾¿äºŽå®šä½ï¼›è·³è¿‡æ­¤æ¡ï¼Œç»§ç»­ä¸‹ä¸€æ¡
                print(f"âŒ å…¥åº“å¤±è´¥ï¼ˆè®°å½•çº§ï¼‰: code={r.get('color_code')} size={r.get('size')} | é”™è¯¯: {e}")
                conn.rollback()  # å›žæ»šå½“å‰å¤±è´¥è¯­å¥
                continue
    conn.commit()


# -------------------- ç›®å½•å‘çŽ° & æ‰¹å¤„ç†å…¥å£ --------------------
def _discover_txt_paths() -> List[Path]:
    """
    ä¼˜å…ˆä½¿ç”¨ BARBOUR['TXT_DIRS'] ä¸‹å„ç«™ç‚¹ç›®å½•ï¼›å¦åˆ™é€€å›ž BARBOUR['TXT_DIR']ã€‚
    è¿™æ · Outdoor / Allweathers / Barbour / House of Fraser çš„ TXT éƒ½èƒ½è¢«å¯¼å…¥ã€‚
    """
    paths: List[Path] = []
    txt_dirs = BARBOUR.get("TXT_DIRS")
    if isinstance(txt_dirs, dict) and txt_dirs:
        for d in txt_dirs.values():
            p = Path(d)
            if p.exists():
                paths += sorted(p.glob("*.txt"))
    else:
        p = Path(BARBOUR["TXT_DIR"])
        if p.exists():
            paths = sorted(p.glob("*.txt"))
    return paths

# â€”â€” æ–°å¢ž/æ›¿æ¢ï¼šæŒ‰ supplier å‘çŽ° TXT æ–‡ä»¶ â€”â€”
from pathlib import Path
from typing import List, Dict
import sys

_ALIAS = {
    "oac": "outdoorandcountry",
    "outdoor": "outdoorandcountry",
    "allweather": "allweathers",
    "hof": "houseoffraser",
    "pm": "philipmorris",
}

def _discover_txt_paths_by_supplier(supplier: str) -> List[Path]:
    """
    æ ¹æ® config.BARBOUR["TXT_DIRS"] æŒ‰ä¾›åº”å•†è¿”å›ž *.txt åˆ—è¡¨ã€‚
    supplier:
      - "all"ï¼ˆé»˜è®¤ï¼‰ï¼šéåŽ†æ‰€æœ‰å·²é…ç½®ç›®å½•
      - å…·ä½“åç§°ï¼šoutdoorandcountry / allweathers / barbour / houseoffraser / philipmorris
      - æ”¯æŒå¸¸è§åˆ«åï¼šoac/outdoor, allweather, hof, pm
    """
    supplier = (supplier or "all").strip().lower()
    supplier = _ALIAS.get(supplier, supplier)

    txt_dirs: Dict[str, Path] = BARBOUR.get("TXT_DIRS", {}) or {}
    paths: List[Path] = []

    if supplier == "all":
        # éåŽ†æ‰€æœ‰ç›®å½•ï¼ˆè·³è¿‡ä¸å­˜åœ¨çš„ï¼‰
        for key, dirpath in txt_dirs.items():
            p = Path(dirpath)
            if p.exists():
                paths.extend(sorted(p.glob("*.txt")))
        # è‹¥æ²¡é… TXT_DIRSï¼Œåˆ™é€€å›žå•ç›®å½•
        if not paths and BARBOUR.get("TXT_DIR"):
            p = Path(BARBOUR["TXT_DIR"])
            if p.exists():
                paths = sorted(p.glob("*.txt"))
        return paths

    # æŒ‡å®šæŸä¸€ä¾›åº”å•†
    if supplier not in txt_dirs:
        # å…œåº•ï¼šå¦‚æžœä¼ çš„æ˜¯ "barbourå®˜ç½‘" è¿™ç±»ä¸­æ–‡ï¼Œå¯åšä¸€æ¬¡ç®€å•æ˜ å°„
        zh_map = {
            "å®˜ç½‘": "barbour",
            "barbourå®˜ç½‘": "barbour",
            "æˆ·å¤–": "outdoorandcountry",
            "å¥¥ç‰¹èŽ±æ–¯": "outdoorandcountry",
        }
        supplier = zh_map.get(supplier, supplier)

    dirpath = txt_dirs.get(supplier)
    if not dirpath:
        # å†å°è¯• "all" ç›®å½•
        dirpath = txt_dirs.get("all")

    p = Path(dirpath) if dirpath else None
    if p and p.exists():
        return sorted(p.glob("*.txt"))

    # å…¨éƒ¨å¤±è´¥ï¼šç©ºåˆ—è¡¨
    return []


# â€”â€” æ›¿æ¢ï¼šæ‰¹å¤„ç†å…¥å£ï¼Œå¢žåŠ  supplier å½¢å‚ â€”â€”
def batch_import_txt_to_barbour_product(supplier: str = "all"):
    """
    å¯¼å…¥æŒ‡å®šä¾›åº”å•†ï¼ˆæˆ–å…¨éƒ¨ï¼‰çš„ TXT åˆ° barbour_productsã€‚
    supplier:
      - "all"ï¼šå¯¼å…¥æ‰€æœ‰ BARBOUR["TXT_DIRS"] ç›®å½•
      - å…·ä½“ï¼šoutdoorandcountry / allweathers / barbour / houseoffraser / philipmorrisï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰
      - ä¹Ÿæ”¯æŒåˆ«åï¼šoac/outdoor, allweather, hof, pm
    """
    files = _discover_txt_paths_by_supplier(supplier)
    if not files:
        print(f"âš ï¸ æœªæ‰¾åˆ°ä»»ä½• TXT æ–‡ä»¶ï¼ˆsupplier='{supplier}'ï¼‰ã€‚è¯·æ£€æŸ¥ BARBOUR['TXT_DIRS'] é…ç½®æˆ–ç›®å½•æ˜¯å¦å­˜åœ¨ã€‚")
        return

    # å¤ç”¨ä½ å·²æœ‰çš„ DB è¿žæŽ¥å’Œå…¥åº“å‡½æ•°
    import psycopg2
    from config import PGSQL_CONFIG

    conn = psycopg2.connect(**PGSQL_CONFIG)

    total_rows = 0
    parsed_files = 0

    for file in files:
        try:
            records = parse_txt_file(file)
            if not records:
                print(f"â“˜ è·³è¿‡ï¼ˆæ— è®°å½•ï¼‰: {file.name}")
                continue

            insert_into_products(records, conn)  # â¬…ï¸ é‡Œé¢ä¼šå†åšé€è¡Œä¿æŠ¤
            print(f"âœ… å¯¼å…¥ {file.name} â€” {len(records)} æ¡")
            total_rows += len(records)
            parsed_files += 1

        except Exception as e:
            # å…³é”®ï¼šå•æ–‡ä»¶å¤±è´¥ä¸é˜»æ–­åŽç»­ï¼›å›žæ»šå†ç»§ç»­ä¸‹ä¸€ä¸ª
            conn.rollback()
            print(f"âŒ å¯¼å…¥å¤±è´¥ï¼ˆæ–‡ä»¶çº§ï¼‰: {file.name} | é”™è¯¯: {e}")
            continue


    conn.close()
    print(f"\nðŸŽ‰ å¯¼å…¥å®Œæˆï¼ˆsupplier='{supplier}'ï¼‰ï¼š{parsed_files} ä¸ªæ–‡ä»¶ï¼Œå…± {total_rows} æ¡è®°å½•")


# â€”â€” å¯é€‰ï¼šå‘½ä»¤è¡Œè°ƒç”¨ï¼ˆä¸ç ´ååŽŸç”¨æ³•ï¼‰ â€”â€”
if __name__ == "__main__":
    # æ”¯æŒï¼špython barbour_import_to_barbour_products.py
    #      python barbour_import_to_barbour_products.py outdoorandcountry
    #      python barbour_import_to_barbour_products.py hof
    arg = sys.argv[1] if len(sys.argv) > 1 else "all"
    batch_import_txt_to_barbour_product(arg)
