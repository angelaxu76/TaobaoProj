import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from bs4 import BeautifulSoup
from pathlib import Path
import time
from config import BARBOUR

# âœ… é…ç½®
TARGET_URL = "https://www.outdoorandcountry.co.uk/shop-by-brand/barbour/barbour-menswear/all-barbour-mens-clothing-footwear.sub"
BASE_DOMAIN = "https://www.outdoorandcountry.co.uk"
OUTPUT_FILE = BARBOUR["LINKS_FILES"]["outdoorandcountry"]
DEBUG_DIR = OUTPUT_FILE.parent / "debug_pages"
DEBUG_FILE = DEBUG_DIR / "debug_manual_scroll_uc.html"

def collect_links_from_html(html):
    soup = BeautifulSoup(html, "html.parser")
    links = set()
    for a in soup.select("a.image"):
        href = a.get("href", "").strip()
        if href:
            full_url = href if href.startswith("http") else BASE_DOMAIN + href
            links.add(full_url)
    return links

def outdoorandcountry_fetch_and_save_links():
    DEBUG_DIR.mkdir(parents=True, exist_ok=True)
    OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)

    # âœ… å¯åŠ¨ undetected Chrome
    options = uc.ChromeOptions()
    options.add_argument("--start-maximized")

    driver = uc.Chrome(options=options, headless=False)
    print(f"ğŸš€ æ­£åœ¨æ‰“å¼€é¡µé¢: {TARGET_URL}")
    driver.get(TARGET_URL)
    time.sleep(8)  # ç­‰å¾…é¡µé¢ JS åˆå§‹åŒ–

    print("\nğŸŸ¡ è¯·æ‰‹åŠ¨æ“ä½œï¼š")
    print("1ï¸âƒ£ æ¥å— Cookieï¼ˆå¦‚æç¤ºï¼‰")
    print("2ï¸âƒ£ å‘ä¸‹æ»šåŠ¨æˆ–ç‚¹å‡»æŒ‰é’®ï¼Œç›´åˆ°æ‰€æœ‰å•†å“åŠ è½½å®Œæ¯•")
    print("ğŸ”„ ç„¶åå›åˆ°æ§åˆ¶å°ï¼ŒæŒ‰å›è½¦ç»§ç»­")
    input("â¸ï¸ ç­‰ä½ å‡†å¤‡å¥½åï¼ŒæŒ‰å›è½¦ç»§ç»­æå–å•†å“é“¾æ¥ >>> ")

    html = driver.page_source
    links = collect_links_from_html(html)

    with OUTPUT_FILE.open("w", encoding="utf-8") as f:
        for link in sorted(links):
            f.write(link + "\n")

    with DEBUG_FILE.open("w", encoding="utf-8") as f:
        f.write(html)

    print(f"\nâœ… å…±æå–å•†å“é“¾æ¥: {len(links)} æ¡")
    print(f"ğŸ“„ é“¾æ¥å†™å…¥: {OUTPUT_FILE}")
    print(f"ğŸ“ é¡µé¢å¿«ç…§ä¿å­˜: {DEBUG_FILE}")
    driver.quit()

