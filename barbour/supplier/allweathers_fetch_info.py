# barbour/supplier/allweathers_fetch_info.py

import os
import re
import time
import json
import demjson3
import tempfile
from bs4 import BeautifulSoup
from config import BARBOUR
from pathlib import Path
from datetime import datetime
from selenium import webdriver

# è®© selenium-stealth å¯é€‰ï¼ˆæ²¡è£…ä¹Ÿèƒ½è·‘ï¼‰
try:
    from selenium_stealth import stealth
except ImportError:
    def stealth(*args, **kwargs):
        return

from barbour.barbouir_write_offer_txt import write_supplier_offer_txt
from concurrent.futures import ThreadPoolExecutor, as_completed

# å…¨å±€è·¯å¾„
LINK_FILE = BARBOUR["LINKS_FILES"]["allweathers"]
TXT_DIR = BARBOUR["TXT_DIRS"]["allweathers"]
TXT_DIR.mkdir(parents=True, exist_ok=True)

# çº¿ç¨‹æ•°
MAX_WORKERS = 6


def get_driver():
    temp_profile = tempfile.mkdtemp()
    options = webdriver.ChromeOptions()
    options.add_argument("--headless=new")
    options.add_argument(f"--user-data-dir={temp_profile}")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-gpu")
    options.add_argument("--window-size=1920,1080")
    # ä½ å¯æŒ‰éœ€æ·»åŠ ä»£ç†/UA ç­‰

    driver = webdriver.Chrome(options=options)

    # å¯é€‰ stealth
    stealth(
        driver,
        languages=["en-US", "en"],
        vendor="Google Inc.",
        platform="Win32",
        webgl_vendor="Intel Inc.",
        renderer="Intel Iris OpenGL Engine",
        fix_hairline=True,
    )
    return driver


# ============ æŠ½å–è¾…åŠ©å‡½æ•° ============

def _clean_text(s: str) -> str:
    return re.sub(r"\s+", " ", (s or "").strip())

def _infer_gender_from_title(title_or_name: str) -> str:
    t = (title_or_name or "").lower()
    if re.search(r"\b(women|woman|women's|ladies)\b", t):
        return "å¥³æ¬¾"
    if re.search(r"\b(men|men's|man)\b", t):
        return "ç”·æ¬¾"
    if re.search(r"\b(kids?|boys?|girls?)\b", t):
        return "ç«¥æ¬¾"
    return "æœªçŸ¥"

def _extract_name_and_color(soup: BeautifulSoup) -> tuple[str, str]:
    # ä¼˜å…ˆ og:titleï¼šå½¢å¦‚ "Barbour Acorn Women's Waxed Jacket | Olive"
    og = soup.find("meta", {"property": "og:title"})
    if og and og.get("content"):
        txt = og["content"].strip()
        if "|" in txt:
            name, color = map(str.strip, txt.split("|", 1))
            return name, color
        return txt, "Unknown"

    # å…¶æ¬¡ document.title
    if soup.title and soup.title.string:
        t = soup.title.string.strip()
        t = t.split("|", 1)[0].strip()
        if "â€“" in t:
            name, color = map(str.strip, t.split("â€“", 1))
            return name, color
        return t, "Unknown"

    return "Unknown", "Unknown"

def _extract_description(soup: BeautifulSoup) -> str:
    # 1) twitter:description
    m = soup.find("meta", attrs={"name": "twitter:description"})
    if m and m.get("content"):
        desc = _clean_text(m["content"])
        # å»æ‰å…¶ä¸­çš„ â€œKey Features â€¦â€ ç­‰å°¾æ³¨
        desc = re.split(r"(Key\s*Features|Materials\s*&\s*Technical)", desc, flags=re.I)[0].strip(" -â€“|,")
        return desc

    # 2) og:description
    m = soup.find("meta", attrs={"property": "og:description"})
    if m and m.get("content"):
        desc = _clean_text(m["content"])
        return desc

    # 3) JSON-LD ProductGroup.description
    for s in soup.find_all("script", {"type": "application/ld+json"}):
        try:
            j = demjson3.decode(s.string)
        except Exception:
            continue
        if isinstance(j, dict) and j.get("@type") in ("ProductGroup", "Product"):
            desc = _clean_text(j.get("description") or "")
            if desc:
                # æˆªåˆ° â€œKey Featuresâ€ ä¹‹å‰
                desc = re.split(r"(Key\s*Features|Materials\s*&\s*Technical)", desc, flags=re.I)[0].strip(" -â€“|,")
                return desc
    return "No Data"

def _extract_features(soup: BeautifulSoup) -> str:
    # å¯»æ‰¾ â€œKey Features & Benefitsâ€ æ ‡é¢˜åçš„åˆ—è¡¨
    h = soup.find(["h2", "h3"], string=re.compile(r"Key\s*Features", re.I))
    if h:
        ul = h.find_next("ul")
        if ul:
            items = []
            for li in ul.find_all("li"):
                txt = _clean_text(li.get_text(" ", strip=True))
                if txt:
                    items.append(txt)
            if items:
                return " | ".join(items)

    # é€€å› JSON-LD description é‡Œâ€œKey Features â€¦\n...ï¼ˆåˆ° Materials ä¹‹å‰ï¼‰â€
    for s in soup.find_all("script", {"type": "application/ld+json"}):
        try:
            j = demjson3.decode(s.string)
        except Exception:
            continue
        if isinstance(j, dict) and j.get("@type") in ("ProductGroup", "Product"):
            desc = j.get("description") or ""
            if "Key" in desc:
                # æŠ“ Key Features å—
                m = re.search(
                    r"Key\s*Features.*?:\s*(.+?)\s*(Materials\s*&\s*Technical|Frequently|$)",
                    desc, flags=re.I | re.S
                )
                if m:
                    block = m.group(1)
                    # æŒ‰æ¢è¡Œ/é¡¹ç›®ç‚¹åˆ‡åˆ†
                    parts = [ _clean_text(p) for p in re.split(r"[\r\n]+|â€¢|- ", block) ]
                    parts = [p for p in parts if p]
                    if parts:
                        return " | ".join(parts)
    return "No Data"

def _extract_material_outer(soup: BeautifulSoup) -> str:
    # é¡µé¢ H2 â€œMaterials & Technical Specificationsâ€ åˆ—è¡¨ä¸­çš„ Outer
    h = soup.find(["h2", "h3"], string=re.compile(r"Materials\s*&\s*Technical", re.I))
    if h:
        ul = h.find_next("ul")
        if ul:
            for li in ul.find_all("li"):
                txt = _clean_text(li.get_text(" ", strip=True))
                m = re.match(r"Outer:\s*(.+)", txt, flags=re.I)
                if m:
                    return m.group(1)

    # é€€å› JSON-LD description
    for s in soup.find_all("script", {"type": "application/ld+json"}):
        try:
            j = demjson3.decode(s.string)
        except Exception:
            continue
        if isinstance(j, dict) and j.get("@type") in ("ProductGroup", "Product"):
            desc = j.get("description") or ""
            m = re.search(r"Outer:\s*(.+)", desc, flags=re.I)
            if m:
                outer_line = _clean_text(m.group(1))
                # æˆªæ–­åˆ°è¡Œå°¾æˆ–åˆ†å·/æ¢è¡Œ
                outer_line = re.split(r"[\r\n;]+", outer_line)[0].strip()
                return outer_line
    return "No Data"

def _extract_price(soup: BeautifulSoup) -> float | None:
    # é¡µé¢ metaï¼ˆShopifyï¼‰ä»·æ ¼
    m = soup.find("meta", {"property": "product:price:amount"})
    if m and m.get("content"):
        try:
            return float(m["content"])
        except Exception:
            pass
    return None


def parse_detail_page(html, url):
    soup = BeautifulSoup(html, "html.parser")

    # åç§° & é¢œè‰²
    name, color = _extract_name_and_color(soup)

    # JSON-LDï¼ˆShopify ProductGroupï¼‰
    script = soup.find("script", {"type": "application/ld+json"})
    if not script:
        raise ValueError("æœªæ‰¾åˆ° JSON-LD æ•°æ®æ®µ")

    data = demjson3.decode(script.string)
    variants = data.get("hasVariant", []) if isinstance(data, dict) else []
    if not variants:
        raise ValueError("âŒ æœªæ‰¾åˆ°å°ºç å˜ä½“")

    # å•†å“ç¼–ç ï¼ˆè‰²ç å«åœ¨ç¼–ç æœ«å°¾ï¼‰ï¼šå¦‚ LWX0752OL51-16 â†’ LWX0752OL51
    first_sku = (variants[0].get("sku") or "")
    base_sku = first_sku.split("-")[0] if first_sku else "Unknown"

    # å°ºç /ä»·æ ¼/åº“å­˜
    offer_list = []
    for item in variants:
        sku = item.get("sku", "")
        offer = item.get("offers") or {}
        try:
            price = float(offer.get("price", 0.0))
        except Exception:
            price = 0.0
        availability = offer.get("availability", "")
        stock_status = "æœ‰è´§" if "InStock" in availability else "æ— è´§"
        can_order = (stock_status == "æœ‰è´§")
        # UK å°ºç åœ¨ sku å°¾éƒ¨ï¼šLWX0752OL51-16 â†’ UK 16
        size_tail = sku.split("-")[-1] if "-" in sku else "Unknown"
        size = f"UK {re.sub(r'\\s+', ' ', size_tail)}"
        offer_list.append((size, price, stock_status, can_order))

    # æ€§åˆ«/æè¿°/ç‰¹æ€§/æè´¨/ä»·æ ¼
    gender = _infer_gender_from_title(name)
    description = _extract_description(soup)
    features = _extract_features(soup)
    material_outer = _extract_material_outer(soup)
    price_header = _extract_price(soup)

    info = {
        "Product Name": name,
        "Product Gender": gender,
        "Product Description": description,
        "Feature": features,
        "Product Material": material_outer,         # åªå†™ Outer
        "Product Color": color,
        "Product Color Code": base_sku,
        "Product Price": price_header,              # é¡µå¤´ä»·ï¼ˆå¯èƒ½ç­‰äºå„å°ºç ä»·ï¼‰
        "Site Name": "Allweathers",
        "Product URL": url,
        "Source URL": url,                          # å…¼å®¹å†™å…¥å™¨
        "Offers": offer_list
    }
    return info


def fetch_one_product(url, idx, total):
    print(f"[{idx}/{total}] æŠ“å–: {url}")
    try:
        driver = get_driver()
        driver.get(url)
        time.sleep(2.5)
        html = driver.page_source
        driver.quit()

        data = parse_detail_page(html, url)
        code = data["Product Color Code"] or "Unknown"
        txt_path = TXT_DIR / f"{code}.txt"   # æ–‡ä»¶å = å•†å“ç¼–ç 
        write_supplier_offer_txt(data, txt_path)
        return (url, "âœ… æˆåŠŸ")
    except Exception as e:
        return (url, f"âŒ å¤±è´¥: {e}")


def fetch_allweathers_products(max_workers=MAX_WORKERS):
    print(f"ğŸš€ å¯åŠ¨ Allweathers å¤šçº¿ç¨‹å•†å“è¯¦æƒ…æŠ“å–ï¼ˆçº¿ç¨‹æ•°: {max_workers}ï¼‰")
    links = LINK_FILE.read_text(encoding="utf-8").splitlines()
    links = [u.strip() for u in links if u.strip()]
    total = len(links)

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = [
            executor.submit(fetch_one_product, url, idx + 1, total)
            for idx, url in enumerate(links)
        ]
        for future in as_completed(futures):
            url, status = future.result()
            print(f"{status} - {url}")

    print("\nâœ… æ‰€æœ‰å•†å“æŠ“å–å®Œæˆ")


if __name__ == "__main__":
    fetch_allweathers_products()
