# barbour/supplier/allweathers_fetch_info.py

import os
import re
import time
import json
import demjson3
import tempfile
from bs4 import BeautifulSoup
from config import BARBOUR
from pathlib import Path
from datetime import datetime
from selenium import webdriver
from selenium_stealth import stealth
from barbour.barbouir_write_offer_txt import write_supplier_offer_txt
from concurrent.futures import ThreadPoolExecutor, as_completed

# å…¨å±€è·¯å¾„
LINK_FILE = BARBOUR["LINKS_FILES"]["allweathers"]
TXT_DIR = BARBOUR["TXT_DIRS"]["allweathers"]
TXT_DIR.mkdir(parents=True, exist_ok=True)

# çº¿ç¨‹æ•°
MAX_WORKERS = 6


def get_driver():
    temp_profile = tempfile.mkdtemp()
    options = webdriver.ChromeOptions()
    options.add_argument("--headless=new")  # âœ… é™é»˜æ¨¡å¼ä¸å¼¹çª—
    options.add_argument(f"--user-data-dir={temp_profile}")  # âœ… æ¯çº¿ç¨‹ç‹¬ç«‹é…ç½®
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-gpu")
    options.add_argument("--window-size=1920,1080")

    driver = webdriver.Chrome(options=options)

    stealth(driver,
        languages=["en-US", "en"],
        vendor="Google Inc.",
        platform="Win32",
        webgl_vendor="Intel Inc.",
        renderer="Intel Iris OpenGL Engine",
        fix_hairline=True,
    )
    return driver


def parse_detail_page(html, url):
    soup = BeautifulSoup(html, "html.parser")

    # âœ… ä» meta og:title æå–é¢œè‰²
    og_title = soup.find("meta", property="og:title")
    if og_title and og_title.get("content"):
        og_text = og_title["content"].strip()
        if "|" in og_text:
            name, color = map(str.strip, og_text.split("|"))
        else:
            name, color = og_text.strip(), "Unknown"
    else:
        title = soup.title.text.strip()
        clean_title = title.split("|")[0].strip()
        if "â€“" in clean_title:
            name, color = map(str.strip, clean_title.split("â€“"))
        else:
            name, color = clean_title, "Unknown"

    script = soup.find("script", {"type": "application/ld+json"})
    if not script:
        raise ValueError("æœªæ‰¾åˆ° JSON æ•°æ®æ®µ")

    data = demjson3.decode(script.string)
    variants = data.get("hasVariant", [])
    if not variants:
        raise ValueError("âŒ æœªæ‰¾åˆ°å°ºç å˜ä½“")

    offer_list = []
    base_sku = variants[0]["sku"].split("-")[0]

    for item in variants:
        sku = item.get("sku", "")
        price = float(item["offers"].get("price", 0.0))
        availability = item["offers"].get("availability", "")
        stock_status = "æœ‰è´§" if "InStock" in availability else "æ— è´§"
        can_order = stock_status == "æœ‰è´§"
        size = f"UK {sku.split('-')[-1]}" if "-" in sku else "Unknown"
        offer_list.append((size, price, stock_status, can_order))

    return {
        "Product Name": name,
        "Product Color": color,
        "Product Color Code": base_sku,
        "Site Name": "Allweathers",
        "Product URL": url,
        "Offers": offer_list
    }


def fetch_one_product(url, idx, total):
    print(f"[{idx}/{total}] æŠ“å–: {url}")
    try:
        driver = get_driver()
        driver.get(url)
        time.sleep(2.5)
        html = driver.page_source
        driver.quit()

        data = parse_detail_page(html, url)
        code = data["Product Color Code"]
        txt_path = TXT_DIR / f"{code}.txt"
        write_supplier_offer_txt(data, txt_path)
        return (url, "âœ… æˆåŠŸ")
    except Exception as e:
        return (url, f"âŒ å¤±è´¥: {e}")


def fetch_allweathers_products(max_workers=MAX_WORKERS):
    print(f"ğŸš€ å¯åŠ¨ Allweathers å¤šçº¿ç¨‹å•†å“è¯¦æƒ…æŠ“å–ï¼ˆçº¿ç¨‹æ•°: {max_workers}ï¼‰")
    links = LINK_FILE.read_text(encoding="utf-8").splitlines()
    total = len(links)

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = [
            executor.submit(fetch_one_product, url, idx + 1, total)
            for idx, url in enumerate(links)
        ]
        for future in as_completed(futures):
            url, status = future.result()
            print(f"{status} - {url}")

    print("\nâœ… æ‰€æœ‰å•†å“æŠ“å–å®Œæˆ")


if __name__ == "__main__":
    fetch_allweathers_products()
