# barbour/supplier/houseoffraser_fetch_info.py
# -*- coding: utf-8 -*-
"""
House of Fraser | Barbour
- æŠ“å–é€»è¾‘ä¿æŒä¸å˜ï¼ˆparse_product_page â†’ Offer Listï¼‰
- pipeline æ–¹æ³•åä¿æŒä¸å˜ï¼šprocess_link(url), fetch_all()
- ç»Ÿä¸€ç”¨ txt_writer.format_txt å†™å‡ºâ€œåŒä¸€æ¨¡æ¿â€çš„ TXT
- æœ¬ç«™æ— å•†å“ç¼–ç  => Product Code å›ºå®šå†™ "No Data"
- å°ºç ï¼šç”± Offer List ç”Ÿæˆ Product Size / Product Size Detailï¼ˆä¸å†™ SizeMapï¼‰
- å¥³ï¼š4â€“20ï¼ˆå¶æ•°ï¼‰ï¼›ç”·ï¼š30â€“50ï¼ˆå¶æ•°ï¼‰ï¼›ä¸å†™ 52
"""

import time
from pathlib import Path
import re
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed

import undetected_chromedriver as uc
from bs4 import BeautifulSoup

from config import BARBOUR

# âœ… ç»Ÿä¸€å†™å…¥ï¼šä½¿ç”¨é¡¹ç›®é‡Œçš„ txt_writerï¼ˆä¸å…¶å®ƒç«™ç‚¹åŒæ¨¡æ¿ï¼‰
from common_taobao.txt_writer import format_txt

LINKS_FILE = BARBOUR["LINKS_FILES"]["houseoffraser"]
TXT_DIR = BARBOUR["TXT_DIRS"]["houseoffraser"]
TXT_DIR.mkdir(parents=True, exist_ok=True)
SITE_NAME = "House of Fraser"


# ---------------- æµè§ˆå™¨ ----------------

def get_driver():
    options = uc.ChromeOptions()
    # å¦‚éœ€é™é»˜è¿è¡Œå¯æ‰“å¼€ï¼š
    # options.add_argument("--headless=new")
    options.add_argument("--disable-gpu")
    options.add_argument("--window-size=1920,1080")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-blink-features=AutomationControlled")
    return uc.Chrome(options=options, use_subprocess=True)


# ---------------- é¡µé¢è§£æï¼ˆä¿æŒä½ ç°æœ‰é€»è¾‘ï¼‰ ----------------

def parse_product_page(html: str, url: str):
    """
    åŸæœ‰è§£æï¼šè¿”å› {Product Name, Product Color, Site Name, Product URL, Offer List, Updated At}
    Offer List å…ƒç´ å½¢å¦‚: "size|price|stock_status|True"
    """
    soup = BeautifulSoup(html, "html.parser")

    # æ ‡é¢˜ï¼šä¸€èˆ¬æ˜¯ "House of Fraser | <Product Name> | ..."
    title = (soup.title.text or "").strip() if soup.title else ""
    product_name = title.split("|")[1].strip() if "|" in title else title

    # ä»·æ ¼
    price_tag = soup.find("span", id="lblSellingPrice")
    price = price_tag.text.replace("\xa3", "").strip() if price_tag else "0.00"

    # é¢œè‰²
    color_tag = soup.find("span", id="colourName")
    raw_color = color_tag.text.strip() if color_tag else "No Color"
    color = clean_color(raw_color)

    # å°ºç åˆ—è¡¨
    offer_list = []
    size_select = soup.find("select", id="sizeDdl")
    if size_select:
        for option in size_select.find_all("option"):
            size = option.text.strip()
            if not size or "Select Size" in size:
                continue
            stock_qty = option.get("data-stock-qty", "0")
            stock_status = "æœ‰è´§" if stock_qty and stock_qty != "0" else "æ— è´§"
            cleaned_size = clean_size(size)
            # ä»ä¿æŒä½ åŸæ¥çš„ Offer List å­—ç¬¦ä¸²æ ¼å¼
            offer_list.append(f"{cleaned_size}|{price}|{stock_status}|True")

    return {
        "Product Name": product_name,
        "Product Color": color,
        "Site Name": SITE_NAME,
        "Product URL": url,
        "Offer List": offer_list,
        "Updated At": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }


# ---------------- æ¸…æ´—å·¥å…· ----------------

def clean_size(size: str) -> str:
    return size.split("(")[0].strip()

def clean_color(color: str) -> str:
    txt = (color or "").strip()
    txt = re.sub(r"\([^)]*\)", "", txt)          # å»æ‹¬å·æ³¨é‡Š
    txt = re.sub(r"[^\w\s/+-]", " ", txt)        # å»å¥‡æ€ªç¬¦å·
    txt = re.sub(r"\s+", " ", txt).strip()
    # å»æ‰å«æ•°å­—çš„è¯
    parts = [p for p in txt.split() if not any(c.isdigit() for c in p)]
    base = " ".join(parts) if parts else txt
    return base.strip()

def safe_filename(name: str) -> str:
    return "".join(c for c in name if c.isalnum() or c in (" ", "-", "_")).rstrip()

# ------- å°ºç æ ‡å‡†åŒ–ï¼ˆä¸å…¶å®ƒç«™ç‚¹åŒè§„åˆ™ï¼›ä¸å†™ 52ï¼‰ -------

WOMEN_ORDER = ["4","6","8","10","12","14","16","18","20"]
MEN_ALPHA_ORDER = ["2XS","XS","S","M","L","XL","2XL","3XL"]
MEN_NUM_ORDER = [str(n) for n in range(30, 52, 2)]  # 30..50ï¼ˆä¸å« 52ï¼‰

ALPHA_MAP = {
    "XXXS": "2XS", "2XS": "2XS",
    "XXS": "XS", "XS": "XS",
    "S": "S", "SMALL": "S",
    "M": "M", "MEDIUM": "M",
    "L": "L", "LARGE": "L",
    "XL": "XL", "X-LARGE": "XL",
    "XXL": "2XL", "2XL": "2XL",
    "XXXL": "3XL", "3XL": "3XL",
}

def _infer_gender_from_name(name: str) -> str:
    n = (name or "").lower()
    if any(k in n for k in ["women", "women's", "womens", "ladies", "lady"]):
        return "å¥³æ¬¾"
    if any(k in n for k in ["men", "men's", "mens"]):
        return "ç”·æ¬¾"
    return "ç”·æ¬¾"  # å…œåº•

def _normalize_size(token: str, gender: str) -> str | None:
    s = (token or "").strip().upper()
    s = s.replace("UK ", "").replace("EU ", "").replace("US ", "")
    s = re.sub(r"\s*\(.*?\)\s*", "", s)
    s = re.sub(r"\s+", " ", s)
    # å…ˆæ•°å­—
    m = re.findall(r"\d{1,3}", s)
    if m:
        n = int(m[0])
        if gender == "å¥³æ¬¾" and n in {4,6,8,10,12,14,16,18,20}:
            return str(n)
        if gender == "ç”·æ¬¾":
            if 30 <= n <= 50 and n % 2 == 0:
                return str(n)
            if 28 <= n <= 54:  # å°±è¿‘å®¹é”™åˆ° 30..50 å¶æ•°
                cand = n if n % 2 == 0 else n-1
                cand = max(30, min(50, cand))
                return str(cand)
        return None
    # å†å­—æ¯
    key = s.replace("-", "").replace(" ", "")
    return ALPHA_MAP.get(key)

def _sort_sizes(keys: list[str], gender: str) -> list[str]:
    if gender == "å¥³æ¬¾":
        return [k for k in WOMEN_ORDER if k in keys]
    return [k for k in MEN_ALPHA_ORDER if k in keys] + [k for k in MEN_NUM_ORDER if k in keys]

def offers_to_size_lines(offer_list: list[str], gender: str) -> tuple[str, str]:
    """
    Offer Listï¼ˆ'size|price|stock|bool'ï¼‰â†’
      Product Size: "6:æœ‰è´§;8:æœ‰è´§;..."
      Product Size Detail: "6:1:0000000000000;8:1:0000000000000;..."
    åŒå°ºç å‡ºç°å¤šæ¬¡æ—¶â€œæœ‰è´§â€ä¼˜å…ˆï¼›ä¸è¾“å‡º SizeMapã€‚
    """
    status = {}
    count = {}
    for row in offer_list or []:
        parts = [p.strip() for p in row.split("|")]
        if len(parts) < 3:
            continue
        raw_size, _price, stock_status = parts[0], parts[1], parts[2]
        norm = _normalize_size(raw_size, gender)
        if not norm:
            continue
        curr = "æœ‰è´§" if stock_status == "æœ‰è´§" else "æ— è´§"
        prev = status.get(norm)
        if prev is None or (prev == "æ— è´§" and curr == "æœ‰è´§"):
            status[norm] = curr
            count[norm] = 1 if curr == "æœ‰è´§" else 0

    ordered = _sort_sizes(list(status.keys()), gender)
    ps  = ";".join(f"{k}:{status[k]}" for k in ordered)
    psd = ";".join(f"{k}:{count[k]}:0000000000000" for k in ordered)
    return ps, psd


# ---------------- å†™å…¥ TXTï¼ˆç»Ÿä¸€æ¨¡æ¿ï¼‰ ----------------

def process_link(url):
    driver = get_driver()
    try:
        driver.get(url)
        time.sleep(6)
        html = driver.page_source

        # ä¿æŒåŸæœ‰è§£æé€»è¾‘
        parsed = parse_product_page(html, url)

        # â€”â€” æ„é€ ç»Ÿä¸€ infoï¼ˆä¸ä¾èµ–å•†å“ç¼–ç ï¼›Product Code å›ºå®š No Dataï¼‰â€”â€”
        gender = _infer_gender_from_name(parsed.get("Product Name", ""))
        ps, psd = offers_to_size_lines(parsed.get("Offer List", []), gender)

        info = {
            "Product Code": "No Data",                # æœ¬ç«™æ— ç¼–ç  â†’ å›ºå®š No Data
            "Product Name": parsed.get("Product Name", "No Data"),
            "Product Description": "No Data",
            "Product Gender": gender,
            "Product Color": parsed.get("Product Color", "No Data"),
            "Product Price": None,
            "Adjusted Price": None,
            "Product Material": "No Data",
            "Style Category": "",                     # äº¤ç»™ txt_writer æ¨æ–­
            "Feature": "No Data",
            "Product Size": ps,                       # ä¸¤è¡Œå°ºç ï¼ˆä¸å†™ SizeMapï¼‰
            "Product Size Detail": psd,
            "Site Name": SITE_NAME,
            "Source URL": parsed.get("Product URL", url),
            "Brand": "Barbour",
        }

        # æ–‡ä»¶åï¼šæœ¬ç«™æ— ç¼–ç  â†’ ç”¨ åç§°_é¢œè‰²
        safe_name  = safe_filename(info["Product Name"])
        safe_color = safe_filename(info["Product Color"])
        filename = f"{safe_name}_{safe_color}.txt"
        txt_path = TXT_DIR / filename

        # âœ… ç»Ÿä¸€æ¨¡æ¿å†™å…¥
        format_txt(info, txt_path, brand="Barbour")
        print(f"âœ… å·²å†™å…¥: {txt_path.name}")

    except Exception as e:
        print(f"âŒ æŠ“å–å¤±è´¥: {url}\n{e}\n")
    finally:
        driver.quit()


def fetch_all():
    links = [u.strip() for u in LINKS_FILE.read_text(encoding="utf-8").splitlines() if u.strip()]
    print(f"ğŸš€ å…±éœ€æŠ“å– {len(links)} ä¸ªå•†å“é“¾æ¥\n")

    with ThreadPoolExecutor(max_workers=4) as executor:
        futures = [executor.submit(process_link, url) for url in links]
        for future in as_completed(futures):
            _ = future.result()


if __name__ == "__main__":
    fetch_all()
