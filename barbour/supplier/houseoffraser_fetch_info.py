# barbour/supplier/houseoffraser_fetch_info.py
# -*- coding: utf-8 -*-
"""
æŠ“å– House of Fraser çš„ Barbour å•†å“ï¼Œè§£æåç§°/é¢œè‰²/å°ºç åº“å­˜ï¼Œ
å¹¶è°ƒç”¨é€šç”¨åŒ¹é…å™¨ barbour.match_resolver è§£æå”¯ä¸€ color_codeã€‚
æˆåŠŸåˆ™ç”¨ color_code å‘½å TXT æ–‡ä»¶ï¼›å¦åˆ™æ‰“å°å€™é€‰æ—¥å¿—å¹¶å›é€€ã€‚
"""

import time
from pathlib import Path
import re
import psycopg2
import undetected_chromedriver as uc
from bs4 import BeautifulSoup
from datetime import datetime
from config import BARBOUR
from concurrent.futures import ThreadPoolExecutor, as_completed

# â˜… æ–°å¢ï¼šå¼•å…¥é€šç”¨åŒ¹é…å™¨
from barbour.match_resolver import resolve_color_code, debug_log

# ---------------- åŸºæœ¬é…ç½® ----------------

LINKS_FILE = BARBOUR["LINKS_FILES"]["houseoffraser"]
TXT_DIR = BARBOUR["TXT_DIRS"]["houseoffraser"]
TXT_DIR.mkdir(parents=True, exist_ok=True)
SITE_NAME = "House of Fraser"


# ---------------- æµè§ˆå™¨ ----------------

def get_driver():
    options = uc.ChromeOptions()
    # options.add_argument("--headless=new")  # å¦‚éœ€é™é»˜è¿è¡Œå–æ¶ˆæ³¨é‡Š
    options.add_argument("--disable-gpu")
    options.add_argument("--window-size=1920,1080")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-blink-features=AutomationControlled")
    return uc.Chrome(options=options, use_subprocess=True)


# ---------------- é¡µé¢è§£æ ----------------

def parse_product_page(html: str, url: str):
    soup = BeautifulSoup(html, "html.parser")

    # æ ‡é¢˜ï¼šä¸€èˆ¬æ˜¯ "House of Fraser | <Product Name> | ..."
    title = (soup.title.text or "").strip() if soup.title else ""
    product_name = title.split("|")[1].strip() if "|" in title else title

    # ä»·æ ¼
    price_tag = soup.find("span", id="lblSellingPrice")
    price = price_tag.text.replace("\xa3", "").strip() if price_tag else "0.00"

    # é¢œè‰²
    color_tag = soup.find("span", id="colourName")
    raw_color = color_tag.text.strip() if color_tag else "No Color"
    color = clean_color(raw_color)

    # å°ºç åˆ—è¡¨
    offer_list = []
    size_select = soup.find("select", id="sizeDdl")
    if size_select:
        for option in size_select.find_all("option"):
            size = option.text.strip()
            if not size or "Select Size" in size:
                continue
            stock_qty = option.get("data-stock-qty", "0")
            stock_status = "æœ‰è´§" if stock_qty and stock_qty != "0" else "æ— è´§"
            cleaned_size = clean_size(size)
            # ä½ åŸæœ‰æ ¼å¼ï¼šsize|price|stock_status|True
            offer_list.append(f"{cleaned_size}|{price}|{stock_status}|True")

    return {
        "Product Name": product_name,
        "Product Color": color,
        "Site Name": SITE_NAME,
        "Product URL": url,
        "Offer List": offer_list,
        "Updated At": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }


# ---------------- æ¸…æ´—å·¥å…· ----------------

def clean_size(size: str) -> str:
    return size.split("(")[0].strip()

def clean_color(color: str) -> str:
    """å»æ‰æ‹¬å·/æ•°å­—ç­‰å™ªéŸ³ï¼ŒåšåŸºæœ¬æ¸…æ´—"""
    txt = (color or "").strip()
    txt = re.sub(r"\([^)]*\)", "", txt)          # å»æ‹¬å·æ³¨é‡Š
    txt = re.sub(r"[^\w\s/+-]", " ", txt)        # å»å¥‡æ€ªç¬¦å·
    txt = re.sub(r"\s+", " ", txt).strip()
    # å»æ‰å«æ•°å­—çš„è¯
    parts = [p for p in txt.split() if not any(c.isdigit() for c in p)]
    base = " ".join(parts) if parts else txt
    return base.strip()

def safe_filename(name: str) -> str:
    return "".join(c for c in name if c.isalnum() or c in (" ", "-", "_")).rstrip()


# ---------------- å†™å…¥ TXT ----------------

def write_txt(info: dict):
    """
    è‹¥ info å« Product Color Codeï¼Œåˆ™ç”¨å…¶å‘½åæ–‡ä»¶ï¼›å¦åˆ™é€€å›åˆ° åç§°+é¢œè‰²ã€‚
    æ–‡ä»¶å†…å®¹åŒ…å« Product Color Code è¡Œï¼Œä¾¿äºåç»­å¯¼å…¥ offersã€‚
    """
    code = info.get("Product Color Code")
    if code:
        filename = f"{code}.txt"
    else:
        filename = safe_filename(f"{info['Product Name']} {info['Product Color']}") + ".txt"

    path = TXT_DIR / filename
    with open(path, "w", encoding="utf-8") as f:
        f.write(f"Product Name: {info['Product Name']}\n")
        f.write(f"Product Color: {info['Product Color']}\n")
        f.write(f"Product Color Code: {code if code else 'No Data'}\n")
        f.write(f"Site Name: {info['Site Name']}\n")
        f.write(f"Product URL: {info['Product URL']}\n")
        f.write("Offer List:\n")
        for offer in info["Offer List"]:
            f.write(f"  {offer}\n")
        f.write(f"Updated At: {info['Updated At']}\n")


# ---------------- æŠ“å–æµç¨‹ ----------------

def process_link(url):
    driver = get_driver()
    conn = None
    try:
        driver.get(url)
        time.sleep(6)
        html = driver.page_source
        info = parse_product_page(html, url)

        # è¿æ¥æ•°æ®åº“å¹¶è°ƒç”¨é€šç”¨åŒ¹é…å™¨è§£æ color_code
        try:
            conn = psycopg2.connect(**BARBOUR["PGSQL_CONFIG"])
            res = resolve_color_code(conn, info["Product Name"], info["Product Color"])
            # æ‰“å° Top-K å€™é€‰æˆ–æˆåŠŸä¿¡æ¯
            debug_log(info["Product Name"], info["Product Color"], res)

            if res.status == "matched":
                info["Product Color Code"] = res.color_code
        except Exception as db_e:
            print(f"âŒ æ•°æ®åº“åŒ¹é…é”™è¯¯ï¼š{db_e}")

        write_txt(info)
        if info.get("Product Color Code"):
            print(f"âœ… å·²ä¿å­˜: {info['Product Color Code']}.txt")
        else:
            print(f"ğŸ“ å·²ä¿å­˜(æ— ç¼–ç ): {info['Product Name']} {info['Product Color']}.txt")
    except Exception as e:
        print(f"âŒ æŠ“å–å¤±è´¥: {url}\n{e}\n")
    finally:
        try:
            if conn:
                conn.close()
        except:
            pass
        driver.quit()

def fetch_all():
    links = [u.strip() for u in LINKS_FILE.read_text(encoding="utf-8").splitlines() if u.strip()]
    print(f"ğŸš€ å…±éœ€æŠ“å– {len(links)} ä¸ªå•†å“é“¾æ¥\n")

    with ThreadPoolExecutor(max_workers=4) as executor:
        futures = [executor.submit(process_link, url) for url in links]
        for future in as_completed(futures):
            _ = future.result()

if __name__ == "__main__":
    fetch_all()
