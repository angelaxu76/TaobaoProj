import time
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
import undetected_chromedriver as uc
from config import BARBOUR
from barbour.supplier.parse_offer_info import parse_offer_info
from barbour.write_offer_txt import write_offer_txt

def accept_cookies(driver, timeout=8):
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    try:
        WebDriverWait(driver, timeout).until(
            EC.element_to_be_clickable((By.ID, "onetrust-accept-btn-handler"))
        ).click()
        time.sleep(1)
    except:
        pass

import re

def sanitize_filename(name: str) -> str:
    """å°†æ–‡ä»¶åä¸­éæ³•å­—ç¬¦æ›¿æ¢æˆä¸‹åˆ’çº¿ï¼Œç¡®ä¿ä¸ä¼šåˆ›å»ºå­ç›®å½•"""
    return re.sub(r"[\\/:*?\"<>|'\s]+", "_", name.strip())

def process_url(url, output_dir):
    options = uc.ChromeOptions()
    options.add_argument("--start-maximized")
    driver = uc.Chrome(options=options)

    try:
        print(f"\nğŸŒ æ­£åœ¨æŠ“å–: {url}")
        driver.get(url)
        accept_cookies(driver)
        time.sleep(3)
        html = driver.page_source

        info = parse_offer_info(html, url)
        if info and info["Offers"]:
            # æ¸…æ´—æ–‡ä»¶å
            safe_name = sanitize_filename(info['Product Name'])
            safe_color = sanitize_filename(info['Product Color'])
            filename = f"{safe_name}_{safe_color}.txt"
            filepath = output_dir / filename
            write_offer_txt(info, filepath)
            print(f"âœ… å†™å…¥: {filepath.name}")
        else:
            print(f"âš ï¸ æ— åº“å­˜ä¿¡æ¯ï¼Œè·³è¿‡: {url}")
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {url}\n    {e}")
    finally:
        driver.quit()


def fetch_outdoor_product_offers_concurrent(max_workers=3):
    links_file = BARBOUR["LINKS_FILES"]["outdoorandcountry"]
    output_dir = BARBOUR["TXT_DIRS"]["outdoorandcountry"]
    output_dir.mkdir(parents=True, exist_ok=True)

    urls = []
    with open(links_file, "r", encoding="utf-8") as f:
        for line in f:
            url = line.strip()
            if url:
                urls.append(url)

    print(f"ğŸ”„ å¯åŠ¨å¤šçº¿ç¨‹æŠ“å–ï¼Œæ€»é“¾æ¥æ•°: {len(urls)}ï¼Œå¹¶å‘çº¿ç¨‹æ•°: {max_workers}")

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = [executor.submit(process_url, url, output_dir) for url in urls]

        for future in as_completed(futures):
            pass  # å¯æ·»åŠ è¿›åº¦æ˜¾ç¤ºæˆ–å¼‚å¸¸æ•è·

if __name__ == "__main__":
    fetch_outdoor_product_offers_concurrent(max_workers=3)

