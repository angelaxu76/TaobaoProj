# -*- coding: utf-8 -*-
"""
Outdoor & Country | Barbour å•†å“æŠ“å–ï¼ˆç»Ÿä¸€ TXT æ¨¡æ¿ç‰ˆï¼‰
ä¿æŒå¯¹å¤–æ¥å£ & pipeline å…¼å®¹ï¼š
- process_url(url, output_dir)
- fetch_outdoor_product_offers_concurrent(max_workers=3)

æ”¹åŠ¨è¦ç‚¹ï¼š
1) å¤ç”¨ä½ å·²æœ‰çš„ parse_offer_info(html, url) è§£æç«™ç‚¹
2) è½ç›˜ç»Ÿä¸€èµ° txt_writer.format_txtï¼ˆä¸å…¶å®ƒç«™ç‚¹ä¸€è‡´ï¼‰
3) å†™å…¥å‰ç»Ÿä¸€å­—æ®µï¼š
   - Product Code = Product Color Codeï¼ˆä½ å½“å‰çš„ç»„åˆç ç­–ç•¥ï¼‰
   - Site Name = "Outdoor and Country"
   - ä¸å†™ SizeMap
   - è¿‡æ»¤ 52 åŠæ›´å¤§çš„ç”·è£…æ•°å­—å°ºç 
4) ç±»ç›®å…œåº•ï¼šé‡åˆ° wax + jacket æˆ– code å‰ç¼€ MWX/LWX æ—¶ï¼Œå¼ºåˆ¶ "waxed jacket"
5) âœ… æ–°å¢ï¼ˆä»…åœ¨æœ¬æ¨¡å—å†…å®Œæˆçš„ä¸šåŠ¡å¤„ç†ï¼Œä¸ä¾µå…¥ writer/parserï¼‰ï¼š
   - ä» Offers å›å¡« Product Priceï¼ˆæœ‰è´§ä¼˜å…ˆï¼‰
   - å¯¹ Product Size / Product Size Detail çš„å°ºç åšæ¸…æ´—
   - è‹¥æ—  Product Size Detailï¼ŒæŒ‰ Size å…œåº•ç”Ÿæˆï¼ˆæœ‰è´§=1/æ— è´§=0ï¼ŒEAN å ä½ï¼‰
"""

import time
import json
import re
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urlparse, parse_qs, unquote

import undetected_chromedriver as uc
from bs4 import BeautifulSoup

from config import BARBOUR
from barbour.supplier.outdoorandcountry_parse_offer_info import parse_offer_info

# âœ… ç»Ÿä¸€ TXT å†™å…¥ï¼ˆä¸å…¶å®ƒç«™ç‚¹ä¸€è‡´ï¼‰
from common_taobao.txt_writer import format_txt

# âœ… å°ºç æ¸…æ´—ï¼ˆä¿å®ˆï¼šè¯†åˆ«ä¸äº†å°±åŸæ ·è¿”å›ï¼‰
from common_taobao.size_utils import clean_size_for_barbour  # è§ä½ ä¸Šä¼ çš„å®ç°

# ========== æµè§ˆå™¨ä¸ Cookie ==========
def accept_cookies(driver, timeout=8):
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    try:
        WebDriverWait(driver, timeout).until(
            EC.element_to_be_clickable((By.ID, "onetrust-accept-btn-handler"))
        ).click()
        time.sleep(1)
    except Exception:
        pass

# ========== å·¥å…· ==========
def _normalize_color_from_url(url: str) -> str:
    try:
        qs = parse_qs(urlparse(url).query)
        c = qs.get("c", [None])[0]
        if not c:
            return ""
        c = unquote(c)  # %2F -> /
        c = c.replace("\\", "/")
        c = re.sub(r"\s*/\s*", " / ", c)
        c = re.sub(r"\s+", " ", c).strip()
        c = " ".join(w.capitalize() for w in c.split(" "))
        return c
    except Exception:
        return ""

def sanitize_filename(name: str) -> str:
    return re.sub(r"[\\/:*?\"<>|'\s]+", "_", (name or "").strip())

def _extract_description(html: str) -> str:
    soup = BeautifulSoup(html, "html.parser")
    tag = soup.find("meta", attrs={"property": "og:description"})
    if tag and tag.get("content"):
        desc = tag["content"].replace("<br>", "").replace("<br/>", "").replace("<br />", "")
        return desc.strip()
    tab = soup.select_one(".product_tabs .tab_content[data-id='0'] div")
    return tab.get_text(" ", strip=True) if tab else "No Data"

def _extract_features(html: str) -> str:
    soup = BeautifulSoup(html, "html.parser")
    h3 = soup.find("h3", attrs={"title": "Features"})
    if h3:
        ul = h3.find_next("ul")
        if ul:
            items = [li.get_text(" ", strip=True) for li in ul.find_all("li")]
            if items:
                return " | ".join(items)
    return "No Data"

def _extract_color_code_from_jsonld(html: str) -> str:
    """
    ä» JSON-LD çš„ offers[].mpn æå–é¢œè‰²ç¼–ç ï¼ˆæˆ–ç»„åˆç ï¼‰ã€‚ä¾‹å¦‚ï¼š
    mpn: MWX0017NY9140 -> é¢œè‰²ä½ NY91ï¼ˆä½ å½“å‰é€»è¾‘æŠŠ MWX0017NY91 å½“ product code ä½¿ç”¨ä¹Ÿå¯ä»¥ï¼‰
    è¿™é‡ŒæŒ‰ä½ ç°æœ‰æ­£åˆ™ï¼Œæå– NY99/NY91 è¿™ç±»ï¼›å¦‚æœç«™ç‚¹ç»™çš„æ˜¯å®Œæ•´ MWX0017NY91 ä¹Ÿä¼šä¼ é€’å›å»ã€‚
    """
    soup = BeautifulSoup(html, "html.parser")
    for script in soup.find_all("script", type="application/ld+json"):
        try:
            data = script.string and script.string.strip()
            if not data:
                continue
            j = json.loads(data)
            if isinstance(j, dict) and j.get("@type") == "Product" and isinstance(j.get("offers"), list):
                for off in j["offers"]:
                    mpn = (off or {}).get("mpn")
                    if isinstance(mpn, str):
                        # å…ˆå°è¯•å– MWX0017NY91 è¿™ç§å®Œæ•´ç»„åˆç ï¼ˆæˆªæ‰æœ€å2ä½å°ºç ï¼‰
                        if len(mpn) >= 11:
                            maybe_code = mpn[:-2]
                            # ç®€å•æ ¡éªŒï¼šå‰ä¸‰ä½å­—æ¯ + æ•°å­— + ä¸¤ä½å­—æ¯ä¸¤ä½æ•°å­—
                            if re.match(r"^[A-Z]{3}\d{4}[A-Z]{2}\d{2}$", maybe_code):
                                return maybe_code
                        # å…¶æ¬¡å›é€€åˆ°æœ«å°¾é¢œè‰²å—ï¼ˆOL99/NY91ï¼‰
                        m = re.search(r'([A-Z]{2}\d{2})(\d{2})$', mpn)
                        if m:
                            return m.group(1)
        except Exception:
            continue
    return ""

def _infer_gender_from_name(name: str) -> str:
    n = (name or "").lower()
    if any(x in n for x in ["women", "women's", "womens", "ladies", "lady"]):
        return "å¥³æ¬¾"
    if any(x in n for x in ["men", "men's", "mens"]):
        return "ç”·æ¬¾"
    if any(x in n for x in ["kid", "kids", "child", "children", "boys", "girls", "boy's", "girl's", "junior", "youth"]):
        return "ç«¥æ¬¾"
    return "ç”·æ¬¾"  # å…œåº•æŒ‰ç”·æ¬¾

def _fallback_style_category(name: str, desc: str, product_code: str) -> str:
    """
    æœ¬åœ°å…œåº•ï¼šå³ä½¿ä½ çš„ category_utils è¿˜æ˜¯é‹ç±»ç‰ˆï¼Œä¹Ÿä¸ä¼šæŠŠå¤–å¥—è¯¯åˆ¤ã€‚
    """
    text = f"{name} {desc}".lower()
    if ("wax" in text and "jacket" in text) or (product_code[:3] in {"MWX", "LWX"}):
        return "waxed jacket"
    if "quilt" in text and "jacket" in text or (product_code[:3] in {"MQU", "LQU"}):
        return "quilted jacket"
    return "casual wear"

def _build_sizes_from_offers(offers, gender: str):
    """
    ä¸ä¾èµ–å…¬å…± size_normalizerï¼ŒæŒ‰ä½ çš„æ–°è§„åˆ™ç”Ÿæˆä¸¤è¡Œï¼š
    - Product Sizeï¼ˆä¸å« 52ï¼Œä¹Ÿä¸å« >50 çš„æ•°å­—å°ºç ï¼‰
    - Product Size Detailï¼ˆåŒä¸Šï¼‰
    è¯´æ˜ï¼šä½ æ˜ç¡®ä¸è¦ SizeMapï¼Œå°±ä¸è¿”å›å®ƒã€‚
    """
    # å½’ä¸€ + è¿‡æ»¤
    def norm(raw):
        s = (raw or "").strip().upper().replace("UK ", "")
        s = re.sub(r"\s*\(.*?\)\s*", "", s)
        # æ•°å­—æŠ½å–ä¼˜å…ˆ
        m = re.findall(r"\d{2,3}", s)
        if m:
            n = int(m[0])
            # å¥³ï¼š4..20ï¼ˆå¶æ•°ï¼‰
            if 4 <= n <= 20 and n % 2 == 0 and gender == "å¥³æ¬¾":
                return str(n)
            # ç”·æ•°å­—ï¼š30..50ï¼ˆå¶æ•°ï¼‰ï¼Œä¸”ä½ è¦æ±‚ä¸è¦ 52
            if 30 <= n <= 50 and n % 2 == 0 and gender == "ç”·æ¬¾":
                return str(n)
            # å…¶å®ƒæƒ…å†µï¼šå°è¯•é è¿‘å°±è¿‘å¶æ•°
            if gender == "ç”·æ¬¾" and 28 <= n <= 54:
                candidate = n if n % 2 == 0 else n-1
                candidate = max(30, min(50, candidate))
                return str(candidate)
        # å­—æ¯å°ºç 
        map_alpha = {
            "XXXS":"2XS","2XS":"2XS","XXS":"XS","XS":"XS",
            "S":"S","SMALL":"S","M":"M","MEDIUM":"M","L":"L","LARGE":"L",
            "XL":"XL","X-LARGE":"XL","XXL":"2XL","2XL":"2XL","XXXL":"3XL","3XL":"3XL"
        }
        key = s.replace("-", "").replace(" ", "")
        return map_alpha.get(key)

    bucket = {}
    for size, price, stock_text, can_order in offers or []:
        ns = norm(size)
        if not ns:
            continue
        # æœ‰è´§ä¼˜å…ˆè¦†ç›–
        curr = "æœ‰è´§" if bool(can_order) else "æ— è´§"
        prev = bucket.get(ns)
        if prev is None or (prev == "æ— è´§" and curr == "æœ‰è´§"):
            bucket[ns] = curr

    # æ’åºï¼šå¥³ 4..20ï¼›ç”· å­—æ¯â†’æ•°å­—ï¼ˆ30..50ï¼‰ï¼›ä¸è¾“å‡º 52
    WOMEN = ["4","6","8","10","12","14","16","18","20"]
    MEN_ALPHA = ["2XS","XS","S","M","L","XL","2XL","3XL"]
    MEN_NUM = [str(n) for n in range(30, 52, 2)]  # 30..50

    ordered = []
    if gender == "å¥³æ¬¾":
        ordered = [k for k in WOMEN if k in bucket]
    else:
        ordered = [k for k in MEN_ALPHA if k in bucket] + [k for k in MEN_NUM if k in bucket]

    product_size = ";".join(f"{k}:{bucket[k]}" for k in ordered)
    product_size_detail = ";".join(f"{k}:{1 if bucket[k]=='æœ‰è´§' else 0}:0000000000000" for k in ordered)
    return product_size, product_size_detail

# ========= æ–°å¢ï¼šä»…åœ¨æœ¬æ¨¡å—å†…åšçš„ Outdoor ä¸“å±ä¸šåŠ¡å¤„ç† =========
def _inject_price_from_offers(info: dict) -> None:
    """Outdoor é¡µæ— æ˜¾å¼ä»·æ ¼æ—¶ï¼Œä» Offers å›å¡«ï¼ˆæœ‰è´§ä¼˜å…ˆï¼Œå…¶æ¬¡ç¬¬ä¸€æ¡ï¼‰"""
    if info.get("Product Price"):
        return
    offers = info.get("Offers") or []
    price_val = None
    for size, price, stock_text, can_order in offers:
        if price:
            if can_order:              # æœ‰è´§ä»·ä¼˜å…ˆ
                price_val = price
                break
            if price_val is None:      # å¦åˆ™å…ˆè®°ç¬¬ä¸€æ¡
                price_val = price
    if price_val:
        info["Product Price"] = str(price_val)

def _clean_sizes(info: dict) -> None:
    """å¯¹ä¸¤è¡Œå°ºç åšä¸€æ¬¡æ¸…æ´—ï¼›ä¸è¯†åˆ«åˆ™ä¿æŒåŸæ ·"""
    # Product Size: "S:æœ‰è´§;M:æ— è´§..."
    if info.get("Product Size"):
        cleaned = []
        for token in str(info["Product Size"]).split(";"):
            token = token.strip()
            if not token:
                continue
            try:
                size, status = token.split(":")
                size = clean_size_for_barbour(size)
                cleaned.append(f"{size}:{status}")
            except ValueError:
                cleaned.append(token)
        info["Product Size"] = ";".join(cleaned)

    # Product Size Detail: "S:1:EAN;M:0:EAN..."
    if info.get("Product Size Detail"):
        cleaned = []
        for token in str(info["Product Size Detail"]).split(";"):
            token = token.strip()
            if not token:
                continue
            parts = token.split(":")
            if len(parts) == 3:
                size, stock, ean = parts
                size = clean_size_for_barbour(size)
                cleaned.append(f"{size}:{stock}:{ean}")
            else:
                cleaned.append(token)
        info["Product Size Detail"] = ";".join(cleaned)

def _ensure_detail_from_size(info: dict) -> None:
    """è‹¥æ—  Detailï¼Œç”¨ Size å…œåº•ç”Ÿæˆï¼ˆæœ‰è´§=1ï¼Œæ— è´§=0ï¼ŒEAN å ä½ï¼‰"""
    if info.get("Product Size") and not info.get("Product Size Detail"):
        detail = []
        for token in str(info["Product Size"]).split(";"):
            token = token.strip()
            if not token:
                continue
            try:
                size, status = token.split(":")
                size = clean_size_for_barbour(size)
                stock = 1 if status.strip() == "æœ‰è´§" else 0
                detail.append(f"{size}:{stock}:0000000000000")
            except ValueError:
                continue
        if detail:
            info["Product Size Detail"] = ";".join(detail)

# ========== ä¸»æµç¨‹ ==========
def process_url(url, output_dir):
    options = uc.ChromeOptions()
    options.add_argument("--start-maximized")
    # å¦‚éœ€æ— å¤´ï¼šoptions.add_argument("--headless=new")
    driver = uc.Chrome(options=options)

    try:
        print(f"\nğŸŒ æ­£åœ¨æŠ“å–: {url}")
        driver.get(url)
        accept_cookies(driver)
        time.sleep(3)
        html = driver.page_source

        # 1) è§£æï¼ˆå¤ç”¨ä½ å·²æœ‰çš„ç«™ç‚¹è§£æï¼‰
        info = parse_offer_info(html, url) or {}
        url_color = _normalize_color_from_url(url)

        # 2) åŸºç¡€å­—æ®µè¡¥é½ï¼ˆç»Ÿä¸€ï¼‰
        info.setdefault("Brand", "Barbour")
        info.setdefault("Product Name", "No Data")
        info.setdefault("Product Color", url_color or "No Data")
        info.setdefault("Product Description", _extract_description(html))
        info.setdefault("Feature", _extract_features(html))
        info.setdefault("Site Name", "Outdoor and Country")
        info["Source URL"] = url  # ä¸å…¶ä»–ç«™ç‚¹ä¿æŒä¸€è‡´çš„å­—æ®µå

        # 3) Product Code / Product Color Codeï¼ˆä½ çš„ç­–ç•¥ï¼šç»„åˆç å³å¯ï¼‰
        color_code = info.get("Product Color Code") or _extract_color_code_from_jsonld(html)
        if color_code:
            info["Product Color Code"] = color_code
            info["Product Code"] = color_code  # âœ… ä½ è¦æ±‚ï¼šç›´æ¥æŠŠç»„åˆç å½“ Product Code

        # 4) æ€§åˆ«ï¼ˆä¼˜å…ˆæ ‡é¢˜/åç§°å…³é”®è¯ï¼Œå…œåº•ç”·æ¬¾ï¼‰
        if not info.get("Product Gender"):
            info["Product Gender"] = _infer_gender_from_name(info.get("Product Name", ""))

        # 5) Offers â†’ ä¸¤è¡Œå°ºç ï¼ˆä¸å†™ SizeMapï¼Œä¸”è¿‡æ»¤ 52ï¼‰
        offers = info.get("Offers") or []
        ps, psd = _build_sizes_from_offers(offers, info["Product Gender"])
        info["Product Size"] = ps
        info["Product Size Detail"] = psd

        # 6) ç±»ç›®ï¼ˆæœ¬åœ°å…œåº•ï¼Œé˜²æ­¢ category_utils æ—§ç‰ˆè¯¯åˆ¤ï¼‰
        if not info.get("Style Category"):
            info["Style Category"] = _fallback_style_category(
                info.get("Product Name",""),
                info.get("Product Description",""),
                info.get("Product Code","") or ""
            )

        # ========= âœ… Outdoor ä¸“å±å¢å¼ºï¼šå†™ç›˜å‰ä¸€æ¬¡æ€§å¤„ç† =========
        _inject_price_from_offers(info)   # Outdoor æ— ä»· â†’ ä» offers è¡¥
        _clean_sizes(info)                 # å°ºç æ¸…æ´—ï¼ˆä¸¤è¡Œï¼‰
        _ensure_detail_from_size(info)     # æ²¡ Detail å°±ä» Size å…œåº•

        # 7) æ–‡ä»¶åç­–ç•¥
        if color_code:
            filename = f"{sanitize_filename(color_code)}.txt"
        else:
            safe_name = sanitize_filename(info.get('Product Name', 'NoName'))
            safe_color = sanitize_filename(info.get('Product Color', 'NoColor'))
            filename = f"{safe_name}_{safe_color}.txt"

        # 8) âœ… ç»Ÿä¸€ç”¨ txt_writer.format_txt å†™å‡ºï¼ˆä¸å…¶å®ƒç«™ç‚¹å®Œå…¨ä¸€è‡´ï¼‰
        output_dir.mkdir(parents=True, exist_ok=True)
        txt_path = output_dir / filename
        format_txt(info, txt_path, brand="Barbour")
        print(f"âœ… å†™å…¥: {txt_path.name}")

    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {url}\n    {e}")
    finally:
        driver.quit()

def fetch_outdoor_product_offers_concurrent(max_workers=3):
    links_file = BARBOUR["LINKS_FILES"]["outdoorandcountry"]
    output_dir = BARBOUR["TXT_DIRS"]["outdoorandcountry"]
    output_dir.mkdir(parents=True, exist_ok=True)

    urls = []
    with open(links_file, "r", encoding="utf-8") as f:
        for line in f:
            url = line.strip()
            if url:
                urls.append(url)

    print(f"ğŸ”„ å¯åŠ¨å¤šçº¿ç¨‹æŠ“å–ï¼Œæ€»é“¾æ¥æ•°: {len(urls)}ï¼Œå¹¶å‘çº¿ç¨‹æ•°: {max_workers}")

    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = [executor.submit(process_url, url, output_dir) for url in urls]
        for _ in as_completed(futures):
            pass

if __name__ == "__main__":
    fetch_outdoor_product_offers_concurrent(max_workers=3)
