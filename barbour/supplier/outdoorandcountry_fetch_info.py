# -*- coding: utf-8 -*-
"""
Outdoor & Country | Barbour å•†å“æŠ“å–ï¼ˆç»Ÿä¸€å†™å…¥ TXTï¼šæ–¹æ¡ˆAï¼‰
ä¾èµ–ï¼š
  pip install undetected-chromedriver bs4 lxml
é¡¹ç›®ä¾èµ–ï¼š
  from config import BARBOUR
  from txt_writer import format_txt
  from common_taobao.core.size_normalizer import build_size_fields_from_offers, infer_gender_for_barbour
  from common_taobao.core.category_utils import infer_style_category
"""

import json
import re
import time
from pathlib import Path
from typing import Dict, List, Tuple, Optional

import undetected_chromedriver as uc
from bs4 import BeautifulSoup

from config import BARBOUR
from common_taobao.txt_writer import format_txt
from common_taobao.core.size_normalizer import (
    build_size_fields_from_offers,
    infer_gender_for_barbour,
)
from common_taobao.core.category_utils import infer_style_category

# ========== è·¯å¾„ ==========
BASE_DIR: Path = BARBOUR["BASE"]
PUBLICATION_DIR: Path = BASE_DIR / "publication"
LINK_FILE: Path = PUBLICATION_DIR / "product_links.txt"
TXT_DIR: Path = BARBOUR.get("TXT_DIR", BASE_DIR / "TXT")  # å…¼å®¹å…œåº•

HEADERS = {"User-Agent": "Mozilla/5.0"}

# ========== Selenium åŸºç¡€ ==========
def make_driver(headless: bool = True):
    opts = uc.ChromeOptions()
    if headless:
        opts.add_argument("--headless=new")
    opts.add_argument("--disable-gpu")
    opts.add_argument("--no-sandbox")
    opts.add_argument("--disable-dev-shm-usage")
    opts.add_argument("--window-size=1400,1000")
    return uc.Chrome(options=opts)


def accept_cookies(driver, timeout: int = 8):
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC

    try:
        # Outdoor & Country å¸¸è§ cookie banner æŒ‰é’®
        btns = WebDriverWait(driver, timeout).until(
            EC.presence_of_all_elements_located((By.XPATH, "//button|//a"))
        )
        for b in btns:
            txt = (b.text or "").strip().lower()
            if any(k in txt for k in ["accept", "agree", "got it", "allow", "i understand"]):
                try:
                    b.click()
                    time.sleep(0.3)
                    break
                except Exception:
                    pass
    except Exception:
        pass


# ========== è§£æå·¥å…· ==========
def _load_soup(driver) -> BeautifulSoup:
    html = driver.page_source
    return BeautifulSoup(html, "lxml")


def _extract_text(soup: BeautifulSoup, selector: str) -> str:
    el = soup.select_one(selector)
    if not el:
        return ""
    return " ".join(el.get_text(" ", strip=True).split())


def _extract_product_code_from_title_or_meta(soup: BeautifulSoup) -> Optional[str]:
    """
    Outdoor & Country é€šå¸¸ä¸ç”¨å®˜æ–¹ color_codeï¼Œä½†æ ‡é¢˜ä¸­å¸¸å‡ºç°æ¬¾å¼åï¼Œå•†å“ code éœ€ä»é¡µé¢æ•°æ®ç»“æ„è·å–ã€‚
    è‹¥ JS ä¸­æœªå« codeï¼Œè¿™é‡Œå…œåº•ï¼šæ‰¾ç±»ä¼¼ "Barbour Beaufort Jacket" + é¢œè‰²ï¼Œæ— æ³•åˆ™è¿”å› Noneã€‚
    """
    title = _extract_text(soup, "h1") or _extract_text(soup, "title")
    # å¸¸è§„ï¼šBarbour ä¼šåœ¨å›¾åƒURLæˆ–è„šæœ¬å—å¸¦ codeï¼›è‹¥æ‹¿ä¸åˆ°ï¼Œè¿™é‡Œåªè¿”å› Noneï¼Œåç»­ä¸å¼ºä¾èµ–ã€‚
    # ä½ ä¹Ÿå¯ä»¥æŒ‰ä½ çš„è§„åˆ™é€šè¿‡ URL å‚æ•°æˆ–å›¾ç‰‡åæ¥å›æ¨ï¼ˆæ­¤å¤„ä¸å†’è¿›ï¼‰ã€‚
    m = re.search(r"\b([A-Z]{3}\d{4}[A-Z]{2}\d{2})\b", soup.text)  # ä¾‹å¦‚ MWX0340NY91
    if m:
        return m.group(1)
    return None


def _json_fixups(raw: str) -> str:
    """
    ä¿®å¤ Outdoor & Country é¡µé‡Œ JS å˜é‡ä¸­å¸¸è§çš„ JSON é—®é¢˜ï¼š
    - HTML ç‰‡æ®µé‡Œçš„å¼•å·ã€æ¢è¡Œ
    - å•å¼•å·åŒ…è£¹çš„é”®å€¼
    - æœ«å°¾å¤šé€—å·
    å°½é‡â€œæœ€å°åŒ–ä¿®å¤â€ï¼Œé¿å…è¯¯ä¼¤ã€‚
    """
    s = raw.strip()

    # å¸¸è§ HTML å®ä½“
    s = s.replace("&quot;", '"').replace("&#34;", '"').replace("&amp;", "&")

    # å»æ‰å¯èƒ½çš„è¡Œå°¾é€—å·
    s = re.sub(r",\s*([\]}])", r"\1", s)

    # å°†ç±»ä¼¼ key:'value' ä¿®ä¸º "key":"value"
    def _quote_keys_vals(match):
        key = match.group(1)
        val = match.group(2)
        return f'"{key}":"{val}"'

    s = re.sub(r"([A-Za-z0-9_]+)\s*:\s*'([^']*)'", _quote_keys_vals, s)

    # å°†å•å¼•å·åŒ…è£¹çš„å­—ç¬¦ä¸²æ›¿æ¢ä¸ºåŒå¼•å·ï¼ˆä¸å½±å“å·²åœ¨å¼•å·å†…çš„ JSONï¼‰
    # æ³¨æ„ï¼šè¿™é‡Œå¾ˆå®¹æ˜“è¿‡åº¦ä¿®å¤ï¼Œæ‰€ä»¥å°½é‡åœ¨å¯æ§è¾¹ç•Œå†…åš
    # è‹¥ä»å¤±è´¥ï¼Œåç»­è¿˜æœ‰ try/except å®¹é”™
    return s


def _extract_js_var_block(soup: BeautifulSoup, var_name: str) -> Optional[str]:
    """
    åœ¨æ‰€æœ‰ <script> ä¸­æŸ¥æ‰¾åŒ…å« var_name çš„æ–‡æœ¬å—ï¼Œè¿”å›ç–‘ä¼¼ JSON ç‰‡æ®µå­—ç¬¦ä¸²
    ä¾‹å¦‚ï¼švar stockInfo = {...}; æˆ– window.stockInfo = {...};
    """
    scripts = soup.find_all("script")
    pat = re.compile(rf"{var_name}\s*=\s*(\{{.*?\}}|\[.*?\])\s*[,;]", re.S)
    for sc in scripts:
        text = sc.string or sc.get_text() or ""
        m = pat.search(text)
        if m:
            return m.group(1)
    return None


def _safe_json_loads(raw: str) -> Optional[dict]:
    if not raw:
        return None
    try:
        return json.loads(raw)
    except Exception:
        pass
    try:
        return json.loads(_json_fixups(raw))
    except Exception:
        return None


def _parse_colour_size_stock(soup: BeautifulSoup):
    """
    Outdoor & Country çš„ä¸‰å¤§æ ¸å¿ƒï¼š
      - Colours: é¢œè‰²åˆ—è¡¨/IDæ˜ å°„
      - Sizes:   å°ºç åˆ—è¡¨/IDæ˜ å°„
      - stockInfo: { "<sizeId>-<colourId>": {...} }
    è¿”å›ï¼š(colours_dict, sizes_dict, stock_dict)
    """
    colours_raw = _extract_js_var_block(soup, "Colours")
    sizes_raw = _extract_js_var_block(soup, "Sizes")
    stock_raw = _extract_js_var_block(soup, "stockInfo")

    colours = _safe_json_loads(colours_raw) or {}
    sizes = _safe_json_loads(sizes_raw) or {}
    stock = _safe_json_loads(stock_raw) or {}

    return colours, sizes, stock


def _choose_active_colour_from_url(url: str, colours: dict) -> Optional[str]:
    """
    ä» URL çš„ ?c=xxx æˆ– path ä¸­æ¨æ–­å½“å‰é¢œè‰²æ–‡å­—/IDã€‚
    æ‰¾ä¸åˆ°åˆ™è¿”å› Noneï¼ˆä¸Šå±‚å¯é»˜è®¤å–åˆ—è¡¨ç¬¬ä¸€ä¸ªï¼‰ã€‚
    """
    m = re.search(r"[?&]c=([^&]+)", url, re.I)
    if not m:
        return None
    c_param = m.group(1).lower()
    # åœ¨ colours ç»“æ„é‡Œå°è¯•åŒ¹é…ï¼ˆç»“æ„å¤šæ ·ï¼Œå°½é‡å®½æ¾ï¼‰
    # å…è®¸ç›´æ¥æ¯”å¯¹ name æˆ– slug
    for cid, cinfo in (colours.items() if isinstance(colours, dict) else []):
        name = (cinfo.get("name") or "").lower()
        slug = (cinfo.get("url") or cinfo.get("slug") or "").lower()
        if c_param in {name, slug} or c_param in name or c_param in slug:
            return str(cid)
    return None


def _build_offer_list(colours: dict, sizes: dict, stock: dict, active_colour_id: Optional[str]) -> Tuple[str, List[Tuple[str, float, str, bool]]]:
    """
    ç»„è£… Offer åˆ—è¡¨ï¼ˆ(size_label, price, stock_text, can_order)ï¼‰
    å°½é‡é€‰æ‹© URL æŒ‡å®šçš„é¢œè‰²ï¼›è‹¥æ— åˆ™é€‰ç¬¬ä¸€ä¸ªé¢œè‰²ã€‚
    è¿”å›ï¼š(color_name, offer_list)
    """
    if not isinstance(colours, dict) or not isinstance(sizes, dict) or not isinstance(stock, dict):
        return "", []

    # é€‰ç”¨é¢œè‰²
    color_id = active_colour_id
    if not color_id:
        # å–ç¬¬ä¸€ä¸ªé¢œè‰² id
        if colours:
            color_id = str(next(iter(colours.keys())))
    color_name = ""
    if color_id and color_id in colours:
        color_name = colours[color_id].get("name") or colours[color_id].get("label") or ""

    # ç»„è£…æ¯ä¸ªå°ºç çš„åº“å­˜
    offers: List[Tuple[str, float, str, bool]] = []
    for sid, sinfo in sizes.items():
        size_label = sinfo.get("name") or sinfo.get("label") or str(sid)
        key = f"{sid}-{color_id}"
        sitem = stock.get(key) or {}
        # ä»·æ ¼å­—æ®µæœ‰æ—¶åœ¨ HTML/JS çš„å…¶ä»–å—é‡Œï¼Œè¿™é‡Œå°½é‡è¯»å–ï¼Œæ²¡æœ‰å°±ç½® 0
        price = 0.0
        for k in ("price", "salePrice", "sale", "now", "currentPrice"):
            v = sitem.get(k)
            try:
                if v is not None:
                    price = float(v)
                    break
            except Exception:
                pass

        # åº“å­˜åˆ¤æ–­ï¼šè‹¥æœ‰æ˜ç¡® availability å­—æ®µï¼›å¦åˆ™çœ‹ stockLevelMessage / inStock ç­‰
        stock_text = (sitem.get("stockLevelMessage") or sitem.get("availability") or "").strip()
        in_stock_flags = [
            sitem.get("inStock"),
            sitem.get("isInStock"),
            sitem.get("canOrder"),
            sitem.get("available"),
        ]
        can_order = any(bool(x) for x in in_stock_flags)

        # å¦‚æœæ²¡æœ‰æ˜¾å¼å¸ƒå°”ï¼Œä½†æœ‰æ–‡æ¡ˆï¼Œåšä¸€æ¬¡ç²—åˆ¤
        if not any(in_stock_flags) and stock_text:
            low = stock_text.lower()
            can_order = any(k in low for k in ["in stock", "available", "dispatch", "pre-order"])

        offers.append((size_label, price, stock_text, bool(can_order)))

    return color_name, offers


# ========== é¡µé¢è§£æä¸»å‡½æ•° ==========
def parse_outdoor_and_country(driver, url: str) -> Optional[Dict]:
    driver.get(url)
    time.sleep(1.6)
    accept_cookies(driver, timeout=8)
    time.sleep(0.5)

    soup = _load_soup(driver)

    title = _extract_text(soup, "h1") or _extract_text(soup, "title")
    description = _extract_text(soup, ".productView-description") or _extract_text(soup, '[data-tab-content="description"]')
    # Featuresï¼ˆè¦ç‚¹åˆ—è¡¨ï¼‰
    features_block = soup.select(".productView-info .productView-info-name, .productView-info .productView-info-value")
    features = []
    if features_block:
        features_text = " ".join(x.get_text(" ", strip=True) for x in features_block)
        features.append(features_text)

    product_code = _extract_product_code_from_title_or_meta(soup)  # å¯èƒ½æŠ“ä¸åˆ°ï¼Œä¸å¼ºåˆ¶
    colours, sizes, stock = _parse_colour_size_stock(soup)
    active_colour_id = _choose_active_colour_from_url(url, colours)
    color_name, offer_list = _build_offer_list(colours, sizes, stock, active_colour_id)

    # ç«™ç‚¹å
    site_name = "Outdoor and Country"

    # ç»„è£…åŸºç¡€ä¿¡æ¯
    info: Dict = {
        "Product Name": title,
        "Product Description": description,
        "Product Gender": "",        # ç¨åç”¨å…±äº«æ¨¡å—ä¿®æ­£
        "Product Color": color_name or "",
        "Style Category": "",        # ç¨ååˆ¤å®š
        "Feature": " | ".join(features) if features else "",
        "Source URL": url,
        "Site Name": site_name,
        "Offers": offer_list,        # æš‚å­˜ï¼Œå†™å…¥å‰è½¬ä¸‰å­—æ®µ
    }
    if product_code:
        info["Product Code"] = product_code
    info["Brand"] = "Barbour"

    # ====== æ€§åˆ«åˆ¤å®šï¼ˆä¼˜å…ˆ Code â†’ æ ‡é¢˜/æè¿° â†’ å…œåº•ï¼‰======
    gender = infer_gender_for_barbour(
        product_code=product_code,
        title=title,
        description=description,
        given_gender=info.get("Product Gender"),
    ) or "ç”·æ¬¾"
    info["Product Gender"] = gender

    # ====== å°ºç ä¸‰å­—æ®µ ======
    size_map, size_detail, product_size = build_size_fields_from_offers(offer_list, gender)
    info["SizeMap"] = size_map
    info["SizeDetail"] = size_detail
    info["Product Size"] = product_size

    # ====== é£æ ¼ç±»ç›® ======
    info["Style Category"] = infer_style_category(
        desc=description,
        product_name=title,
        product_code=product_code or "",
        brand="Barbour",
    )

    return info


# ========== å†™å…¥ & æ‰¹é‡ ==========
def write_one_product(info: Dict, code_hint: Optional[str] = None):
    """
    code_hintï¼šå½“é¡µé¢æ— æ³•æå–åˆ° Product Code æ—¶ï¼Œç”¨äºå†™æ–‡ä»¶åçš„å…œåº•ã€‚
    """
    code = info.get("Product Code") or code_hint
    if not code:
        # æ²¡æœ‰ code å°±ç”¨æ ‡é¢˜é™çº§æˆå®‰å…¨æ–‡ä»¶å
        safe = re.sub(r"[^\w\-]+", "_", (info.get("Product Name") or "barbour_item"))
        code = safe[:50]

    TXT_DIR.mkdir(parents=True, exist_ok=True)
    txt_path = TXT_DIR / f"{code}.txt"
    format_txt(info, txt_path, brand="Barbour")
    print(f"âœ… å†™å…¥: {txt_path}")


def fetch_one(url: str, driver=None):
    own_driver = False
    if driver is None:
        driver = make_driver(headless=True)
        own_driver = True
    try:
        info = parse_outdoor_and_country(driver, url)
        if info:
            # å°è¯•ä» URL çŒœæµ‹ codeï¼ˆå¯é€‰ï¼‰
            code_hint = None
            m = re.search(r"/([A-Za-z0-9]{3}\d{4}[A-Za-z]{2}\d{2})", url)
            if m:
                code_hint = m.group(1)
            write_one_product(info, code_hint=code_hint)
        else:
            print(f"âš ï¸ è§£æå¤±è´¥: {url}")
    finally:
        if own_driver:
            driver.quit()


def main():
    import sys
    urls: List[str] = []
    if len(sys.argv) > 1:
        urls = sys.argv[1:]
    else:
        if LINK_FILE.exists():
            urls = [u.strip() for u in LINK_FILE.read_text(encoding="utf-8").splitlines() if u.strip()]

    if not urls:
        print("âš ï¸ æœªå‘ç°å¾…æŠ“å–é“¾æ¥ã€‚å¯åœ¨å‘½ä»¤è¡Œä¼ å…¥ URLï¼Œæˆ–åœ¨ publication/product_links.txt å¡«å…¥é“¾æ¥ã€‚")
        return

    driver = make_driver(headless=True)
    try:
        for i, url in enumerate(urls, 1):
            print(f"ğŸŒ [{i}/{len(urls)}] æŠ“å–: {url}")
            fetch_one(url, driver=driver)
    finally:
        driver.quit()


if __name__ == "__main__":
    main()
