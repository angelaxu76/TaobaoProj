# barbour_fetch_info.py
# -*- coding: utf-8 -*-

import re
import json
import requests
from bs4 import BeautifulSoup
from pathlib import Path

from config import BARBOUR
from common_taobao.txt_writer import format_txt              # âœ… ç»Ÿä¸€å†™å…¥æ¨¡æ¿
from barbour.core.site_utils import assert_site_or_raise as canon


# å¯é€‰ï¼šæ›´ç¨³çš„ Barbour æ€§åˆ«å…œåº•ï¼ˆM*/L* å‰ç¼€ï¼‰
try:
    from common_taobao.core.size_normalizer import infer_gender_for_barbour
except Exception:
    infer_gender_for_barbour = None

HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/120.0.0.0 Safari/537.36"
    )
}

CANON_SITE = canon("barbour")

# ---------- å°ºç æ ‡å‡†åŒ–ï¼ˆä¸å…¶å®ƒç«™ç‚¹ä¸€è‡´ï¼‰ ----------
WOMEN_ORDER = ["4","6","8","10","12","14","16","18","20"]
MEN_ALPHA_ORDER = ["2XS","XS","S","M","L","XL","2XL","3XL"]
MEN_NUM_ORDER = [str(n) for n in range(30, 52, 2)]  # 30..50ï¼ˆæŒ‰ä½ çš„è¦æ±‚ï¼šä¸å« 52ï¼‰

ALPHA_MAP = {
    "XXXS": "2XS", "2XS": "2XS",
    "XXS": "XS",  "XS":  "XS",
    "S": "S", "SMALL": "S",
    "M": "M", "MEDIUM": "M",
    "L": "L", "LARGE": "L",
    "XL": "XL", "X-LARGE": "XL",
    "XXL": "2XL", "2XL": "2XL",
    "XXXL": "3XL", "3XL": "3XL",
}

def _safe_json_loads(text: str):
    try:
        return json.loads(text)
    except Exception:
        return None

def _extract_gender_from_html(html: str) -> str:
    """
    ä»é¡µé¢çš„æ•°æ®å±‚é‡Œè¯»å‡ºæ€§åˆ«æ ‡ç­¾ï¼Œè½åˆ°ï¼šç”·æ¬¾/å¥³æ¬¾/ç«¥æ¬¾/æœªçŸ¥
    """
    m = re.search(r'"item_category"\s*:\s*"([^"]+)"', html, re.IGNORECASE)
    gender_raw = m.group(1).strip().lower() if m else ""
    mapping = {
        "womens": "å¥³æ¬¾", "women": "å¥³æ¬¾", "ladies": "å¥³æ¬¾",
        "mens": "ç”·æ¬¾",   "men": "ç”·æ¬¾",
        "kids": "ç«¥æ¬¾", "children": "ç«¥æ¬¾", "child": "ç«¥æ¬¾",
        "unisex": "ä¸­æ€§",
    }
    return mapping.get(gender_raw, "æœªçŸ¥")

def _extract_material_from_features(features_text: str) -> str:
    if not features_text:
        return "No Data"
    text = features_text.replace("\n", " ").replace("\r", " ")
    mats = re.findall(r"\b\d{1,3}%\s+[A-Za-z][A-Za-z \-]*", text)
    if mats:
        return " / ".join(mats[:2])
    return "No Data"

def _normalize_size_token(token: str, gender: str) -> str | None:
    s = (token or "").strip().upper()
    s = s.replace("UK ", "").replace("EU ", "").replace("US ", "")
    s = re.sub(r"\s*\(.*?\)\s*", "", s)
    s = re.sub(r"\s+", " ", s)

    # å…ˆæ•°å­—
    nums = re.findall(r"\d{1,3}", s)
    if nums:
        n = int(nums[0])
        if gender == "å¥³æ¬¾" and n in {4,6,8,10,12,14,16,18,20}:
            return str(n)
        if gender == "ç”·æ¬¾":
            # ç”·æ•°å­— 30..50ï¼ˆå¶æ•°ï¼‰ï¼Œæ˜ç¡®æ’é™¤ 52
            if 30 <= n <= 50 and n % 2 == 0:
                return str(n)
            # å°±è¿‘å®¹é”™ï¼š28..54 â†’ è´´è¿‘å¶æ•°å¹¶è£å‰ªåˆ° 30..50
            if 28 <= n <= 54:
                cand = n if n % 2 == 0 else n - 1
                cand = max(30, min(50, cand))
                return str(cand)
        return None

    # å†å­—æ¯
    key = s.replace("-", "").replace(" ", "")
    return ALPHA_MAP.get(key)

def _sort_sizes(keys: list[str], gender: str) -> list[str]:
    if gender == "å¥³æ¬¾":
        return [k for k in WOMEN_ORDER if k in keys]
    return [k for k in MEN_ALPHA_ORDER if k in keys] + [k for k in MEN_NUM_ORDER if k in keys]

def _build_size_lines_from_buttons(size_buttons_map: dict[str, str], gender: str) -> tuple[str, str]:
    """
    ç”¨æŒ‰é’®æ–‡æœ¬å’Œå¯ç”¨æ€§ç”Ÿæˆä¸¤è¡Œï¼Œå¹¶è¡¥é½æœªå‡ºç°çš„å°ºç ä¸ºæ— è´§(0)ï¼š
      - Product Size: "34:æœ‰è´§;36:æ— è´§;..."
      - Product Size Detail: "34:3:0000000000000;36:0:0000000000000;..."
    è§„åˆ™ï¼š
      - åŒå°ºç é‡å¤å‡ºç°æ—¶ï¼Œâ€œæœ‰è´§â€ä¼˜å…ˆ
      - ç”·æ¬¾ï¼šè‡ªåŠ¨åœ¨ã€å­—æ¯ç³»(2XSâ€“3XL)ã€‘ä¸ã€æ•°å­—ç³»(30â€“50, ä¸å«52)ã€‘äºŒé€‰ä¸€ï¼Œç»ä¸æ··ç”¨
      - å¥³æ¬¾ï¼šå›ºå®š 4â€“20
    """
    status_bucket: dict[str, str] = {}
    stock_bucket: dict[str, int] = {}

    # 1) å…ˆæŠŠé¡µé¢ä¸Šâ€œå‡ºç°çš„å°ºç â€å†™å…¥ï¼ˆæœ‰è´§ä¼˜å…ˆè¦†ç›–ï¼‰
    for raw, status in (size_buttons_map or {}).items():
        norm = _normalize_size_token(raw, gender or "ç”·æ¬¾")
        if not norm:
            continue
        curr = "æœ‰è´§" if status == "æœ‰è´§" else "æ— è´§"
        prev = status_bucket.get(norm)
        if prev is None or (prev == "æ— è´§" and curr == "æœ‰è´§"):
            status_bucket[norm] = curr
            stock_bucket[norm] = 3 if curr == "æœ‰è´§" else 0

    # 2) æŒ‰æ€§åˆ«é€‰æ‹©â€œå•ä¸€å°ºç ç³»â€çš„å®Œæ•´é¡ºåºè¡¨
    if (gender or "ç”·æ¬¾") == "å¥³æ¬¾":
        full_order = WOMEN_ORDER[:]  # 4..20
    else:
        # ç”·æ¬¾ï¼šæ ¹æ®å·²å‡ºç°çš„å°ºç è‡ªåŠ¨åˆ¤å®šä½¿ç”¨å“ªä¸€ç³»ï¼ˆå­—æ¯ æˆ– æ•°å­—ï¼‰
        keys = set(status_bucket.keys())
        has_num   = any(k in MEN_NUM_ORDER   for k in keys)
        has_alpha = any(k in MEN_ALPHA_ORDER for k in keys)
        if has_num and not has_alpha:
            chosen = MEN_NUM_ORDER[:]        # åªç”¨æ•°å­—ç³» 30..50
        elif has_alpha and not has_num:
            chosen = MEN_ALPHA_ORDER[:]      # åªç”¨å­—æ¯ç³» 2XS..3XL
        elif has_num or has_alpha:
            # åŒæ—¶å‡ºç°ï¼ˆå¼‚å¸¸åœºæ™¯ï¼‰ï¼šå–å‡ºç°æ•°é‡å¤šçš„é‚£ä¸€ç³»
            num_count   = sum(1 for k in keys if k in MEN_NUM_ORDER)
            alpha_count = sum(1 for k in keys if k in MEN_ALPHA_ORDER)
            chosen = MEN_NUM_ORDER[:] if num_count >= alpha_count else MEN_ALPHA_ORDER[:]
            # æŠŠå¦ä¸€ç³»çš„é”®åˆ æ‰ï¼Œç¡®ä¿ä¸æ··ç”¨
            for k in list(status_bucket.keys()):
                if k not in chosen:
                    status_bucket.pop(k, None)
                    stock_bucket.pop(k, None)
        else:
            # é¡µé¢å•¥ä¹Ÿæ²¡è¯†åˆ«åˆ°ï¼šé»˜è®¤ç”¨å­—æ¯ç³»ï¼ˆæ›´å¸¸è§çš„å¤–å¥—ï¼‰
            chosen = MEN_ALPHA_ORDER[:]
        full_order = chosen

    # 3) å¯¹â€œæœªå‡ºç°â€çš„å°ºç è¡¥é½ä¸º æ— è´§/0ï¼ˆä»…åœ¨é€‰å®šçš„é‚£ä¸€ç³»å†…è¡¥é½ï¼‰
    for s in full_order:
        if s not in status_bucket:
            status_bucket[s] = "æ— è´§"
            stock_bucket[s] = 0

    # 4) å›ºå®šé¡ºåºè¾“å‡ºï¼ˆåªè¾“å‡ºé€‰å®šé‚£ä¸€ç³»ï¼‰
    ordered = [s for s in full_order]
    ps  = ";".join(f"{k}:{status_bucket[k]}" for k in ordered)
    psd = ";".join(f"{k}:{stock_bucket[k]}:0000000000000" for k in ordered)
    return ps, psd



# ---------- è§£ææ ¸å¿ƒï¼šä¿æŒä½ å½“å‰çš„ç»“æ„ ----------
def extract_product_info_from_html(html: str, url: str) -> dict:
    soup = BeautifulSoup(html, "html.parser")

    # åç§° / SKU ä» ld+json é‡Œæ‹¿ï¼ˆBarbour å®˜ç½‘å¸¸è§ï¼‰
    name = "No Data"
    sku = "No Data"
    for script in soup.find_all("script", type="application/ld+json"):
        data = _safe_json_loads(script.string or "")
        if isinstance(data, dict) and data.get("@type") == "Product":
            if data.get("name"):
                name = str(data["name"]).strip()
            if data.get("sku"):
                sku = str(data["sku"]).strip()
            break

    # æè¿°
    desc_tag = soup.find("div", {"id": "collapsible-description-1"})
    description = desc_tag.get_text(separator=" ", strip=True) if desc_tag else "No Data"
    if sku and sku != "No Data":
        description = description.replace(f"SKU: {sku}", "").strip() or "No Data"

    # Featuresï¼ˆå«ä¿å…»/æè´¨ç­‰ï¼‰
    features_tag = soup.find("div", class_="care-information")
    features = features_tag.get_text(separator=" | ", strip=True) if features_tag else "No Data"

    # ä»·æ ¼
    price = "0"
    price_tag = soup.select_one("span.sales span.value")
    if price_tag and price_tag.has_attr("content"):
        price = price_tag["content"]

    # é¢œè‰²
    color_tag = soup.select_one("span.selected-color")
    color = color_tag.get_text(strip=True).replace("(", "").replace(")", "") if color_tag else "No Data"

    # å°ºç æŒ‰é’®ï¼ˆæœ‰æ— è´§ï¼‰
    size_buttons = soup.select("div.size-wrapper button.size-button")
    size_map = {}
    for btn in size_buttons or []:
        size_text = btn.get_text(strip=True)
        if not size_text:
            continue
        disabled = ("disabled" in (btn.get("class") or [])) or btn.has_attr("disabled")
        size_map[size_text] = "æ— è´§" if disabled else "æœ‰è´§"

    # æ€§åˆ« / ä¸»ä½“æè´¨
    product_gender = _extract_gender_from_html(html)
    product_material = _extract_material_from_features(features)

    # â€”â€” ä»æŒ‰é’®ç›´æ¥æ„å»ºä¸¤è¡Œï¼ˆä¸å†™ SizeMapï¼›å¹¶è¿‡æ»¤ 52ï¼‰â€”â€”
    ps, psd = _build_size_lines_from_buttons(size_map, product_gender)

    # å¦‚å¯ç”¨ï¼Œç”¨ Barbour å‰ç¼€å†æ¬¡å…œåº•æ€§åˆ«
    if infer_gender_for_barbour:
        product_gender = infer_gender_for_barbour(
            product_code=sku,
            title=name,
            description=description,
            given_gender=product_gender,
        ) or product_gender or "ç”·æ¬¾"

    info = {
        "Product Code": sku,                 # âœ… å®˜ç½‘ SKU
        "Product Name": name,
        "Product Description": description,
        "Product Gender": product_gender,
        "Product Color": color,
        "Product Price": price,
        "Adjusted Price": price,             # ä¿ƒé”€ä»·ä¸å”®ä»·æš‚åŒ
        "Product Material": product_material,
        "Feature": features,
        "Product Size": ps,                  # âœ… ç›´æ¥ä¸¤è¡Œ
        "Product Size Detail": psd,
        # ä¸å†™ SizeMapï¼ˆæŒ‰ä½ çš„ç»Ÿä¸€è§„èŒƒï¼‰
        "Source URL": url,
        "Site Name": CANON_SITE,
        # ä¸ä¼  Style Category â†’ äº¤ç»™ txt_writer åšç»Ÿä¸€æ¨æ–­
    }
    return info

# ---------- ä¸»æµç¨‹ï¼ˆä¿æŒå‡½æ•°åï¼‰ ----------
def barbour_fetch_info():
    links_file = BARBOUR["LINKS_FILE"]
    txt_output_dir = Path(BARBOUR["TXT_DIR"])
    txt_output_dir.mkdir(parents=True, exist_ok=True)

    with open(links_file, "r", encoding="utf-8") as f:
        urls = [line.strip() for line in f if line.strip()]

    print(f"ğŸ“„ å…± {len(urls)} ä¸ªå•†å“é¡µé¢å¾…è§£æ...")

    for idx, url in enumerate(urls, 1):
        try:
            resp = requests.get(url, headers=HEADERS, timeout=25)
            resp.raise_for_status()
            info = extract_product_info_from_html(resp.text, url)

            # æ–‡ä»¶åï¼šç”¨ SKUï¼ˆæ— åˆ™ç”¨å®‰å…¨åŒ–æ ‡é¢˜ï¼‰
            code_for_file = info.get("Product Code") or re.sub(r"[^A-Za-z0-9\-]+", "_", info.get("Product Name", "NoCode"))
            txt_path = txt_output_dir / f"{code_for_file}.txt"

            # âœ… ç»Ÿä¸€å†™å‡ºï¼ˆå’Œå…¶å®ƒç«™ç‚¹å®Œå…¨ä¸€è‡´ï¼‰
            format_txt(info, txt_path, brand="Barbour")
            print(f"âœ… [{idx}/{len(urls)}] å†™å…¥æˆåŠŸï¼š{txt_path.name}")

        except Exception as e:
            print(f"âŒ [{idx}/{len(urls)}] å¤±è´¥ï¼š{url}ï¼Œé”™è¯¯ï¼š{e}")

if __name__ == "__main__":
    barbour_fetch_info()
