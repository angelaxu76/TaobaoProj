# barbour/supplier/allweathers_get_links.py

import time
from bs4 import BeautifulSoup
import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from pathlib import Path
from config import BARBOUR

# === é¡µé¢ä¸è¾“å‡ºé…ç½® ===
BASE_URL = "https://www.allweathers.co.uk/collections/barbour"
PAGE_TEMPLATE = BASE_URL + "?page={}"
OUTPUT_PATH = BARBOUR["LINKS_FILES"]["allweathers"]
OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)

def get_driver():
    options = uc.ChromeOptions()
    options.add_argument("--headless=new")  # âœ… å¯ç”¨æ–°ç‰ˆæ— å¤´æ¨¡å¼
    options.add_argument("--disable-gpu")
    options.add_argument("--window-size=1920,1080")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-blink-features=AutomationControlled")
    return uc.Chrome(options=options, use_subprocess=True)

def extract_links_from_html(html: str):
    soup = BeautifulSoup(html, "html.parser")
    links = set()
    for tag in soup.select("a.product-title.h6"):
        href = tag.get("href", "").strip()
        if href.startswith("http"):
            links.add(href)
        elif href.startswith("/"):
            links.add("https://www.allweathers.co.uk" + href)
    return links

def allweathers_get_links():
    print("ğŸš€ å¼€å§‹æŠ“å– Allweathers å•†å“é“¾æ¥")
    driver = get_driver()
    all_links = set()
    page = 1

    while True:
        url = PAGE_TEMPLATE.format(page)
        print(f"ğŸŒ æŠ“å–ç¬¬ {page} é¡µ: {url}")
        driver.get(url)

        try:
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "a.product-title.h6"))
            )
        except:
            print(f"âš ï¸ ç¬¬ {page} é¡µåŠ è½½è¶…æ—¶æˆ–æ— å•†å“ï¼Œç»ˆæ­¢")
            break

        html = driver.page_source
        links = extract_links_from_html(html)

        if not links:
            print(f"âš ï¸ ç¬¬ {page} é¡µæœªæå–åˆ°é“¾æ¥ï¼Œç»ˆæ­¢")
            break

        print(f"âœ… ç¬¬ {page} é¡µæå– {len(links)} ä¸ªå•†å“é“¾æ¥")
        all_links.update(links)
        page += 1
        time.sleep(1)

    driver.quit()

    # å†™å…¥æ–‡ä»¶
    OUTPUT_PATH.write_text("\n".join(sorted(all_links)), encoding="utf-8")
    print(f"\nğŸ¯ å…±æå– {len(all_links)} æ¡å•†å“é“¾æ¥ï¼Œå·²ä¿å­˜è‡³ï¼š{OUTPUT_PATH}")

if __name__ == "__main__":
    allweathers_get_links()
