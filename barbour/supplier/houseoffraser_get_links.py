# barbour/supplier/houseoffraser_get_links.py

import time
from pathlib import Path
from bs4 import BeautifulSoup
import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from config import BARBOUR

# é…ç½®åˆ†é¡µåœ°å€å’Œè¾“å‡ºè·¯å¾„
BASE_URL = "https://www.houseoffraser.co.uk/brand/barbour/coats-and-jackets"
PAGE_URL_TEMPLATE = BASE_URL + "#dcp={}&dppp=59&OrderBy=rank"
OUTPUT_PATH = BARBOUR["LINKS_FILES"]["houseoffraser"]
OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)


def get_driver():
    options = uc.ChromeOptions()
    # ğŸ‘‰ å¦‚éœ€é™é»˜è¿è¡Œå¯å¯ç”¨ headless
    # options.add_argument("--headless=new")
    options.add_argument("--disable-gpu")
    options.add_argument("--window-size=1920,1080")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-blink-features=AutomationControlled")
    driver = uc.Chrome(options=options, use_subprocess=True)
    return driver


def extract_links_from_html(html: str):
    soup = BeautifulSoup(html, "html.parser")
    links = set()
    for tag in soup.select("a.ProductImageList"):
        href = tag.get("href", "").strip()
        if href.startswith("http"):
            links.add(href)
        elif href.startswith("/"):
            links.add("https://www.houseoffraser.co.uk" + href)
    return links


def houseoffraser_get_links():
    print("ğŸš€ å¼€å§‹æŠ“å– House of Fraser å•†å“é“¾æ¥")
    driver = get_driver()
    all_links = set()
    page = 1

    while True:
        page_url = PAGE_URL_TEMPLATE.format(page)
        print(f"ğŸŒ æŠ“å–ç¬¬ {page} é¡µ: {page_url}")
        driver.get(page_url)

        try:
            # æ˜¾å¼ç­‰å¾…å•†å“å…ƒç´ åŠ è½½
            WebDriverWait(driver, 15).until(
                EC.presence_of_element_located((By.CLASS_NAME, "ProductImageList"))
            )
        except Exception as e:
            print(f"âš ï¸ ç¬¬ {page} é¡µç­‰å¾…è¶…æ—¶æˆ–æ— å•†å“ï¼Œç»ˆæ­¢æŠ“å–")
            break

        html = driver.page_source
        links = extract_links_from_html(html)
        if not links:
            print(f"âš ï¸ ç¬¬ {page} é¡µæœªæå–åˆ°é“¾æ¥ï¼Œç»ˆæ­¢")
            break

        print(f"âœ… ç¬¬ {page} é¡µæå– {len(links)} ä¸ªå•†å“é“¾æ¥")
        all_links.update(links)
        page += 1

    driver.quit()

    # å†™å…¥å»é‡åé“¾æ¥åˆ°æ–‡ä»¶
    OUTPUT_PATH.write_text("\n".join(sorted(all_links)), encoding="utf-8")
    print(f"\nğŸ¯ å…±æå– {len(all_links)} æ¡å•†å“é“¾æ¥ï¼Œå·²ä¿å­˜è‡³ï¼š{OUTPUT_PATH}")


if __name__ == "__main__":
    houseoffraser_get_links()
