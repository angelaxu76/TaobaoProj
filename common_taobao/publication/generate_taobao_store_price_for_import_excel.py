# -*- coding: utf-8 -*-
"""
é€ SKU å¯¼å‡ºåº—é“ºä»·æ ¼ï¼ˆæ”¯æŒæ‰¹é‡ï¼‰
- å•æ–‡ä»¶ï¼šä¿æŒ generate_price_excel(brand, input_dir, output_path) åŸè¡Œä¸ºä¸å˜ï¼ˆå– input_dir å†…â€œæœ€è¿‘ä¿®æ”¹â€çš„ä¸€ä¸ªExcelï¼‰
- æ‰¹é‡ï¼šæ–°å¢ generate_price_excels_bulk(brand, input_dir, output_dir, suffix)
  * å¤„ç† input_dir ä¸‹æ‰€æœ‰ *.xlsx / *.xls
  * è¾“å‡ºæ–‡ä»¶å = è¾“å…¥æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰ + suffix + ".xlsx"
  * æ¯ä¸ªæ–‡ä»¶ç‹¬ç«‹æŸ¥ä»·ã€ç‹¬ç«‹å¯¼å‡ºï¼Œå•ä¸ªå¤±è´¥ä¸å½±å“å…¶å®ƒæ–‡ä»¶
- åˆ—è¯†åˆ«ï¼šå®è´ID(=item_id)ã€å•†å®¶ç¼–ç (=product_code)ã€skuID(=skuid)
- ä»·æ ¼æ¥æºï¼šå“ç‰Œè¡¨ä¸­çš„ taobao_store_priceï¼ˆä¼˜å…ˆ product_codeï¼›å…œåº• product_nameï¼‰
- è¾“å‡ºä¸‰åˆ—ï¼šå®è´id | skuid | è°ƒæ•´åä»·æ ¼
"""
from pathlib import Path
import unicodedata
import re
from typing import List, Dict, Optional, Iterable, Tuple
import pandas as pd
import psycopg2
import math

from config import BRAND_CONFIG

# ===== åˆ—ååˆ«å =====
COL_ALIASES = {
    "item_id": {"item_id","itemid","ITEM_ID","å®è´id","å®è´ID","å®è´Id","å®è´"},
    "product_code": {
        "product_code","productcode","code",
        "å•†å“ç¼–ç ","å•†å“Code","äº§å“ç¼–ç ","ç¼–ç ","è´§å·",
        "å•†å®¶ç¼–ç ",
        "å•†å®¶è´§å·","å¤–éƒ¨ç¼–ç ","å¤–éƒ¨ä»£ç ",
        "outer_id","outerid","outer code","outercode"
    },
    "skuid": {
        "skuid","sku_id","SkuId","SKU_ID","SKUID",
        "skuID",
        "æ¸ é“è´§å“ID","æ¸ é“skuid","è´§å“id","è´§å“ID"
    },
}

_SPLIT = re.compile(r"[,\uFF0C;ï¼›\s\r\n]+")


import pandas as pd

import pandas as pd
from pathlib import Path

def _load_blacklist_codes(blacklist_excel_file: str | None) -> set[str]:
    """
    ä» blacklist_excel_file è¯»å–é»‘åå•å•†å“ç¼–ç åˆ—è¡¨ã€‚
    å¦‚æœ blacklist_excel_file æ˜¯ None æˆ–æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™è¿”å›ç©ºé›†åˆï¼Œè¡¨ç¤ºä¸å¯ç”¨é»‘åå•ã€‚
    """
    if not blacklist_excel_file:
        # æ²¡ä¼ ï¼Œç­‰äºä¸å¯ç”¨é»‘åå•
        print("[BLACKLIST] æœªæä¾›é»‘åå•æ–‡ä»¶ï¼Œé»‘åå•ä¸ºç©º")
        return set()

    path_obj = Path(blacklist_excel_file)
    if not path_obj.exists():
        print(f"[BLACKLIST] é»‘åå•æ–‡ä»¶ä¸å­˜åœ¨: {blacklist_excel_file}ï¼Œé»‘åå•ä¸ºç©º")
        return set()

    df_blk = pd.read_excel(path_obj)

    candidate_cols = [
        "å•†å“ç¼–ç ",
        "product_code",
        "å•†å®¶ç¼–ç ",
        "å¤–éƒ¨å•†å“ç¼–ç ",
        "å•†å®¶è´§å·",
        "è´§å·",
        "ç¼–ç ",
    ]

    col_found = None
    for c in candidate_cols:
        if c in df_blk.columns:
            col_found = c
            break

    if col_found is None:
        print("[BLACKLIST] æœªæ‰¾åˆ°å¯è¯†åˆ«çš„é»‘åå•åˆ—ï¼Œé»‘åå•ä¸ºç©º")
        return set()

    codes = (
        df_blk[col_found]
        .astype(str)
        .str.strip()
        .replace({"": pd.NA})
        .dropna()
        .unique()
        .tolist()
    )

    blacklist = {c.upper() for c in codes}
    print(f"[BLACKLIST] è¯»å–åˆ° {len(blacklist)} ä¸ªé»‘åå•å•†å“ç¼–ç ")
    return blacklist



import psycopg2
from psycopg2.extras import execute_values

from psycopg2.extras import execute_values

def _fetch_prices_by_code_and_size_bulk(
    conn,
    table: str,
    code_size_pairs: list[tuple[str, str]]
) -> pd.DataFrame:
    """
    æ‰¹é‡ä» {table} é‡Œæ‹¿ (product_code, size) å¯¹åº”çš„ taobao_store_priceã€‚
    å…³é”®ç‚¹ï¼š
    - ä¸å†ä½¿ç”¨ execute_valuesï¼ˆä¹‹å‰åªæ‹¿åˆ°æœ€åä¸€æ‰¹ï¼Œå¯¼è‡´ä¸¥é‡ä¸¢ä»·ï¼‰
    - æ‰‹åŠ¨åˆ†æ‰¹ï¼Œæ¯æ‰¹ç”¨ WITH wanted AS (VALUES ...) JOINï¼Œé€æ‰¹æ‰§è¡Œ cur.execute()
    - æ±‡æ€»æ‰€æœ‰æ‰¹æ¬¡è¿”å›ï¼Œå»é‡åè¾“å‡º DataFrame
    """

    # 1. å…ˆæŠŠè¾“å…¥è§„æ ¼æ¸…æ´—æˆç¨³å®šå­—ç¬¦ä¸²é”®ï¼Œé˜²æ­¢ '16 ' / None ç­‰è„å€¼
    cleaned_pairs = []
    for code, sz in code_size_pairs:
        if code is None or sz is None:
            continue
        c = str(code).strip()
        s = str(sz).strip()
        if c and s:
            cleaned_pairs.append((c, s))

    # å»é‡ï¼Œé¿å…åŒä¸€ä¸ª (code,size) é‡å¤æŸ¥
    unique_pairs = sorted(set(cleaned_pairs))
    if not unique_pairs:
        return pd.DataFrame(columns=["product_code", "size", "taobao_store_price"])

    print(f"[PRICEDEBUG] å¾…æŸ¥è¯¢ç»„åˆæ€»æ•°: {len(cleaned_pairs)}ï¼Œå»é‡å: {len(unique_pairs)}")

    # 2. åˆ†æ‰¹ï¼Œæ¯æ‰¹ 50 ä¸ª (code,size)
    CHUNK_SIZE = 50
    all_rows: list[tuple[str, str, float]] = []

    with conn.cursor() as cur:
        total_batches = (len(unique_pairs) + CHUNK_SIZE - 1) // CHUNK_SIZE

        for batch_idx, start in enumerate(range(0, len(unique_pairs), CHUNK_SIZE), start=1):
            batch = unique_pairs[start:start + CHUNK_SIZE]

            # ç”¨ mogrify æŠŠæ¯æ¡ (code,size) å˜æˆå®‰å…¨çš„ SQL ('CODE','SIZE') ç‰‡æ®µ
            values_sql_list = [
                cur.mogrify("(%s,%s)", (code, size)).decode("utf-8")
                for code, size in batch
            ]
            values_sql_block = ",".join(values_sql_list)

            # æ„é€ æœ¬æ‰¹ SQL
            query_sql = (
                f"WITH wanted(code,size) AS (VALUES {values_sql_block}) "
                f"SELECT t.product_code, t.size, t.taobao_store_price "
                f"FROM {table} t "
                "JOIN wanted w ON t.product_code = w.code AND t.size = w.size"
            )

            # Debug: æ‰“å°æœ¬æ‰¹çš„å…³é”®ä¿¡æ¯ï¼ˆä¸ä¼šå¤ªåµï¼‰
            print("\n[DEBUG SQL BATCH]")
            print(f"  æ‰¹æ¬¡ {batch_idx}/{total_batches}, æœ¬æ‰¹ç»„åˆæ•°: {len(batch)}")
            print(f"  ç¤ºä¾‹VALUESå‰5ä¸ª: {', '.join(values_sql_list[:5])}")

            # çœŸæ­£æ‰§è¡Œ
            cur.execute(query_sql)
            batch_rows = cur.fetchall()
            print(f"  -> æœ¬æ‰¹è¿”å› {len(batch_rows)} è¡Œ")

            all_rows.extend(batch_rows)

    print(f"[PRICEDEBUG] å…¨éƒ¨åˆ†æ‰¹åˆè®¡è¿”å› {len(all_rows)} è¡Œ")

    # 3. æ±‡æ€»å¹¶å»é‡ (é˜²æ­¢åŒä¸€ä¸ª (product_code,size) å¤šæ¬¡å‡ºç°)
    merged_unique = {}
    for (product_code, size, price_val) in all_rows:
        key = (str(product_code).strip(), str(size).strip())
        if key not in merged_unique:
            merged_unique[key] = price_val  # ç¬¬ä¸€æ¡ä¸ºå‡†

    rows_for_df = [
        {
            "product_code": pc,
            "size": sz,
            "taobao_store_price": price_val,
        }
        for (pc, sz), price_val in merged_unique.items()
    ]

    df_price = pd.DataFrame(
        rows_for_df,
        columns=["product_code", "size", "taobao_store_price"]
    )

    print(f"[PRICEDEBUG] å»é‡åæœ€ç»ˆä»·æ ¼è¡Œæ•°: {len(df_price)}")
    return df_price




def _canon(s: str) -> str:
    if s is None: return ""
    s = unicodedata.normalize("NFKC", str(s)).strip()
    s = s.replace("\u00A0", " ").replace("\u200B", "")
    return s.lower()

def _normalize_col(df: pd.DataFrame, want: str) -> str:
    canon2raw = {_canon(c): c for c in df.columns}
    for alias in COL_ALIASES[want]:
        key = _canon(alias)
        if key in canon2raw:
            return canon2raw[key]
    raise KeyError(f"Excelä¸­ç¼ºå°‘å¿…è¦åˆ—ï¼š{want}ï¼ˆå¯ç”¨åˆ«åï¼š{COL_ALIASES[want]}ï¼‰ï¼Œå½“å‰è¡¨å¤´ï¼š{list(df.columns)}")

def _list_excels(input_dir: Path) -> List[Path]:
    files = list(input_dir.glob("*.xlsx")) + list(input_dir.glob("*.xls"))
    return sorted(files, key=lambda p: p.stat().st_mtime, reverse=True)

def _find_latest_excel(input_dir: Path) -> Path:
    files = _list_excels(input_dir)
    if not files:
        raise FileNotFoundError(f"ç›®å½•æ²¡æœ‰æ‰¾åˆ° Excelï¼š{input_dir}")
    return files[0]

def _split_skuids(val) -> List[str]:
    if pd.isna(val): return []
    if isinstance(val, (int, float)) and not isinstance(val, bool):
        val = str(int(val))
    s = str(val).strip()
    if not s: return []
    parts = [p.strip() for p in _SPLIT.split(s) if p.strip()]
    parts = [re.sub(r"[^\w\-]", "", p) for p in parts if p]
    return [p for p in parts if p]

def _chunked(it: Iterable, size: int):
    buf = []
    for x in it:
        buf.append(x)
        if len(buf) >= size:
            yield buf; buf = []
    if buf: yield buf

def _fetch_prices(conn, table: str, codes: List[str]) -> Dict[str, Optional[float]]:
    prices: Dict[str, Optional[float]] = {}
    missing = list(dict.fromkeys(codes))
    with conn.cursor() as cur:
        try:
            for chunk in _chunked(missing, 1000):
                cur.execute(
                    f"SELECT product_code, taobao_store_price FROM {table} "
                    f"WHERE product_code = ANY(%s)", (chunk,))
                for code, price in cur.fetchall():
                    prices[str(code)] = None if price is None else float(price)
            missing = [c for c in missing if c not in prices]
        except Exception:
            pass
        if missing:
            try:
                for chunk in _chunked(missing, 1000):
                    cur.execute(
                        f"SELECT product_name, taobao_store_price FROM {table} "
                        f"WHERE product_name = ANY(%s)", (chunk,))
                    for code, price in cur.fetchall():
                        prices[str(code)] = None if price is None else float(price)
            except Exception:
                pass
    return prices

def _to_text(v: object) -> str:
    if v is None or (isinstance(v, float) and (math.isnan(v))):
        return ""
    if isinstance(v, (int,)):
        return str(v)
    if isinstance(v, float):
        if v.is_integer():
            return str(int(v))
        return f"{v:.15g}"
    if isinstance(v, pd._libs.missing.NAType) or (isinstance(v, str) and v.lower() == "nan"):
        return ""
    return str(v)

# ===== å•æ–‡ä»¶ï¼šä¿æŒå…¼å®¹ =====
def generate_price_excel(
    brand: str,
    input_dir: str | Path,
    output_path: str | Path,
    drop_rows_without_price: bool = True
) -> Path:
    brand = brand.lower().strip()
    if brand not in BRAND_CONFIG:
        raise ValueError(f"æœªçŸ¥å“ç‰Œï¼š{brand}")
    cfg = BRAND_CONFIG[brand]
    table = cfg["TABLE_NAME"]
    pg    = cfg["PGSQL_CONFIG"]

    input_dir = Path(input_dir)
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    excel_file = _find_latest_excel(input_dir)
    print(f"ğŸ“„ ä½¿ç”¨è¾“å…¥æ–‡ä»¶ï¼š{excel_file}")
    return _generate_price_excel_from_file(brand, excel_file, output_path, drop_rows_without_price, table, pg)

# ===== æ‰¹é‡ï¼šå¤„ç† input_dir ä¸‹æ‰€æœ‰ Excel =====
def generate_price_excels_bulk(
    brand: str,
    input_dir: str,
    output_dir: str,
    suffix: str = "_ä»·æ ¼",
    drop_rows_without_price: bool = True,
    blacklist_excel_file: str | None = None,
):
    """
    ä» input_dir ä¸­æ‰¹é‡è¯»å–åº—é“º Excelï¼ˆæ¯ä¸ªä»£è¡¨ä¸€ä¸ªåº—é“ºï¼‰ï¼Œ
    è°ƒç”¨ _generate_price_excel_from_file() ç”Ÿæˆå¯¹åº”ä»·æ ¼è¡¨ï¼Œ
    å¹¶è¾“å‡ºåˆ° output_dirã€‚

    æ–°å¢å‚æ•°:
        blacklist_excel_file: é»‘åå• Excel çš„ç»å¯¹è·¯å¾„ã€‚
                              å¦‚æœæä¾›ï¼Œåˆ™ä¼šè¿‡æ»¤æ‰é»‘åå•å•†å“ç¼–ç ã€‚
                              å¦‚æœä¸º Noneï¼Œåˆ™ä¸å¯ç”¨é»‘åå•ã€‚
    """

    input_dir = Path(input_dir)
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # æ•°æ®åº“é…ç½®
    from config import BRAND_CONFIG
    pgsql_config = BRAND_CONFIG[brand]["PGSQL_CONFIG"]
    table_name = BRAND_CONFIG[brand]["TABLE_NAME"]

    # æ‰¾å‡ºç›®å½•ä¸‹æ‰€æœ‰ Excel æ–‡ä»¶
    excel_files = list(input_dir.glob("*.xlsx"))
    if not excel_files:
        print(f"âš  æ²¡æ‰¾åˆ°ä»»ä½• Excel æ–‡ä»¶: {input_dir}")
        return

    print(f"[INFO] å…±å‘ç° {len(excel_files)} ä¸ªè¾“å…¥æ–‡ä»¶ï¼Œå°†ç”Ÿæˆä»·æ ¼è¡¨...")
    print(f"[INFO] å“ç‰Œ: {brand}")
    print(f"[INFO] é»‘åå•æ–‡ä»¶: {blacklist_excel_file or 'æœªå¯ç”¨'}")

    for f in excel_files:
        try:
            print(f"\n[START] å¤„ç†æ–‡ä»¶: {f.name}")
            _generate_price_excel_from_file(
                file_path=str(f),
                output_dir=str(output_dir),
                brand=brand,
                pgsql_config=pgsql_config,
                blacklist_excel_file=blacklist_excel_file,
                table_name=table_name,
            )
        except Exception as e:
            print(f"[ERROR] å¤„ç† {f.name} å¤±è´¥: {e}")

    print(f"\nâœ… æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆã€‚è¾“å‡ºè·¯å¾„: {output_dir}")





import pandas as pd
from pathlib import Path

def _normalize_input_columns(df: pd.DataFrame) -> pd.DataFrame:
    """
    æˆ‘ä»¬éœ€è¦æ‹¿åˆ°ä¸‰åˆ—ï¼š
    - item_id   (å®è´id)
    - skuid     (SKUå”¯ä¸€æ ‡è¯†ï¼Œæ¸ é“è´§å“ID)
    - sku_spec  (skuè§„æ ¼ï¼Œæ¯”å¦‚ 'MWX0339OL71,M')

    è¿™ä¸ªå‡½æ•°çš„ä½œç”¨æ˜¯ï¼šä»å„ç§å¯èƒ½çš„åˆ—åé‡ŒæŠ½å–å¹¶æ ‡å‡†åŒ–æˆè¿™ä¸‰åˆ—ã€‚
    """

    # å¯èƒ½çš„åˆ—åæ˜ å°„
    item_id_candidates = ["å®è´id", "å®è´ID", "item_id", "itemid", "itemId", "å•†å“ID", "item id"]
    skuid_candidates   = ["skuid", "SKU ID", "skuID", "SKUId", "æ¸ é“è´§å“ID", "æ¸ é“è´§å“id", "è´§å“id", "sku id"]
    spec_candidates    = ["skuè§„æ ¼", "SKUè§„æ ¼", "è§„æ ¼", "sku spec", "é”€å”®å±æ€§"]

    colmap = {}

    # æ‰¾ item_id
    for c in item_id_candidates:
        if c in df.columns:
            colmap["item_id"] = c
            break
    # æ‰¾ skuid
    for c in skuid_candidates:
        if c in df.columns:
            colmap["skuid"] = c
            break
    # æ‰¾ sku_spec
    for c in spec_candidates:
        if c in df.columns:
            colmap["sku_spec"] = c
            break

    missing = [name for name in ["item_id","skuid","sku_spec"] if name not in colmap]
    if missing:
        print("âš  è¾“å…¥Excelç¼ºå°‘å¿…è¦åˆ—:", missing)
        # æˆ‘ä»¬è¿˜æ˜¯å°½é‡è¿”å›ä¸€äº›åˆ—ï¼Œåé¢ä¼š dropna
    # å¤åˆ¶ä¸€ä»½åªä¿ç•™æˆ‘ä»¬å…³å¿ƒçš„åˆ—ï¼Œå¹¶é‡å‘½å
    df2 = df.copy()
    out = pd.DataFrame()
    out["item_id"] = df2[colmap["item_id"]] if "item_id" in colmap else pd.NA
    out["skuid"]   = df2[colmap["skuid"]]   if "skuid"   in colmap else pd.NA
    out["sku_spec"]= df2[colmap["sku_spec"]]if "sku_spec"in colmap else pd.NA

    return out


def _split_spec_value(spec_val: str) -> tuple[str|None, str|None]:
    """
    æŠŠ 'MWX0339OL71,M' è¿™ç§å€¼æ‹†æˆ ('MWX0339OL71','M')
    è¦æ±‚ï¼šç¬¬ä¸€ä¸ªé€—å·å‰ = å•†å“ç¼–ç 
          ç¬¬ä¸€ä¸ªé€—å·å = å°ºç 
    å¦‚æœæ²¡æœ‰é€—å·ï¼Œæˆ–ä¸ºç©ºï¼Œè¿”å› (None, None)
    """
    if not isinstance(spec_val, str):
        return (None, None)
    raw = spec_val.strip()
    if raw == "":
        return (None, None)
    parts = [p.strip() for p in raw.split(",")]
    if len(parts) < 2:
        # æ²¡æœ‰å°ºç ä¿¡æ¯ï¼Œè§†ä¸ºæ— æ•ˆ
        return (None, None)
    code_part = parts[0].strip().upper()
    size_part = parts[1].strip()
    if code_part == "" or size_part == "":
        return (None, None)
    return (code_part, size_part)





def _clean_spec_key(spec_val):
    if not isinstance(spec_val, str):
        return None
    v = spec_val.strip()
    return v if v else None


def _generate_price_excel_from_file(
    file_path: str,
    output_dir: str,
    brand: str,
    pgsql_config: dict,
    blacklist_excel_file: str | None,
    table_name: str = "barbour_inventory",
):
    print(f"\n[START] æ­£åœ¨å¤„ç†æ–‡ä»¶: {file_path}")

    # 1. é»‘åå•
    blacklist_codes = _load_blacklist_codes(blacklist_excel_file)

    # 2. è¯»è¾“å…¥Excelå¹¶æ ‡å‡†åŒ–åˆ—
    df_raw = pd.read_excel(file_path)
    print(f"[STATS] åŸå§‹Excelè¡Œæ•° df_raw: {len(df_raw)}")

    df_norm = _normalize_input_columns(df_raw)
    # æœŸæœ›: item_id, skuid, sku_spec
    print(f"[STATS] è§„èŒƒåŒ–å df_norm(åˆå§‹) è¡Œæ•°: {len(df_norm)}")

    # 2.1 æŒ‰excelç»“æ„å‘ä¸‹å¡«å……å®è´ID
    df_norm["item_id"] = df_norm["item_id"].ffill()

    # 2.2 æŠŠ item_id è½¬æˆå­—ç¬¦ä¸²ï¼Œé¿å…ç§‘å­¦è®¡æ•°æ³•
    def _item_id_to_str(val):
        if pd.isna(val):
            return ""
        if isinstance(val, (int, float)):
            ival = int(val)
            return str(ival)
        return str(val).strip()

    df_norm["item_id"] = df_norm["item_id"].map(_item_id_to_str)

    print(f"[STATS] df_norm(å¡«å……å®è´ID+è½¬å­—ç¬¦ä¸²å) è¡Œæ•°: {len(df_norm)}")
    print(f"[INFO] è¾“å…¥åˆ—: {list(df_norm.columns)}")
    print("[INFO] æ ·ä¾‹æ•°æ® (ffill+å­—ç¬¦ä¸²åŒ–å):")
    print(df_norm.head(10))

    # 3. sku_spec -> code_part / size_part
    pairs = df_norm["sku_spec"].map(_split_spec_value)
    df_norm["code_part"] = [p[0] for p in pairs]   # å•†å“ç¼–ç  (å¦‚ MWX0339OL71 / ä¹Ÿå¯èƒ½æ˜¯ 'æµ·å†›è“')
    df_norm["size_part"] = [p[1] for p in pairs]   # å°ºç  (å¦‚ 'M' / '10')
    df_norm["spec_key"]  = df_norm["sku_spec"].map(_clean_spec_key)

    before_drop = len(df_norm)
    df_norm = df_norm.dropna(subset=["code_part", "size_part"])
    after_drop = len(df_norm)
    print(f"[STATS] dropna(code_part/size_part): {before_drop} -> {after_drop}")

    # 4. é»‘åå•è¿‡æ»¤ï¼šæ•´æ¬¾ä¸è¦
    if len(blacklist_codes) > 0:
        before_blk = len(df_norm)
        df_norm = df_norm[~df_norm["code_part"].isin(blacklist_codes)]
        after_blk = len(df_norm)
        print(f"[STATS] é»‘åå•è¿‡æ»¤: {before_blk} -> {after_blk}")
    else:
        print("[STATS] é»‘åå•æœªå¯ç”¨ï¼Œè·³è¿‡è¿‡æ»¤")

    # 5. å±•å¼€ skuid
    # skuid æœ‰å¯èƒ½æ˜¯ "111,222,333" è¿™ç§å¤åˆï¼Œä¹Ÿå¯èƒ½æœ¬æ¥å°±ä¸€è¡Œä¸€ä¸ª
    rows = []
    for _, r in df_norm.iterrows():
        this_item_id = r["item_id"]        # å·²ç» ffill + str
        this_code    = r["code_part"]
        this_size    = r["size_part"]
        skus_raw     = r["skuid"]
        sku_list     = _split_skuids(skus_raw)

        # debug: çœ‹çœ‹æœ‰æ²¡æœ‰è¡Œæ ¹æœ¬è§£æä¸å‡º skuid
        if not sku_list:
            # æ‰“å°ä¸€æ¬¡ï¼Œè¿™è¡Œæ²¡æœ‰æœ‰æ•ˆ skuidï¼Œä¼šè¢«ä¸¢
            # ï¼ˆæ³¨æ„åˆ«æ‰“å¤ªå¤šï¼Œåªæ‰“å‰10ä¸ªï¼‰
            if len(rows) < 10:
                print(f"[WARN] ç©ºSKUè¡Œ? item_id={this_item_id}, code={this_code}, size={this_size}, raw_skuid={skus_raw}")

        for one_sku in sku_list:
            if one_sku:
                rows.append({
                    "item_id":   this_item_id,
                    "skuid":     one_sku,
                    "code_part": this_code,
                    "size_part": this_size,
                })

    df_expanded = pd.DataFrame(
        rows,
        columns=["item_id", "skuid", "code_part", "size_part"]
    )
    print(f"[STATS] å±•å¼€å df_expanded è¡Œæ•°: {len(df_expanded)}")
    if not df_expanded.empty:
        print(df_expanded.head(10))
    else:
        print(f"[WARN] {file_path} ç»è¿‡æ‹†åˆ†åæ²¡æœ‰ä»»ä½•æœ‰æ•ˆ SKU è¡Œï¼Œè·³è¿‡")
        return

    # 6. æ‰¹é‡æŸ¥ä»·æ ¼ (code_part + size_part)
    conn = psycopg2.connect(**pgsql_config)
    try:
        pairs_for_price = list(zip(df_expanded["code_part"], df_expanded["size_part"]))
        print(f"[STATS] éœ€è¦æŸ¥ä»·çš„å”¯ä¸€(code_part,size_part)ç»„åˆæ•°é‡: {len(set(pairs_for_price))}")
        df_price = _fetch_prices_by_code_and_size_bulk(
            conn,
            table_name,
            pairs_for_price
        )
    finally:
        conn.close()

    print(f"[STATS] df_price(æ•°æ®åº“è¿”å›ä»·æ ¼) è¡Œæ•°: {len(df_price)}")
    if not df_price.empty:
        print(df_price.head(10))

    # 7. åˆå¹¶ä»·æ ¼
    df_merged = df_expanded.merge(
        df_price,
        left_on=["code_part", "size_part"],
        right_on=["product_code", "size"],
        how="left"
    )
    print(f"[STATS] åˆå¹¶å df_merged è¡Œæ•°: {len(df_merged)}")
    # ç»Ÿè®¡ä¸€ä¸‹å¤šå°‘æ²¡æœ‰ä»·
    missing_price_mask = df_merged["taobao_store_price"].isna()
    missing_cnt = int(missing_price_mask.sum())
    have_cnt = len(df_merged) - missing_cnt
    print(f"[STATS] df_merged ä¸­æœ‰ä»· {have_cnt} è¡Œ / æ— ä»· {missing_cnt} è¡Œ")

    # ä½ å½“å‰è¦æ±‚ï¼šæ— ä»·è¡Œå¿…é¡»ä¸¢æ‰ï¼Œä¸å…è®¸ç©ºä»·æ ¼å‡ºç°åœ¨è¾“å‡ºExcel
    df_merged = df_merged.dropna(subset=["taobao_store_price"])
    print(f"[STATS] ä¸¢æ‰æ— ä»·å df_merged è¡Œæ•°: {len(df_merged)}")

    # 8. é€‰å‡ºæœ€ç»ˆä¸‰åˆ—
    df_final = df_merged[["item_id", "skuid", "taobao_store_price"]].copy()
    print(f"[STATS] df_final(åˆé€‰ä¸‰åˆ—) è¡Œæ•°: {len(df_final)}")

    df_final = df_final.rename(columns={
        "item_id": "å®è´id",
        "skuid": "skuid",
        "taobao_store_price": "è°ƒæ•´åä»·æ ¼",
    })

    # 9. å»é‡ skuid
    before_dedup = len(df_final)
    df_final = df_final.drop_duplicates(subset=["skuid"], keep="first")
    after_dedup = len(df_final)
    print(f"[STATS] å»é‡skuid: {before_dedup} -> {after_dedup}")

    # 10. å†ä¿é™©ï¼šå®è´id å¯¼å‡ºæ—¶æ˜¯å­—ç¬¦ä¸²
    df_final["å®è´id"] = df_final["å®è´id"].astype(str)

    print("[INFO] df_final é¢„è§ˆ:")
    print(df_final.head(20))

    # 11. å†™excel
    out_dir = Path(output_dir)
    out_dir.mkdir(parents=True, exist_ok=True)

    src_name = Path(file_path).stem
    out_path = out_dir / f"{src_name}_price.xlsx"

    df_final.to_excel(out_path, index=False)
    print(f"[DONE] å·²ç”Ÿæˆä»·æ ¼Excel: {out_path}")
    print(f"[STATS] å†™å…¥Excelçš„æœ€ç»ˆè¡Œæ•°: {len(df_final)}")










# ===== æ–°å¢ï¼šæ‰¹é‡å¯¼å‡º SKU åº“å­˜ =====
def generate_stock_excels_bulk(
    brand: str,
    input_dir: str | Path,
    output_dir: str | Path,
    suffix: str = "_åº“å­˜",
    in_stock_qty: int = 3,
    out_stock_qty: int = 0,
):
    """
    æ‰¹é‡æ ¹æ® input_dir ä¸‹çš„åº—é“ºå¯¼å‡ºè¡¨ç”Ÿæˆâ€œSKUID | è°ƒæ•´ååº“å­˜â€çš„ Excelã€‚
    è§„åˆ™ä¸ generate_price_excels_bulk ä¿æŒä¸€è‡´ï¼šä»…æŒ‰ product_code åˆå¹¶ï¼Œå…¨æ¬¾åŒå€¼ã€‚
    - æ•°æ®æ¥æºï¼š<TABLE_NAME> ä¸­çš„ taobao_store_price å­—æ®µï¼š
        * 'æœ‰è´§'  -> in_stock_qtyï¼ˆé»˜è®¤3ï¼‰
        * å…¶ä»–/ç©º -> out_stock_qtyï¼ˆé»˜è®¤0ï¼‰
    - è¾“å‡ºï¼š<è¾“å…¥æ–‡ä»¶å+suffix>.xlsxï¼Œåªæœ‰ä¸¤åˆ—ï¼šSKUID, è°ƒæ•´ååº“å­˜
    """
    import pandas as pd
    import psycopg2
    from pathlib import Path

    def _to_text(v):
        if v is None:
            return ""
        s = str(v).strip()
        return s

    def _list_excels(input_dir: Path):
        return (list(input_dir.glob("*.xlsx")) + list(input_dir.glob("*.xls")))

    def status_to_qty_from_price(val: str) -> int:
        # æŒ‰ä½ è¦æ±‚ï¼šå¦‚æœ taobao_store_price å­—æ®µæ–‡æœ¬ä¸ºâ€œæœ‰è´§â€ => 3ï¼Œå¦åˆ™ => 0
        #ï¼ˆæ³¨æ„ï¼šå¦‚æœè¯¥å­—æ®µåœ¨æŸäº›å“ç‰Œæ˜¯â€œæ•°å­—ä»·æ ¼â€ï¼Œæ­¤æ˜ å°„ä¼šå¤±çœŸï¼Œéœ€è¦æ”¹å› stock_statusï¼‰
        s = _to_text(val)
        return in_stock_qty if s == "æœ‰è´§" else out_stock_qty

    brand = brand.lower().strip()
    if brand not in BRAND_CONFIG:
        raise ValueError(f"æœªçŸ¥å“ç‰Œï¼š{brand}")
    cfg   = BRAND_CONFIG[brand]
    table = cfg["TABLE_NAME"]
    pg    = cfg["PGSQL_CONFIG"]

    input_dir  = Path(input_dir)
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # 1) æ‹‰å–â€œå¯å”®çŠ¶æ€â€å¹¶åšæ˜ å°„ï¼ˆä»…æŒ‰ product_codeï¼‰
    conn = psycopg2.connect(**pg)
    try:
        df_flag = pd.read_sql(f'SELECT product_code, taobao_store_price FROM {table}', conn)
    finally:
        conn.close()

    if "product_code" not in df_flag.columns:
        raise RuntimeError(f"{table} ç¼ºå°‘ product_code åˆ—")

    df_flag["product_code"] = df_flag["product_code"].astype(str).str.strip()
    # ç»Ÿä¸€æ˜ å°„ä¸ºæ•°é‡
    df_flag["è°ƒæ•´ååº“å­˜"] = df_flag["taobao_store_price"].map(status_to_qty_from_price)
    # æŒ‰æ¬¾èšåˆï¼ˆè‹¥åŒä¸€æ¬¾å¤šè¡Œï¼Œå–æœ€å¤§â€”â€”ç­‰ä»·â€œåªè¦æœ‰ä¸€è¡Œæœ‰è´§åˆ™æœ‰è´§â€ï¼‰
    qty_by_code = (
        df_flag.groupby("product_code")["è°ƒæ•´ååº“å­˜"].max()
               .reset_index()
    )

    # 2) æ‰«æè¾“å…¥ç›®å½•
    files = _list_excels(input_dir)
    if not files:
        raise FileNotFoundError(f"ç›®å½•æ²¡æœ‰æ‰¾åˆ° Excelï¼š{input_dir}")

    results = []
    for f in sorted(files, key=lambda p: p.stat().st_mtime, reverse=True):
        try:
            df0 = pd.read_excel(f, dtype=object)

            # å¤ç”¨ä½ ç°æœ‰çš„åˆ—ååˆ«åè§£æ
            col_item = _normalize_col(df0, "item_id")        # å®è´id
            col_code = _normalize_col(df0, "product_code")   # å•†å®¶ç¼–ç 
            col_sku  = _normalize_col(df0, "skuid")          # skuID

            # å±•å¼€ SKU è¡Œï¼ˆä¸ä»·æ ¼å¯¼å‡ºä¸€è‡´ï¼šåªæŒ‰ product_code åˆå¹¶ï¼Œä¸çœ‹å°ºç ï¼‰
            rows = []
            for _, r in df0.iterrows():
                item_id = _to_text(r.get(col_item))
                code    = _to_text(r.get(col_code))
                skus    = _split_skuids(r.get(col_sku))
                for sid in skus:
                    sid = _to_text(sid)
                    if sid:
                        rows.append((item_id, code, sid))

            if not rows:
                raise ValueError(f"{f.name} æ— æœ‰æ•ˆ SKU è®°å½•ï¼ˆæ£€æŸ¥å®è´ID/å•†å®¶ç¼–ç /skuIDï¼‰ã€‚")

            df_expanded = pd.DataFrame(rows, columns=["å®è´id", "product_code", "skuid"])
            df_expanded["product_code"] = df_expanded["product_code"].astype(str).str.strip()

            # ä»…æŒ‰ product_code åˆå¹¶åº“å­˜æ•°é‡ï¼ˆä¸ä»·æ ¼å¯¼å‡ºç›¸åŒåˆå¹¶ç²’åº¦ï¼‰
            df_tmp = df_expanded.merge(qty_by_code, on="product_code", how="left")
            df_tmp["è°ƒæ•´ååº“å­˜"] = df_tmp["è°ƒæ•´ååº“å­˜"].fillna(out_stock_qty).astype(int)

            # è¾“å‡ºä¸¤åˆ—
            out_df = df_tmp[["skuid", "è°ƒæ•´ååº“å­˜"]]
            out_name = f.stem + (suffix or "")
            if not out_name.endswith(".xlsx"):
                out_name += ".xlsx"
            out_path = output_dir / out_name
            out_df.to_excel(out_path, index=False)

            print(f"âœ… {f.name} -> {out_name} (rows={len(out_df)})")
            results.append((str(f), str(out_path), len(out_df), None))
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥ï¼š{f} | é”™è¯¯ï¼š{e}")
            results.append((str(f), None, 0, str(e)))

    return results



if __name__ == "__main__":
    # ç”¨æ³•ä¸€ï¼šå•æ–‡ä»¶ï¼ˆä¿æŒå…¼å®¹ï¼‰
    #   python this_script.py <brand> <input_dir> <output_excel_path>
    # ç”¨æ³•äºŒï¼šæ‰¹é‡ï¼ˆæ¨èä½ ç°åœ¨çš„åœºæ™¯ï¼‰
    #   python this_script.py <brand> <input_dir> <output_dir> --bulk [--suffix "_ä»·æ ¼"]
    import sys, traceback
    try:
        if len(sys.argv) >= 5 and sys.argv[4] == "--bulk":
            brand = sys.argv[1]
            input_dir = sys.argv[2]
            output_dir = sys.argv[3]
            suffix = "_ä»·æ ¼"
            if len(sys.argv) >= 7 and sys.argv[5] == "--suffix":
                suffix = sys.argv[6]
            results = generate_price_excels_bulk(brand, input_dir, output_dir, suffix=suffix, drop_rows_without_price=True)
            ok = [r for r in results if r[1] is not None]
            bad = [r for r in results if r[1] is None]
            print(f"ğŸ“¦ æ‰¹é‡å®Œæˆï¼šæˆåŠŸ {len(ok)} ä¸ªï¼Œå¤±è´¥ {len(bad)} ä¸ª")
            if bad:
                print("å¤±è´¥æ¸…å•ï¼š")
                for f, _, err in bad:
                    print(f" - {f} -> é”™è¯¯ï¼š{err}")
        elif len(sys.argv) >= 4:
            generate_price_excel(sys.argv[1], sys.argv[2], sys.argv[3])
        else:
            print("ç”¨æ³•ï¼š")
            print("  å•æ–‡ä»¶ï¼špython this_script.py <brand> <input_dir> <output_excel_path>")
            print('  æ‰¹  é‡ï¼špython this_script.py <brand> <input_dir> <output_dir> --bulk [--suffix "_ä»·æ ¼"]')
    except Exception as e:
        print("âŒ å¤±è´¥ï¼š", e)
        traceback.print_exc()
