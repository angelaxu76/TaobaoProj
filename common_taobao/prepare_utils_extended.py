import pandas as pd
import shutil
import psycopg2
from common_taobao.core.translate import safe_translate
from common_taobao.core.price_utils import calculate_discount_price
from common_taobao.core.txt_parser import extract_product_info
from common_taobao.core.image_utils import copy_images_by_code

def get_publishable_product_codes(config: dict, store_name: str) -> list:
    conn = psycopg2.connect(**config["PGSQL_CONFIG"])
    table_name = config["TABLE_NAME"]
    txt_dir = config["TXT_DIR"]

    # åªè·å–å½“å‰åº—é“º stock_name ä¸‹çš„æœªå‘å¸ƒå•†å“ï¼Œä¸”è¯¥åº—é“ºæœªå‘å¸ƒè¿‡è¯¥ç¼–ç çš„ä»»ä½•å°ºç 
    query = f"""
        SELECT product_name
        FROM {table_name}
        WHERE stock_name = %s AND is_published = FALSE
        GROUP BY product_name
        HAVING COUNT(*) = COUNT(*)  -- å¼ºåˆ¶å¯ç”¨ GROUP BY
            AND product_name NOT IN (
                SELECT DISTINCT product_name FROM {table_name}
                WHERE stock_name = %s AND is_published = TRUE
            )
    """
    df = pd.read_sql(query, conn, params=(store_name, store_name))
    candidate_codes = df["product_name"].unique().tolist()

    # æ£€æŸ¥ TXT æ–‡ä»¶ä¸­æ˜¯å¦å­˜åœ¨ 3 ä¸ªä»¥ä¸Š :æœ‰è´§ çš„å°ºç 
    def has_3_or_more_instock(code):
        try:
            txt_path = txt_dir / f"{code}.txt"
            if not txt_path.exists():
                return False
            lines = txt_path.read_text(encoding="utf-8").splitlines()
            size_line = next((line for line in lines if line.startswith("Product Size:")), "")
            return size_line.count(":æœ‰è´§") >= 3
        except:
            return False

    result = [code for code in candidate_codes if has_3_or_more_instock(code)]
    print(f"ğŸŸ¢ åº—é“ºã€{store_name}ã€‘å¾…å‘å¸ƒå•†å“æ•°: {len(result)}")
    return result


def generate_product_excels(config: dict, store_name: str):
    from openpyxl import Workbook
    txt_dir = config["TXT_DIR"]
    output_dir = config["OUTPUT_DIR"] / store_name
    output_dir.mkdir(parents=True, exist_ok=True)
    image_dir = config["IMAGE_DIR"]
    image_output_dir = output_dir / "images"
    image_output_dir.mkdir(parents=True, exist_ok=True)

    codes = get_publishable_product_codes(config, store_name)
    if not codes:
        print("âš ï¸ æ²¡æœ‰å¯å‘å¸ƒå•†å“")
        return

    # ä»æ•°æ®åº“è·å– gender + æ­£ç¡®ä»·æ ¼å­—æ®µ
    conn = psycopg2.connect(**config["PGSQL_CONFIG"])
    table = config["TABLE_NAME"]
    query = f"""
        SELECT product_name, gender, original_price_gbp, discount_price_gbp
        FROM {table}
        WHERE stock_name = %s
    """
    df = pd.read_sql(query, conn, params=(store_name,))
    price_map = {
        row["product_name"]: {
            "gender": row["gender"],
            "Price": row["original_price_gbp"],
            "AdjustedPrice": row["discount_price_gbp"]
        }
        for _, row in df.iterrows()
    }

    records = []
    for code in codes:
        info = extract_product_info(txt_dir / f"{code}.txt")
        info.update(price_map.get(code, {}))
        gender = info.get("gender", "unknown").lower()
        eng_title = info.get("Product Name", "No Data")
        cn_title = safe_translate(eng_title)
        upper = info.get("Upper Material", "No Data")
        price = calculate_discount_price(info)
        category = classify_shoe(eng_title + " " + info.get("Product Description", ""))
        records.append({
            "gender": gender,
            "category": category,
            "å•†å“åç§°": cn_title,
            "å•†å“ç¼–ç ": code,
            "ä»·æ ¼": price,
            "up material": upper,
            "è‹±æ–‡åç§°": eng_title
        })
        copy_images_by_code(code, image_dir, image_output_dir)

    df = pd.DataFrame(records)
    df = df[["å•†å“åç§°", "å•†å“ç¼–ç ", "ä»·æ ¼", "up material", "è‹±æ–‡åç§°", "gender", "category"]]

    from collections import defaultdict
    group_map = defaultdict(list)
    for rec in records:
        group_map[(rec["gender"], rec["category"])].append(rec["å•†å“ç¼–ç "])

    for (gender, category), code_list in group_map.items():
        part = df[df["å•†å“ç¼–ç "].isin(code_list)].drop(columns=["gender", "category"])
        if not part.empty:
            wb = Workbook()
            ws = wb.active
            ws.title = "å•†å“å‘å¸ƒ"
            ws.append(part.columns.tolist())
            for row in part.itertuples(index=False):
                ws.append(row)
            save_path = output_dir / f"{gender}-{category}.xlsx"
            wb.save(save_path)
            print(f"âœ… å·²å¯¼å‡º: {save_path.name}")

def classify_shoe(text: str):
    text = text.lower()
    if any(k in text for k in ["boot", "chelsea", "ankle", "chukka"]):
        return "é´å­"
    elif any(k in text for k in ["sandal", "slide", "å‡‰é‹", "open toe"]):
        return "å‡‰é‹"
    else:
        return "å…¶ä»–"






def copy_images_for_store(config: dict, store_name: str, code_list: list):
    """
    å°†æŒ‡å®šç¼–ç çš„æ‰€æœ‰å›¾ç‰‡ä»å…±äº«ç›®å½•å¤åˆ¶åˆ°åº—é“ºå‘å¸ƒç›®å½•ä¸‹çš„ images æ–‡ä»¶å¤¹ä¸­ã€‚
    å¦‚æœæŸä¸ªç¼–ç æ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•å›¾ç‰‡ï¼Œåˆ™è®°å½•åˆ° missing_images.txtã€‚
    """
    src_dir = config["IMAGE_DIR"]
    dst_dir = config["OUTPUT_DIR"] / store_name / "images"
    dst_dir.mkdir(parents=True, exist_ok=True)

    missing_file = config["OUTPUT_DIR"] / store_name / "missing_images.txt"
    missing_file.parent.mkdir(parents=True, exist_ok=True)
    missing_codes = []

    copied_count = 0
    for code in code_list:
        matched = False
        for img in src_dir.glob(f"*{code}*.jpg"):
            shutil.copy(img, dst_dir / img.name)
            copied_count += 1
            matched = True
        if not matched:
            missing_codes.append(code)

    if missing_codes:
        with open(missing_file, "w", encoding="utf-8") as f:
            for code in missing_codes:
                f.write(code + "\n")
        print(f"âš ï¸ ç¼ºå›¾å•†å“ç¼–ç å·²è®°å½•: {missing_file}ï¼ˆå…± {len(missing_codes)} æ¡ï¼‰")

    print(f"âœ… å›¾ç‰‡æ‹·è´å®Œæˆï¼Œå…±å¤åˆ¶ {copied_count} å¼ å›¾ â†’ {dst_dir}")


