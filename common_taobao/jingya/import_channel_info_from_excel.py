import os
import psycopg2
import pandas as pd
from pathlib import Path
from config import CAMPER, CLARKS, ECCO, GEOX,BRAND_CONFIG


def find_latest_gei_file(document_dir: Path) -> Path:
    files = list(document_dir.glob("GEI@sales_catalogue_export@*.xlsx"))
    if not files:
        raise FileNotFoundError("âŒ æœªæ‰¾åˆ° GEI@sales_catalogue_export@ å¼€å¤´çš„æ–‡ä»¶")
    latest = max(files, key=lambda f: f.stat().st_mtime)
    print(f"ğŸ“„ ä½¿ç”¨æ–‡ä»¶: {latest.name}")
    return latest

def insert_jingyaid_to_db(brand: str):
    brand = brand.lower()
    if brand not in BRAND_CONFIG:
        raise ValueError(f"âŒ ä¸æ”¯æŒçš„å“ç‰Œ: {brand}")

    config = BRAND_CONFIG[brand]
    document_dir = Path(config["BASE"]) / "document"
    output_dir = Path(config["OUTPUT_DIR"])
    output_dir.mkdir(parents=True, exist_ok=True)
    db_config = config["PGSQL_CONFIG"]
    table_name = config["TABLE_NAME"]

    gei_file = find_latest_gei_file(document_dir)
    df = pd.read_excel(gei_file)

    updated = 0
    skipped = 0

    # âœ… ç”¨äºæ”¶é›†è§£æå¤±è´¥çš„è®°å½•
    unparsed_records = []

    conn = psycopg2.connect(**db_config)
    with conn:
        with conn.cursor() as cur:
            for _, row in df.iterrows():
                sku_name_raw = str(row.get("skuåç§°", "")).strip()

                if "ï¼Œ" not in sku_name_raw:
                    skipped += 1
                    # âœ… æ”¶é›†æ— æ³•è§£æçš„è®°å½•
                    unparsed_records.append({
                        "skuåç§°": sku_name_raw,
                        "æ¸ é“äº§å“id": str(row.get("æ¸ é“äº§å“id", "")),
                        "è´§å“id": str(row.get("è´§å“id", "")),
                        "skuID": str(row.get("skuID", ""))
                    })
                    continue

                parts = list(map(str.strip, sku_name_raw.split("ï¼Œ")))
                if len(parts) != 2:
                    skipped += 1
                    # âœ… æ”¶é›†æ— æ³•è§£æçš„è®°å½•
                    unparsed_records.append({
                        "skuåç§°": sku_name_raw,
                        "æ¸ é“äº§å“id": str(row.get("æ¸ é“äº§å“id", "")),
                        "è´§å“id": str(row.get("è´§å“id", "")),
                        "skuID": str(row.get("skuID", ""))
                    })
                    continue

                try:
                    product_code, size = parts
                    new_sku_name = product_code.replace("-", "") + size
                    sql = f"""
                        UPDATE {table_name}
                        SET
                            channel_product_id = %s,
                            channel_item_id = %s,
                            skuid = %s,
                            sku_name = %s,
                            is_published = TRUE,
                            last_checked = CURRENT_TIMESTAMP
                        WHERE product_code = %s AND size = %s
                    """
                    params = (
                        str(row.get("æ¸ é“äº§å“id")),
                        str(row.get("è´§å“id")),
                        str(row.get("skuID")),
                        new_sku_name,
                        product_code,
                        size
                    )
                    cur.execute(sql, params)
                    if cur.rowcount:
                        updated += 1
                    else:
                        skipped += 1
                except Exception as e:
                    print(f"âŒ è¡Œå¤„ç†å¤±è´¥: {e}")
                    skipped += 1

    print(f"âœ… æ›´æ–°å®Œæˆï¼šæˆåŠŸ {updated} æ¡ï¼Œè·³è¿‡ {skipped} æ¡")

    # âœ… å°†æ— æ³•è§£æçš„è®°å½•è¾“å‡ºåˆ° Excel
    if unparsed_records:
        error_df = pd.DataFrame(unparsed_records)
        error_file = output_dir / "unparsed_sku_names.xlsx"
        error_df.to_excel(error_file, index=False)
        print(f"âš ï¸ æ— æ³•è§£æçš„è®°å½•å·²è¾“å‡ºåˆ°ï¼š{error_file}")
    else:
        print("âœ… æ²¡æœ‰æ— æ³•è§£æçš„è®°å½•")

def insert_missing_products_with_zero_stock(brand: str):
    brand = brand.lower()
    if brand not in BRAND_CONFIG:
        raise ValueError(f"âŒ ä¸æ”¯æŒçš„å“ç‰Œ: {brand}")

    config = BRAND_CONFIG[brand]
    document_dir = Path(config["BASE"]) / "document"
    output_dir = Path(config["OUTPUT_DIR"])
    output_dir.mkdir(parents=True, exist_ok=True)
    missing_file = output_dir / "missing_product_codes.txt"

    db_config = config["PGSQL_CONFIG"]
    table_name = config["TABLE_NAME"]

    gei_file = find_latest_gei_file(document_dir)
    df = pd.read_excel(gei_file)

    # âœ… åˆ›å»ºæ˜ å°„è¡¨ï¼šproduct_code -> (title, channel_product_id, channel_item_id)
    product_info_map = {}
    for _, row in df.iterrows():
        sku_name_raw = str(row.get("skuåç§°", ""))
        if "ï¼Œ" in sku_name_raw:
            code = sku_name_raw.split("ï¼Œ")[0].strip()
            product_info_map[code] = {
                "title": str(row.get("æ¸ é“äº§å“åç§°", "")),
                "channel_product_id": str(row.get("æ¸ é“äº§å“id", "")).strip(),
                "channel_item_id": str(row.get("è´§å“id", "")).strip()
            }

    inserted = 0

    conn = psycopg2.connect(**db_config)
    with conn:
        with conn.cursor() as cur:
            # 1. ä» Excel æå–æ‰€æœ‰ product_code
            excel_product_codes = set(product_info_map.keys())

            # 2. æŸ¥è¯¢æ•°æ®åº“å·²æœ‰çš„ product_code
            cur.execute(f"SELECT DISTINCT product_code FROM {table_name}")
            db_product_codes = set([r[0] for r in cur.fetchall()])

            # 3. æ‰¾å‡ºç¼ºå¤±çš„ product_code
            missing_codes = excel_product_codes - db_product_codes
            print(f"ğŸ” ç¼ºå¤±å•†å“ç¼–ç æ•°é‡: {len(missing_codes)}")

            # 4. è¾“å‡ºç¼ºå¤±å•†å“ç¼–ç åˆ° TXT æ–‡ä»¶
            with open(missing_file, "w", encoding="utf-8") as f:
                for code in sorted(missing_codes):
                    f.write(code + "\n")
            print(f"âœ… ç¼ºå¤±å•†å“ç¼–ç å·²å†™å…¥æ–‡ä»¶ï¼š{missing_file}")

            # 5. æ’å…¥ç¼ºå¤±å•†å“ï¼ˆå¸¦ channel_product_id å’Œ channel_item_idï¼‰
            for code in missing_codes:
                info = product_info_map.get(code, {})
                title = info.get("title", "")
                channel_product_id = info.get("channel_product_id", "")
                channel_item_id = info.get("channel_item_id", "")

                # æ ¹æ®æ ‡é¢˜æ¨æ–­æ€§åˆ«å¹¶è®¾ç½®å°ºç 
                if "ç”·" in title:
                    gender = "ç”·æ¬¾"
                    sizes = ["39", "40", "41", "42", "43", "44", "45", "46"]
                elif "å¥³" in title:
                    gender = "å¥³æ¬¾"
                    sizes = ["35", "36", "37", "38", "39", "40", "41", "42"]
                else:
                    gender = "ç”·æ¬¾"
                    sizes = ["39", "40", "41", "42", "43", "44", "45", "46"]

                for size in sizes:
                    insert_sql = f"""
                        INSERT INTO {table_name} (
                            product_code, product_url, size, gender,
                            stock_count, channel_product_id, channel_item_id,
                            is_published, last_checked
                        ) VALUES (%s, %s, %s, %s, %s, %s, %s, FALSE, CURRENT_TIMESTAMP)
                    """
                    cur.execute(insert_sql, (
                        code, "", size, gender, 0,
                        channel_product_id, channel_item_id
                    ))
                    inserted += 1

    print(f"âœ… æ’å…¥å®Œæˆï¼šæ–°å¢ {inserted} æ¡ï¼ˆç¼ºå¤±å•†å“å…± {len(missing_codes)} ä¸ªï¼‰")
    print(f"ğŸ“‚ TXT æ–‡ä»¶ä½ç½®: {missing_file}")





if __name__ == "__main__":
    #insert_jingyaid_to_db("camper")
    insert_missing_products_with_zero_stock("camper")