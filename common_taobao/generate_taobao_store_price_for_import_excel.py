# -*- coding: utf-8 -*-
"""
é€ SKU å¯¼å‡ºåº—é“ºä»·æ ¼ï¼ˆæ”¯æŒæ‰¹é‡ï¼‰
- å•æ–‡ä»¶ï¼šä¿æŒ generate_price_excel(brand, input_dir, output_path) åŸè¡Œä¸ºä¸å˜ï¼ˆå– input_dir å†…â€œæœ€è¿‘ä¿®æ”¹â€çš„ä¸€ä¸ªExcelï¼‰
- æ‰¹é‡ï¼šæ–°å¢ generate_price_excels_bulk(brand, input_dir, output_dir, suffix)
  * å¤„ç† input_dir ä¸‹æ‰€æœ‰ *.xlsx / *.xls
  * è¾“å‡ºæ–‡ä»¶å = è¾“å…¥æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰ + suffix + ".xlsx"
  * æ¯ä¸ªæ–‡ä»¶ç‹¬ç«‹æŸ¥ä»·ã€ç‹¬ç«‹å¯¼å‡ºï¼Œå•ä¸ªå¤±è´¥ä¸å½±å“å…¶å®ƒæ–‡ä»¶
- åˆ—è¯†åˆ«ï¼šå®è´ID(=item_id)ã€å•†å®¶ç¼–ç (=product_code)ã€skuID(=skuid)
- ä»·æ ¼æ¥æºï¼šå“ç‰Œè¡¨ä¸­çš„ taobao_store_priceï¼ˆä¼˜å…ˆ product_codeï¼›å…œåº• product_nameï¼‰
- è¾“å‡ºä¸‰åˆ—ï¼šå®è´id | skuid | è°ƒæ•´åä»·æ ¼
"""
from pathlib import Path
import unicodedata
import re
from typing import List, Dict, Optional, Iterable, Tuple
import pandas as pd
import psycopg2
import math

from config import BRAND_CONFIG

# ===== åˆ—ååˆ«å =====
COL_ALIASES = {
    "item_id": {"item_id","itemid","ITEM_ID","å®è´id","å®è´ID","å®è´Id","å®è´"},
    "product_code": {
        "product_code","productcode","code",
        "å•†å“ç¼–ç ","å•†å“Code","äº§å“ç¼–ç ","ç¼–ç ","è´§å·",
        "å•†å®¶ç¼–ç ",
        "å•†å®¶è´§å·","å¤–éƒ¨ç¼–ç ","å¤–éƒ¨ä»£ç ",
        "outer_id","outerid","outer code","outercode"
    },
    "skuid": {
        "skuid","sku_id","SkuId","SKU_ID","SKUID",
        "skuID",
        "æ¸ é“è´§å“ID","æ¸ é“skuid","è´§å“id","è´§å“ID"
    },
}

_SPLIT = re.compile(r"[,\uFF0C;ï¼›\s\r\n]+")

def _canon(s: str) -> str:
    if s is None: return ""
    s = unicodedata.normalize("NFKC", str(s)).strip()
    s = s.replace("\u00A0", " ").replace("\u200B", "")
    return s.lower()

def _normalize_col(df: pd.DataFrame, want: str) -> str:
    canon2raw = {_canon(c): c for c in df.columns}
    for alias in COL_ALIASES[want]:
        key = _canon(alias)
        if key in canon2raw:
            return canon2raw[key]
    raise KeyError(f"Excelä¸­ç¼ºå°‘å¿…è¦åˆ—ï¼š{want}ï¼ˆå¯ç”¨åˆ«åï¼š{COL_ALIASES[want]}ï¼‰ï¼Œå½“å‰è¡¨å¤´ï¼š{list(df.columns)}")

def _list_excels(input_dir: Path) -> List[Path]:
    files = list(input_dir.glob("*.xlsx")) + list(input_dir.glob("*.xls"))
    return sorted(files, key=lambda p: p.stat().st_mtime, reverse=True)

def _find_latest_excel(input_dir: Path) -> Path:
    files = _list_excels(input_dir)
    if not files:
        raise FileNotFoundError(f"ç›®å½•æ²¡æœ‰æ‰¾åˆ° Excelï¼š{input_dir}")
    return files[0]

def _split_skuids(val) -> List[str]:
    if pd.isna(val): return []
    if isinstance(val, (int, float)) and not isinstance(val, bool):
        val = str(int(val))
    s = str(val).strip()
    if not s: return []
    parts = [p.strip() for p in _SPLIT.split(s) if p.strip()]
    parts = [re.sub(r"[^\w\-]", "", p) for p in parts if p]
    return [p for p in parts if p]

def _chunked(it: Iterable, size: int):
    buf = []
    for x in it:
        buf.append(x)
        if len(buf) >= size:
            yield buf; buf = []
    if buf: yield buf

def _fetch_prices(conn, table: str, codes: List[str]) -> Dict[str, Optional[float]]:
    prices: Dict[str, Optional[float]] = {}
    missing = list(dict.fromkeys(codes))
    with conn.cursor() as cur:
        try:
            for chunk in _chunked(missing, 1000):
                cur.execute(
                    f"SELECT product_code, taobao_store_price FROM {table} "
                    f"WHERE product_code = ANY(%s)", (chunk,))
                for code, price in cur.fetchall():
                    prices[str(code)] = None if price is None else float(price)
            missing = [c for c in missing if c not in prices]
        except Exception:
            pass
        if missing:
            try:
                for chunk in _chunked(missing, 1000):
                    cur.execute(
                        f"SELECT product_name, taobao_store_price FROM {table} "
                        f"WHERE product_name = ANY(%s)", (chunk,))
                    for code, price in cur.fetchall():
                        prices[str(code)] = None if price is None else float(price)
            except Exception:
                pass
    return prices

def _to_text(v: object) -> str:
    if v is None or (isinstance(v, float) and (math.isnan(v))):
        return ""
    if isinstance(v, (int,)):
        return str(v)
    if isinstance(v, float):
        if v.is_integer():
            return str(int(v))
        return f"{v:.15g}"
    if isinstance(v, pd._libs.missing.NAType) or (isinstance(v, str) and v.lower() == "nan"):
        return ""
    return str(v)

# ===== å•æ–‡ä»¶ï¼šä¿æŒå…¼å®¹ =====
def generate_price_excel(
    brand: str,
    input_dir: str | Path,
    output_path: str | Path,
    drop_rows_without_price: bool = True
) -> Path:
    brand = brand.lower().strip()
    if brand not in BRAND_CONFIG:
        raise ValueError(f"æœªçŸ¥å“ç‰Œï¼š{brand}")
    cfg = BRAND_CONFIG[brand]
    table = cfg["TABLE_NAME"]
    pg    = cfg["PGSQL_CONFIG"]

    input_dir = Path(input_dir)
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    excel_file = _find_latest_excel(input_dir)
    print(f"ğŸ“„ ä½¿ç”¨è¾“å…¥æ–‡ä»¶ï¼š{excel_file}")
    return _generate_price_excel_from_file(brand, excel_file, output_path, drop_rows_without_price, table, pg)

# ===== æ‰¹é‡ï¼šå¤„ç† input_dir ä¸‹æ‰€æœ‰ Excel =====
def generate_price_excels_bulk(
    brand: str,
    input_dir: str | Path,
    output_dir: str | Path,
    suffix: str = "_ä»·æ ¼",
    drop_rows_without_price: bool = True
):
    """
    æ‰¹é‡å¤„ç† input_dir ä¸‹çš„æ‰€æœ‰ Excelï¼›è¾“å‡ºæ–‡ä»¶å = è¾“å…¥æ–‡ä»¶å(ä¸å«æ‰©å±•å) + suffix + ".xlsx"
    """
    brand = brand.lower().strip()
    if brand not in BRAND_CONFIG:
        raise ValueError(f"æœªçŸ¥å“ç‰Œï¼š{brand}")
    cfg = BRAND_CONFIG[brand]
    table = cfg["TABLE_NAME"]
    pg    = cfg["PGSQL_CONFIG"]

    input_dir = Path(input_dir)
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    files = _list_excels(input_dir)
    if not files:
        raise FileNotFoundError(f"ç›®å½•æ²¡æœ‰æ‰¾åˆ° Excelï¼š{input_dir}")

    results = []
    for f in files:
        try:
            out_name = f.stem + (suffix or "")
            if not out_name.endswith(".xlsx"):
                out_name += ".xlsx"
            out_path = output_dir / out_name
            print(f"â–¶ï¸ {f.name} -> {out_name}")
            _generate_price_excel_from_file(brand, f, out_path, drop_rows_without_price, table, pg)
            results.append((str(f), str(out_path), None))
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥ï¼š{f} | é”™è¯¯ï¼š{e}")
            results.append((str(f), None, str(e)))
    return results

def _generate_price_excel_from_file(
    brand: str,
    excel_file: Path,
    output_path: Path,
    drop_rows_without_price: bool,
    table: str,
    pg: dict
) -> Path:
    output_path.parent.mkdir(parents=True, exist_ok=True)
    print(f"ğŸ“„ å¤„ç†ï¼š{excel_file}")
    df0 = pd.read_excel(excel_file, dtype=object)

    col_item = _normalize_col(df0, "item_id")
    col_code = _normalize_col(df0, "product_code")
    col_sku  = _normalize_col(df0, "skuid")

    def _prep_ffill(col: str):
        s = df0[col].apply(lambda v: _to_text(v).strip())
        s = s.replace("", pd.NA)
        return s.ffill().fillna("")

    df0[col_item] = _prep_ffill(col_item)
    df0[col_code] = _prep_ffill(col_code)

    rows = []
    for _, r in df0.iterrows():
        item_id = _to_text(r.get(col_item)).strip()
        code    = _to_text(r.get(col_code)).strip()
        skus    = _split_skuids(r.get(col_sku))
        if not skus:
            continue
        for sid in skus:
            sid = _to_text(sid).strip()
            if sid:
                rows.append((item_id, code, sid))

    if not rows:
        raise ValueError("è¾“å…¥Excelæ— æœ‰æ•ˆè®°å½•ï¼ˆæ£€æŸ¥å®è´ID/å•†å®¶ç¼–ç /skuIDåˆ—ä¸å†…å®¹ï¼‰ã€‚")

    df_expanded = pd.DataFrame(rows, columns=["å®è´id", "product_code", "skuid"])
    print(f"ğŸ” å±•å¼€åSKUè¡Œæ•°: {len(df_expanded)} | å®è´æ•°: {df_expanded['å®è´id'].nunique()} | å”¯ä¸€SKUæ•°: {df_expanded['skuid'].nunique()}")

    conn = psycopg2.connect(**pg)
    try:
        codes = list(dict.fromkeys(df_expanded["product_code"].tolist()))
        price_map = _fetch_prices(conn, table, codes)
    finally:
        conn.close()

    df_price = pd.DataFrame(
        [{"product_code": k, "è°ƒæ•´åä»·æ ¼": v} for k, v in price_map.items()],
        columns=["product_code", "è°ƒæ•´åä»·æ ¼"]
    )
    df_merged = df_expanded.merge(df_price, on="product_code", how="left")

    if drop_rows_without_price:
        before = len(df_merged)
        df_out = df_merged[df_merged["è°ƒæ•´åä»·æ ¼"].notna()].copy()
        print(f"ğŸ§¹ è·³è¿‡(æ— ä»·/éé²¸èŠ½)SKUè¡Œ: {before - len(df_out)}")
    else:
        df_out = df_merged.copy()
        df_out.loc[df_out["è°ƒæ•´åä»·æ ¼"].isna(), "è°ƒæ•´åä»·æ ¼"] = ""

    df_out = df_out[["å®è´id", "skuid", "è°ƒæ•´åä»·æ ¼"]]
    df_out.to_excel(output_path, index=False)
    print(f"âœ… å·²å¯¼å‡ºï¼š{output_path} | è¾“å‡ºSKUè¡Œæ•°: {len(df_out)} | å®è´æ•°: {df_out['å®è´id'].nunique()}")
    return output_path


# ===== æ–°å¢ï¼šæ‰¹é‡å¯¼å‡º SKU åº“å­˜ =====
def generate_stock_excels_bulk(
    brand: str,
    input_dir: str | Path,
    output_dir: str | Path,
    suffix: str = "_åº“å­˜",
    in_stock_qty: int = 3,
    out_stock_qty: int = 0
):
    """
    æ‰¹é‡å¤„ç† input_dir ä¸‹çš„æ‰€æœ‰ Excelï¼Œè¾“å‡º SKU çº§åº“å­˜ï¼š
    - å¦‚æœ Excel æ— â€œè§„æ ¼/å°ºç â€åˆ—ï¼šæŒ‰ product_code å½’å¹¶ï¼Œåªè¦è¯¥æ¬¾ä»»ä¸€å°ºç æœ‰è´§â†’è¯¥æ¬¾æ‰€æœ‰ skuID ç»Ÿä¸€å†™ in_stock_qtyï¼Œå¦åˆ™ 0ã€‚
    - å¦‚æœ Excel æœ‰â€œskuè§„æ ¼/è§„æ ¼/å°ºç â€åˆ—ï¼šæŒ‰ (product_code, size) ç²¾ç¡®åŒ¹é… DB çš„ stock_status è¾“å‡ºåº“å­˜ã€‚
    """
    brand = brand.lower().strip()
    if brand not in BRAND_CONFIG:
        raise ValueError(f"æœªçŸ¥å“ç‰Œï¼š{brand}")
    cfg = BRAND_CONFIG[brand]
    table = cfg["TABLE_NAME"]
    pg    = cfg["PGSQL_CONFIG"]

    input_dir = Path(input_dir)
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    files = _list_excels(input_dir)
    if not files:
        raise FileNotFoundError(f"ç›®å½•æ²¡æœ‰æ‰¾åˆ° Excelï¼š{input_dir}")

    # é¢„å– DB çš„åº“å­˜æ˜ç»†ï¼šproduct_code,size,stock_status
    import pandas as _pd
    conn = psycopg2.connect(**pg)
    try:
        sql = f"SELECT product_code, size, stock_status FROM {table}"
        db_stock = _pd.read_sql(sql, conn)
    finally:
        conn.close()

    # æ ‡å‡†åŒ–
    db_stock["product_code"] = db_stock["product_code"].astype(str).str.strip()
    db_stock["size"] = db_stock["size"].astype(str).str.strip()
    db_stock["stock_status"] = db_stock["stock_status"].astype(str).str.strip()

    # æ˜ å°„å‡½æ•°
    def status_to_qty(s: str) -> int:
        return in_stock_qty if str(s).strip() == "æœ‰è´§" else out_stock_qty

    results = []
    for f in files:
        try:
            out_name = f.stem + (suffix or "")
            if not out_name.endswith(".xlsx"):
                out_name += ".xlsx"
            out_path = output_dir / out_name
            print(f"â–¶ï¸ {f.name} -> {out_name}")

            df0 = pd.read_excel(f, dtype=object)

            col_item = _normalize_col(df0, "item_id")
            col_code = _normalize_col(df0, "product_code")
            col_sku  = _normalize_col(df0, "skuid")

            # é¢å¤–å°è¯•è¯†åˆ«â€œè§„æ ¼/å°ºç â€åˆ—ï¼ˆå¯é€‰ï¼‰
            spec_candidates = ["skuè§„æ ¼","è§„æ ¼","å°ºç ","SKUspec","sku_spec","å±æ€§","é”€å”®å±æ€§"]
            col_spec = None
            canon2raw = {_canon(c): c for c in df0.columns}
            for cand in spec_candidates:
                if _canon(cand) in canon2raw:
                    col_spec = canon2raw[_canon(cand)]
                    break

            # å‰å‘å¡«å……
            def _prep_ffill(col: str):
                s = df0[col].apply(lambda v: _to_text(v).strip())
                s = s.replace("", pd.NA)
                return s.ffill().fillna("")
            df0[col_item] = _prep_ffill(col_item)
            df0[col_code] = _prep_ffill(col_code)
            if col_spec:
                df0[col_spec] = _prep_ffill(col_spec)

            # å±•å¼€ SKU è¡Œ
            rows = []
            for _, r in df0.iterrows():
                item_id = _to_text(r.get(col_item)).strip()
                code    = _to_text(r.get(col_code)).strip()
                spec    = _to_text(r.get(col_spec)).strip() if col_spec else ""
                skus    = _split_skuids(r.get(col_sku))
                if not skus:
                    continue
                for sid in skus:
                    sid = _to_text(sid).strip()
                    if sid:
                        rows.append((item_id, code, spec, sid))
            if not rows:
                raise ValueError("è¾“å…¥Excelæ— æœ‰æ•ˆè®°å½•ï¼ˆæ£€æŸ¥å®è´ID/å•†å®¶ç¼–ç /skuIDåˆ—ä¸å†…å®¹ï¼‰ã€‚")

            df_expanded = pd.DataFrame(rows, columns=["å®è´id","product_code","è§„æ ¼","skuid"])

            # è®¡ç®—åº“å­˜
            if col_spec:
                # å°è¯•ä»è§„æ ¼ä¸­æŠ½å–å°ºç ï¼ˆå¦‚æœè§„æ ¼å°±æ˜¯å°ºç ï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦‚æœæ ¼å¼æ˜¯ â€œç¼–ç ,å°ºç â€ ä¹‹ç±»ï¼Œå¯æ®ä½ ç°çŠ¶åšè§£æï¼‰
                # è¿™é‡Œå…ˆç›´æ¥æ‹¿æ•´æ®µè§„æ ¼ä¸ DB çš„ size åšâ€œç­‰å€¼åŒ¹é…â€ï¼Œå¿…è¦æ—¶ä½ å¯ä»¥åŠ ä¸€ä¸ª normalize æ˜ å°„
                df_tmp = df_expanded.merge(
                    db_stock.assign(è°ƒæ•´ååº“å­˜=db_stock["stock_status"].map(status_to_qty)),
                    left_on=["product_code","è§„æ ¼"], right_on=["product_code","size"], how="left"
                )
                df_tmp["è°ƒæ•´ååº“å­˜"] = df_tmp["è°ƒæ•´ååº“å­˜"].fillna(out_stock_qty).astype(int)
            else:
                # æ— è§„æ ¼ï¼šæŒ‰æ¬¾èšåˆï¼Œåªè¦è¯¥æ¬¾æœ‰ä»»ä½•å°ºç â€œæœ‰è´§â€â†’æ•´æ¬¾ç»™ in_stock_qtyï¼Œå¦åˆ™ 0
                has_stock = (
                    db_stock.assign(qty=db_stock["stock_status"].map(status_to_qty))
                            .groupby("product_code")["qty"].max()
                            .reset_index()
                            .rename(columns={"qty":"è°ƒæ•´ååº“å­˜"})
                )
                df_tmp = df_expanded.merge(has_stock, on="product_code", how="left")
                df_tmp["è°ƒæ•´ååº“å­˜"] = df_tmp["è°ƒæ•´ååº“å­˜"].fillna(out_stock_qty).astype(int)

            # å¯¼å‡ºä¸¤åˆ—ï¼ˆè‹¥è¦å¸¦å®è´idå°±æŠŠåˆ—æ¢æˆ ["å®è´id","skuid","è°ƒæ•´ååº“å­˜"]ï¼‰
            df_out = df_tmp[["skuid","è°ƒæ•´ååº“å­˜"]]
            df_out.to_excel(out_path, index=False)
            print(f"âœ… å·²å¯¼å‡ºï¼š{out_path} | è¾“å‡ºSKUè¡Œæ•°: {len(df_out)}")
            results.append((str(f), str(out_path), None))
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥ï¼š{f} | é”™è¯¯ï¼š{e}")
            results.append((str(f), None, str(e)))
    return results


if __name__ == "__main__":
    # ç”¨æ³•ä¸€ï¼šå•æ–‡ä»¶ï¼ˆä¿æŒå…¼å®¹ï¼‰
    #   python this_script.py <brand> <input_dir> <output_excel_path>
    # ç”¨æ³•äºŒï¼šæ‰¹é‡ï¼ˆæ¨èä½ ç°åœ¨çš„åœºæ™¯ï¼‰
    #   python this_script.py <brand> <input_dir> <output_dir> --bulk [--suffix "_ä»·æ ¼"]
    import sys, traceback
    try:
        if len(sys.argv) >= 5 and sys.argv[4] == "--bulk":
            brand = sys.argv[1]
            input_dir = sys.argv[2]
            output_dir = sys.argv[3]
            suffix = "_ä»·æ ¼"
            if len(sys.argv) >= 7 and sys.argv[5] == "--suffix":
                suffix = sys.argv[6]
            results = generate_price_excels_bulk(brand, input_dir, output_dir, suffix=suffix, drop_rows_without_price=True)
            ok = [r for r in results if r[1] is not None]
            bad = [r for r in results if r[1] is None]
            print(f"ğŸ“¦ æ‰¹é‡å®Œæˆï¼šæˆåŠŸ {len(ok)} ä¸ªï¼Œå¤±è´¥ {len(bad)} ä¸ª")
            if bad:
                print("å¤±è´¥æ¸…å•ï¼š")
                for f, _, err in bad:
                    print(f" - {f} -> é”™è¯¯ï¼š{err}")
        elif len(sys.argv) >= 4:
            generate_price_excel(sys.argv[1], sys.argv[2], sys.argv[3])
        else:
            print("ç”¨æ³•ï¼š")
            print("  å•æ–‡ä»¶ï¼špython this_script.py <brand> <input_dir> <output_excel_path>")
            print('  æ‰¹  é‡ï¼špython this_script.py <brand> <input_dir> <output_dir> --bulk [--suffix "_ä»·æ ¼"]')
    except Exception as e:
        print("âŒ å¤±è´¥ï¼š", e)
        traceback.print_exc()
